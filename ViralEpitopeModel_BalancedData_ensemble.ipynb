{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on August 31 2022\\n\\n@author: JJ\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Created on August 31 2022\n",
    "\n",
    "@author: JJ\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 13:55:38.870971: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import os, re, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import log\n",
    "import random\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.regularizers import (\n",
    "    l2, \n",
    "    l1, \n",
    "    l1_l2\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import (\n",
    "    activations, \n",
    "    initializers, \n",
    "    regularizers, \n",
    "    constraints\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import from python files\n",
    "from model import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 8\n",
    "# Maximum number of threads to use for OpenMP parallel regions.\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "# Without setting below 2 environment variables, it didn't work for me. Thanks to @cjw85 \n",
    "os.environ[\"TF_NUM_INTRAOP_THREADS\"] = \"4\"\n",
    "os.environ[\"TF_NUM_INTEROP_THREADS\"] = \"4\"\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(\n",
    "    num_threads\n",
    ")\n",
    "tf.config.threading.set_intra_op_parallelism_threads(\n",
    "    num_threads\n",
    ")\n",
    "tf.config.set_soft_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in a well-defined initial state.\n",
    "random.seed(1337)\n",
    "np.random.seed(1337)\n",
    "tf.random.set_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint, \n",
    "    EarlyStopping\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    roc_auc_score,\n",
    "    average_precision_score,\n",
    "    precision_recall_curve,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.feature_selection import (\n",
    "    SelectKBest,\n",
    "    chi2\n",
    ")\n",
    "import keras_tuner as kt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pep, all_mhc, all_target = np.load('/home/jjia1/jjia1/viralepitope/all_pep_converted.npy'), np.load('/home/jjia1/jjia1/viralepitope/all_mhc_converted.npy'), np.load('/home/jjia1/jjia1/viralepitope/all_target_converted.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_sampling(pep, mhc, target):\n",
    "    pos = np.where(target==1)\n",
    "    neg = np.where(target==0)\n",
    "\n",
    "    pep_pos, mhc_pos, target_pos = pep[pos], mhc[pos], target[pos]\n",
    "    pep_neg, mhc_neg, target_neg = pep[neg], mhc[neg], target[neg]\n",
    "\n",
    "    pep_pos, mhc_pos, target_pos = resample(pep_pos, mhc_pos, target_pos, n_samples= len(target_pos))\n",
    "    pep_neg, mhc_neg, target_neg = resample(pep_neg, mhc_neg, target_neg, n_samples= len(target_pos))\n",
    "\n",
    "\n",
    "    pep = np.concatenate([pep_pos, pep_neg])\n",
    "    mhc = np.concatenate([mhc_pos, mhc_neg])\n",
    "    target = np.concatenate([target_pos, target_neg])\n",
    "\n",
    "    pep, mhc, target = shuffle(pep, mhc, target)\n",
    "    return pep, mhc, target\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pep, test_pep, train_mhc, test_mhc, train_target, test_target = train_test_split(all_pep, all_mhc, all_target, test_size = 0.2, stratify= all_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor = 'val_accuracy', mode = 'max', verbose = 1, patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1337)    \n",
    "allprobas_=np.array([]) \n",
    "all_labels=np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method attention_flatten.call of <attention_layer.attention_flatten object at 0x7f80d234a700>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method attention_flatten.call of <attention_layer.attention_flatten object at 0x7f80d234a700>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 12:36:03.215232: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-10-11 12:36:03.216733: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-11 12:36:03.216755: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-11 12:36:03.216780: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sbcphaplp001.uthouston.edu): /proc/driver/nvidia/version does not exist\n",
      "2022-10-11 12:36:03.217108: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-11 12:36:03.217764: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 15, 128)      0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 17, 128)      0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1920)         0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2176)         0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention (Attention)           (None, 143)          33281       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1920)         0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_1 (Attention)         (None, 145)          33281       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 2176)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten (attention_fl (None, 128)          0           attention[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            1921        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_1 (attention_ (None, 128)          0           attention_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            2177        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 129)          0           attention_flatten[0][0]          \n",
      "                                                                 dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 129)          0           attention_flatten_1[0][0]        \n",
      "                                                                 dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            130         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            130         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2)            0           dense_1[0][0]                    \n",
      "                                                                 dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            3           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 12:36:08.485174: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-10-11 12:36:08.487207: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200000000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 73s 61ms/step - loss: 0.2637 - accuracy: 0.9053 - auc: 0.7783 - val_loss: 0.2124 - val_accuracy: 0.9149 - val_auc: 0.8832\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91488, saving model to model/Ensemble/CV_0/model_0.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 67s 56ms/step - loss: 0.2167 - accuracy: 0.9131 - auc: 0.8774 - val_loss: 0.2062 - val_accuracy: 0.9159 - val_auc: 0.8913\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91488 to 0.91593, saving model to model/Ensemble/CV_0/model_0.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 62s 52ms/step - loss: 0.2083 - accuracy: 0.9158 - auc: 0.8858 - val_loss: 0.2034 - val_accuracy: 0.9169 - val_auc: 0.8946\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91593 to 0.91692, saving model to model/Ensemble/CV_0/model_0.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 63s 53ms/step - loss: 0.2081 - accuracy: 0.9154 - auc: 0.8883 - val_loss: 0.2041 - val_accuracy: 0.9159 - val_auc: 0.8961\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.91692\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 61s 52ms/step - loss: 0.2064 - accuracy: 0.9163 - auc: 0.8898 - val_loss: 0.2012 - val_accuracy: 0.9182 - val_auc: 0.8967\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91692 to 0.91825, saving model to model/Ensemble/CV_0/model_0.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 67s 57ms/step - loss: 0.2045 - accuracy: 0.9174 - auc: 0.8916 - val_loss: 0.2009 - val_accuracy: 0.9181 - val_auc: 0.8978\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91825\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 86s 73ms/step - loss: 0.2041 - accuracy: 0.9168 - auc: 0.8935 - val_loss: 0.2009 - val_accuracy: 0.9174 - val_auc: 0.8985\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91825\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 65s 55ms/step - loss: 0.2036 - accuracy: 0.9169 - auc: 0.8943 - val_loss: 0.1988 - val_accuracy: 0.9184 - val_auc: 0.9000\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91825 to 0.91843, saving model to model/Ensemble/CV_0/model_0.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 61s 51ms/step - loss: 0.2029 - accuracy: 0.9170 - auc: 0.8953 - val_loss: 0.1989 - val_accuracy: 0.9186 - val_auc: 0.9000\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91843 to 0.91856, saving model to model/Ensemble/CV_0/model_0.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2018 - accuracy: 0.9178 - auc: 0.8958 - val_loss: 0.1991 - val_accuracy: 0.9182 - val_auc: 0.9004\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91856\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.1998 - accuracy: 0.9183 - auc: 0.8980 - val_loss: 0.1976 - val_accuracy: 0.9192 - val_auc: 0.9015\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91856 to 0.91923, saving model to model/Ensemble/CV_0/model_0.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 62s 52ms/step - loss: 0.2007 - accuracy: 0.9181 - auc: 0.8975 - val_loss: 0.1984 - val_accuracy: 0.9179 - val_auc: 0.9018\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91923\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 66s 56ms/step - loss: 0.2008 - accuracy: 0.9181 - auc: 0.8975 - val_loss: 0.1976 - val_accuracy: 0.9187 - val_auc: 0.9017\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91923\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 65s 55ms/step - loss: 0.2003 - accuracy: 0.9182 - auc: 0.8976 - val_loss: 0.1965 - val_accuracy: 0.9198 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.91923 to 0.91981, saving model to model/Ensemble/CV_0/model_0.h5\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 61s 52ms/step - loss: 0.2002 - accuracy: 0.9182 - auc: 0.8981 - val_loss: 0.1974 - val_accuracy: 0.9192 - val_auc: 0.9016\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.91981\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 63s 53ms/step - loss: 0.1999 - accuracy: 0.9183 - auc: 0.8991 - val_loss: 0.1963 - val_accuracy: 0.9193 - val_auc: 0.9032\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.91981\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.2010 - accuracy: 0.9177 - auc: 0.8983 - val_loss: 0.1959 - val_accuracy: 0.9200 - val_auc: 0.9033\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.91981 to 0.92000, saving model to model/Ensemble/CV_0/model_0.h5\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.2000 - accuracy: 0.9181 - auc: 0.8987 - val_loss: 0.1965 - val_accuracy: 0.9193 - val_auc: 0.9031\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.92000\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 60s 50ms/step - loss: 0.1981 - accuracy: 0.9186 - auc: 0.9009 - val_loss: 0.1960 - val_accuracy: 0.9195 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.92000\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 66s 56ms/step - loss: 0.1979 - accuracy: 0.9192 - auc: 0.9006 - val_loss: 0.1957 - val_accuracy: 0.9197 - val_auc: 0.9037\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.92000\n",
      "Epoch 21/100\n",
      "1182/1182 [==============================] - 66s 56ms/step - loss: 0.1982 - accuracy: 0.9189 - auc: 0.9006 - val_loss: 0.1958 - val_accuracy: 0.9201 - val_auc: 0.9038\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.92000 to 0.92013, saving model to model/Ensemble/CV_0/model_0.h5\n",
      "Epoch 22/100\n",
      "1182/1182 [==============================] - 62s 53ms/step - loss: 0.1986 - accuracy: 0.9185 - auc: 0.9005 - val_loss: 0.1951 - val_accuracy: 0.9199 - val_auc: 0.9045\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.92013\n",
      "Epoch 23/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.1972 - accuracy: 0.9198 - auc: 0.9007 - val_loss: 0.1951 - val_accuracy: 0.9199 - val_auc: 0.9046\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.92013\n",
      "Epoch 24/100\n",
      "1182/1182 [==============================] - 69s 59ms/step - loss: 0.1974 - accuracy: 0.9195 - auc: 0.9013 - val_loss: 0.1949 - val_accuracy: 0.9200 - val_auc: 0.9045\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.92013\n",
      "Epoch 25/100\n",
      "1182/1182 [==============================] - 66s 56ms/step - loss: 0.1968 - accuracy: 0.9192 - auc: 0.9027 - val_loss: 0.1947 - val_accuracy: 0.9201 - val_auc: 0.9050\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.92013\n",
      "Epoch 26/100\n",
      "1182/1182 [==============================] - 62s 52ms/step - loss: 0.1965 - accuracy: 0.9191 - auc: 0.9029 - val_loss: 0.1941 - val_accuracy: 0.9203 - val_auc: 0.9053\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.92013 to 0.92032, saving model to model/Ensemble/CV_0/model_0.h5\n",
      "Epoch 27/100\n",
      "1182/1182 [==============================] - 63s 53ms/step - loss: 0.1976 - accuracy: 0.9191 - auc: 0.9019 - val_loss: 0.1957 - val_accuracy: 0.9198 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.92032\n",
      "Epoch 28/100\n",
      "1182/1182 [==============================] - 65s 55ms/step - loss: 0.1969 - accuracy: 0.9196 - auc: 0.9019 - val_loss: 0.1948 - val_accuracy: 0.9200 - val_auc: 0.9048\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.92032\n",
      "Epoch 29/100\n",
      "1182/1182 [==============================] - 65s 55ms/step - loss: 0.1971 - accuracy: 0.9193 - auc: 0.9021 - val_loss: 0.1949 - val_accuracy: 0.9201 - val_auc: 0.9053\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.92032\n",
      "Epoch 30/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.1963 - accuracy: 0.9200 - auc: 0.9025 - val_loss: 0.1943 - val_accuracy: 0.9205 - val_auc: 0.9051\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.92032 to 0.92050, saving model to model/Ensemble/CV_0/model_0.h5\n",
      "Epoch 31/100\n",
      "1182/1182 [==============================] - 62s 52ms/step - loss: 0.1968 - accuracy: 0.9194 - auc: 0.9027 - val_loss: 0.1951 - val_accuracy: 0.9203 - val_auc: 0.9056\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.92050\n",
      "Epoch 32/100\n",
      "1182/1182 [==============================] - 63s 53ms/step - loss: 0.1948 - accuracy: 0.9205 - auc: 0.9038 - val_loss: 0.1957 - val_accuracy: 0.9199 - val_auc: 0.9050\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.92050\n",
      "Epoch 33/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.1962 - accuracy: 0.9195 - auc: 0.9034 - val_loss: 0.1939 - val_accuracy: 0.9203 - val_auc: 0.9059\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.92050\n",
      "Epoch 34/100\n",
      "1182/1182 [==============================] - 58s 49ms/step - loss: 0.1955 - accuracy: 0.9197 - auc: 0.9032 - val_loss: 0.1938 - val_accuracy: 0.9203 - val_auc: 0.9059\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.92050\n",
      "Epoch 35/100\n",
      "1182/1182 [==============================] - 62s 52ms/step - loss: 0.1962 - accuracy: 0.9196 - auc: 0.9041 - val_loss: 0.1935 - val_accuracy: 0.9205 - val_auc: 0.9064\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.92050\n",
      "Epoch 00035: early stopping\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 15, 128)      0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 17, 128)      0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1920)         0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 2176)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_4 (Attention)         (None, 143)          33281       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 1920)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_5 (Attention)         (None, 145)          33281       dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 2176)         0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_4 (attention_ (None, 128)          0           attention_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            1921        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_5 (attention_ (None, 128)          0           attention_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            2177        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 129)          0           attention_flatten_4[0][0]        \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 129)          0           attention_flatten_5[0][0]        \n",
      "                                                                 dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 1)            130         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 1)            130         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 2)            0           dense_11[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            3           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1)            0           dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 73s 61ms/step - loss: 0.2714 - accuracy: 0.9074 - auc: 0.7595 - val_loss: 0.2123 - val_accuracy: 0.9148 - val_auc: 0.8834\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91480, saving model to model/Ensemble/CV_0/model_1.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 77s 65ms/step - loss: 0.2163 - accuracy: 0.9139 - auc: 0.8754 - val_loss: 0.2056 - val_accuracy: 0.9153 - val_auc: 0.8935\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91480 to 0.91527, saving model to model/Ensemble/CV_0/model_1.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 68s 57ms/step - loss: 0.2110 - accuracy: 0.9145 - auc: 0.8839 - val_loss: 0.2022 - val_accuracy: 0.9165 - val_auc: 0.8969\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91527 to 0.91650, saving model to model/Ensemble/CV_0/model_1.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 69s 58ms/step - loss: 0.2086 - accuracy: 0.9158 - auc: 0.8863 - val_loss: 0.2021 - val_accuracy: 0.9183 - val_auc: 0.8998\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91650 to 0.91833, saving model to model/Ensemble/CV_0/model_1.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 71s 60ms/step - loss: 0.2078 - accuracy: 0.9155 - auc: 0.8893 - val_loss: 0.1999 - val_accuracy: 0.9171 - val_auc: 0.9002\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.91833\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 70s 59ms/step - loss: 0.2076 - accuracy: 0.9156 - auc: 0.8896 - val_loss: 0.1992 - val_accuracy: 0.9175 - val_auc: 0.9006\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91833\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 72s 61ms/step - loss: 0.2064 - accuracy: 0.9160 - auc: 0.8902 - val_loss: 0.1979 - val_accuracy: 0.9184 - val_auc: 0.9020\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91833 to 0.91844, saving model to model/Ensemble/CV_0/model_1.h5\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 72s 61ms/step - loss: 0.2049 - accuracy: 0.9170 - auc: 0.8921 - val_loss: 0.1976 - val_accuracy: 0.9187 - val_auc: 0.9020\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91844 to 0.91870, saving model to model/Ensemble/CV_0/model_1.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 66s 56ms/step - loss: 0.2046 - accuracy: 0.9167 - auc: 0.8927 - val_loss: 0.1969 - val_accuracy: 0.9191 - val_auc: 0.9032\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91870 to 0.91910, saving model to model/Ensemble/CV_0/model_1.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 68s 57ms/step - loss: 0.2045 - accuracy: 0.9169 - auc: 0.8923 - val_loss: 0.1971 - val_accuracy: 0.9180 - val_auc: 0.9035\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91910\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 69s 59ms/step - loss: 0.2029 - accuracy: 0.9175 - auc: 0.8940 - val_loss: 0.1971 - val_accuracy: 0.9184 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91910\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 71s 60ms/step - loss: 0.2036 - accuracy: 0.9169 - auc: 0.8943 - val_loss: 0.1970 - val_accuracy: 0.9184 - val_auc: 0.9036\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91910\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 70s 59ms/step - loss: 0.2021 - accuracy: 0.9176 - auc: 0.8952 - val_loss: 0.1978 - val_accuracy: 0.9179 - val_auc: 0.9039\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91910\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 75s 63ms/step - loss: 0.2027 - accuracy: 0.9178 - auc: 0.8949 - val_loss: 0.1958 - val_accuracy: 0.9189 - val_auc: 0.9049\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91910\n",
      "Epoch 00014: early stopping\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 15, 128)      0           max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 17, 128)      0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 1920)         0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 2176)         0           dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_8 (Attention)         (None, 143)          33281       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1920)         0           flatten_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_9 (Attention)         (None, 145)          33281       dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 2176)         0           flatten_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_8 (attention_ (None, 128)          0           attention_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 1)            1921        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_9 (attention_ (None, 128)          0           attention_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 1)            2177        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 129)          0           attention_flatten_8[0][0]        \n",
      "                                                                 dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 129)          0           attention_flatten_9[0][0]        \n",
      "                                                                 dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 1)            130         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1)            130         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 2)            0           dense_21[0][0]                   \n",
      "                                                                 dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 1)            3           concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1)            0           dense_24[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 74s 62ms/step - loss: 0.2707 - accuracy: 0.9046 - auc: 0.7655 - val_loss: 0.2103 - val_accuracy: 0.9152 - val_auc: 0.8856\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91523, saving model to model/Ensemble/CV_0/model_2.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 70s 59ms/step - loss: 0.2169 - accuracy: 0.9133 - auc: 0.8747 - val_loss: 0.2039 - val_accuracy: 0.9163 - val_auc: 0.8956\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91523 to 0.91633, saving model to model/Ensemble/CV_0/model_2.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 70s 59ms/step - loss: 0.2120 - accuracy: 0.9144 - auc: 0.8825 - val_loss: 0.2016 - val_accuracy: 0.9167 - val_auc: 0.8986\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91633 to 0.91674, saving model to model/Ensemble/CV_0/model_2.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 70s 59ms/step - loss: 0.2103 - accuracy: 0.9151 - auc: 0.8854 - val_loss: 0.1998 - val_accuracy: 0.9180 - val_auc: 0.9000\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91674 to 0.91796, saving model to model/Ensemble/CV_0/model_2.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 73s 62ms/step - loss: 0.2058 - accuracy: 0.9167 - auc: 0.8892 - val_loss: 0.1986 - val_accuracy: 0.9184 - val_auc: 0.9013\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91796 to 0.91836, saving model to model/Ensemble/CV_0/model_2.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 69s 58ms/step - loss: 0.2065 - accuracy: 0.9160 - auc: 0.8899 - val_loss: 0.1981 - val_accuracy: 0.9188 - val_auc: 0.9018\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.91836 to 0.91876, saving model to model/Ensemble/CV_0/model_2.h5\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 68s 57ms/step - loss: 0.2043 - accuracy: 0.9170 - auc: 0.8915 - val_loss: 0.1980 - val_accuracy: 0.9186 - val_auc: 0.9029\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91876\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 71s 60ms/step - loss: 0.2048 - accuracy: 0.9166 - auc: 0.8921 - val_loss: 0.1964 - val_accuracy: 0.9196 - val_auc: 0.9036\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91876 to 0.91961, saving model to model/Ensemble/CV_0/model_2.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 69s 59ms/step - loss: 0.2042 - accuracy: 0.9170 - auc: 0.8933 - val_loss: 0.1962 - val_accuracy: 0.9201 - val_auc: 0.9039\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91961 to 0.92015, saving model to model/Ensemble/CV_0/model_2.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 69s 58ms/step - loss: 0.2037 - accuracy: 0.9168 - auc: 0.8941 - val_loss: 0.1969 - val_accuracy: 0.9185 - val_auc: 0.9040\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.92015\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 69s 58ms/step - loss: 0.2035 - accuracy: 0.9167 - auc: 0.8946 - val_loss: 0.1967 - val_accuracy: 0.9182 - val_auc: 0.9045\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.92015\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 68s 57ms/step - loss: 0.2015 - accuracy: 0.9179 - auc: 0.8952 - val_loss: 0.1955 - val_accuracy: 0.9191 - val_auc: 0.9051\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.92015\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 68s 58ms/step - loss: 0.2035 - accuracy: 0.9170 - auc: 0.8945 - val_loss: 0.1967 - val_accuracy: 0.9183 - val_auc: 0.9049\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.92015\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 66s 56ms/step - loss: 0.2021 - accuracy: 0.9176 - auc: 0.8954 - val_loss: 0.1951 - val_accuracy: 0.9199 - val_auc: 0.9050\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.92015\n",
      "Epoch 00014: early stopping\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 15, 128)      0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 17, 128)      0           max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 1920)         0           dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 2176)         0           dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_12 (Attention)        (None, 143)          33281       dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 1920)         0           flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_13 (Attention)        (None, 145)          33281       dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 2176)         0           flatten_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_12 (attention (None, 128)          0           attention_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1)            1921        dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_13 (attention (None, 128)          0           attention_13[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 1)            2177        dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 129)          0           attention_flatten_12[0][0]       \n",
      "                                                                 dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 129)          0           attention_flatten_13[0][0]       \n",
      "                                                                 dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 1)            130         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 1)            130         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 2)            0           dense_31[0][0]                   \n",
      "                                                                 dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 1)            3           concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1)            0           dense_34[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 59s 49ms/step - loss: 0.2755 - accuracy: 0.9031 - auc: 0.7485 - val_loss: 0.2149 - val_accuracy: 0.9129 - val_auc: 0.8826\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91291, saving model to model/Ensemble/CV_0/model_3.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 56s 48ms/step - loss: 0.2175 - accuracy: 0.9130 - auc: 0.8747 - val_loss: 0.2045 - val_accuracy: 0.9161 - val_auc: 0.8938\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91291 to 0.91606, saving model to model/Ensemble/CV_0/model_3.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 57s 48ms/step - loss: 0.2127 - accuracy: 0.9145 - auc: 0.8820 - val_loss: 0.2029 - val_accuracy: 0.9154 - val_auc: 0.8976\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.91606\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 56s 48ms/step - loss: 0.2105 - accuracy: 0.9148 - auc: 0.8847 - val_loss: 0.2006 - val_accuracy: 0.9166 - val_auc: 0.8991\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91606 to 0.91658, saving model to model/Ensemble/CV_0/model_3.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 60s 50ms/step - loss: 0.2075 - accuracy: 0.9163 - auc: 0.8881 - val_loss: 0.1992 - val_accuracy: 0.9174 - val_auc: 0.9014\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91658 to 0.91741, saving model to model/Ensemble/CV_0/model_3.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 62s 52ms/step - loss: 0.2078 - accuracy: 0.9157 - auc: 0.8885 - val_loss: 0.1982 - val_accuracy: 0.9176 - val_auc: 0.9020\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.91741 to 0.91765, saving model to model/Ensemble/CV_0/model_3.h5\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.2056 - accuracy: 0.9163 - auc: 0.8904 - val_loss: 0.1983 - val_accuracy: 0.9172 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91765\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.2050 - accuracy: 0.9165 - auc: 0.8918 - val_loss: 0.1966 - val_accuracy: 0.9185 - val_auc: 0.9041\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91765 to 0.91851, saving model to model/Ensemble/CV_0/model_3.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 61s 52ms/step - loss: 0.2050 - accuracy: 0.9167 - auc: 0.8916 - val_loss: 0.1957 - val_accuracy: 0.9193 - val_auc: 0.9047\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91851 to 0.91929, saving model to model/Ensemble/CV_0/model_3.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2056 - accuracy: 0.9164 - auc: 0.8914 - val_loss: 0.1958 - val_accuracy: 0.9192 - val_auc: 0.9048\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91929\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 61s 52ms/step - loss: 0.2034 - accuracy: 0.9173 - auc: 0.8940 - val_loss: 0.1953 - val_accuracy: 0.9199 - val_auc: 0.9050\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91929 to 0.91993, saving model to model/Ensemble/CV_0/model_3.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 60s 50ms/step - loss: 0.2035 - accuracy: 0.9169 - auc: 0.8946 - val_loss: 0.1963 - val_accuracy: 0.9177 - val_auc: 0.9055\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91993\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 58s 49ms/step - loss: 0.2045 - accuracy: 0.9169 - auc: 0.8929 - val_loss: 0.1952 - val_accuracy: 0.9185 - val_auc: 0.9060\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91993\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 58s 49ms/step - loss: 0.2027 - accuracy: 0.9179 - auc: 0.8946 - val_loss: 0.1950 - val_accuracy: 0.9183 - val_auc: 0.9072\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91993\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.2028 - accuracy: 0.9175 - auc: 0.8953 - val_loss: 0.1938 - val_accuracy: 0.9206 - val_auc: 0.9067\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.91993 to 0.92062, saving model to model/Ensemble/CV_0/model_3.h5\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 58s 49ms/step - loss: 0.2017 - accuracy: 0.9177 - auc: 0.8962 - val_loss: 0.1940 - val_accuracy: 0.9196 - val_auc: 0.9073\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.92062\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2011 - accuracy: 0.9185 - auc: 0.8956 - val_loss: 0.1934 - val_accuracy: 0.9205 - val_auc: 0.9075\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.92062\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2021 - accuracy: 0.9179 - auc: 0.8952 - val_loss: 0.1948 - val_accuracy: 0.9182 - val_auc: 0.9077\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.92062\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 58s 49ms/step - loss: 0.2020 - accuracy: 0.9176 - auc: 0.8965 - val_loss: 0.1931 - val_accuracy: 0.9192 - val_auc: 0.9085\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.92062\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 61s 52ms/step - loss: 0.2016 - accuracy: 0.9173 - auc: 0.8966 - val_loss: 0.1934 - val_accuracy: 0.9197 - val_auc: 0.9081\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.92062\n",
      "Epoch 00020: early stopping\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 15, 128)      0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 17, 128)      0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)            (None, 1920)         0           dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)            (None, 2176)         0           dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_16 (Attention)        (None, 143)          33281       dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 1920)         0           flatten_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_17 (Attention)        (None, 145)          33281       dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 2176)         0           flatten_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_16 (attention (None, 128)          0           attention_16[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 1)            1921        dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_17 (attention (None, 128)          0           attention_17[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 1)            2177        dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 129)          0           attention_flatten_16[0][0]       \n",
      "                                                                 dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 129)          0           attention_flatten_17[0][0]       \n",
      "                                                                 dense_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 1)            130         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 1)            130         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 2)            0           dense_41[0][0]                   \n",
      "                                                                 dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 1)            3           concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1)            0           dense_44[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 61s 51ms/step - loss: 0.2630 - accuracy: 0.9065 - auc: 0.7768 - val_loss: 0.2097 - val_accuracy: 0.9146 - val_auc: 0.8885\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91460, saving model to model/Ensemble/CV_0/model_4.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 61s 52ms/step - loss: 0.2154 - accuracy: 0.9138 - auc: 0.8772 - val_loss: 0.2032 - val_accuracy: 0.9166 - val_auc: 0.8961\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91460 to 0.91664, saving model to model/Ensemble/CV_0/model_4.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 63s 53ms/step - loss: 0.2111 - accuracy: 0.9144 - auc: 0.8837 - val_loss: 0.2008 - val_accuracy: 0.9173 - val_auc: 0.8990\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91664 to 0.91735, saving model to model/Ensemble/CV_0/model_4.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 61s 52ms/step - loss: 0.2088 - accuracy: 0.9153 - auc: 0.8870 - val_loss: 0.1995 - val_accuracy: 0.9173 - val_auc: 0.9010\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.91735\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2061 - accuracy: 0.9167 - auc: 0.8892 - val_loss: 0.1991 - val_accuracy: 0.9175 - val_auc: 0.9009\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91735 to 0.91748, saving model to model/Ensemble/CV_0/model_4.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2065 - accuracy: 0.9158 - auc: 0.8910 - val_loss: 0.1980 - val_accuracy: 0.9178 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.91748 to 0.91778, saving model to model/Ensemble/CV_0/model_4.h5\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2047 - accuracy: 0.9172 - auc: 0.8917 - val_loss: 0.1967 - val_accuracy: 0.9190 - val_auc: 0.9036\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91778 to 0.91898, saving model to model/Ensemble/CV_0/model_4.h5\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 61s 51ms/step - loss: 0.2043 - accuracy: 0.9167 - auc: 0.8930 - val_loss: 0.1978 - val_accuracy: 0.9179 - val_auc: 0.9036\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.91898\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2043 - accuracy: 0.9170 - auc: 0.8932 - val_loss: 0.1957 - val_accuracy: 0.9195 - val_auc: 0.9047\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91898 to 0.91947, saving model to model/Ensemble/CV_0/model_4.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.2041 - accuracy: 0.9169 - auc: 0.8940 - val_loss: 0.1960 - val_accuracy: 0.9190 - val_auc: 0.9052\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91947\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 61s 52ms/step - loss: 0.2023 - accuracy: 0.9174 - auc: 0.8956 - val_loss: 0.1952 - val_accuracy: 0.9196 - val_auc: 0.9061\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91947 to 0.91961, saving model to model/Ensemble/CV_0/model_4.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.2009 - accuracy: 0.9181 - auc: 0.8964 - val_loss: 0.1951 - val_accuracy: 0.9198 - val_auc: 0.9056\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.91961 to 0.91978, saving model to model/Ensemble/CV_0/model_4.h5\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.2020 - accuracy: 0.9177 - auc: 0.8954 - val_loss: 0.1948 - val_accuracy: 0.9194 - val_auc: 0.9063\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91978\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.2006 - accuracy: 0.9183 - auc: 0.8969 - val_loss: 0.1964 - val_accuracy: 0.9184 - val_auc: 0.9057\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91978\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 60s 50ms/step - loss: 0.2012 - accuracy: 0.9179 - auc: 0.8968 - val_loss: 0.1946 - val_accuracy: 0.9201 - val_auc: 0.9057\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.91978 to 0.92010, saving model to model/Ensemble/CV_0/model_4.h5\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2013 - accuracy: 0.9177 - auc: 0.8977 - val_loss: 0.1945 - val_accuracy: 0.9198 - val_auc: 0.9061\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.92010\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 58s 49ms/step - loss: 0.2010 - accuracy: 0.9180 - auc: 0.8975 - val_loss: 0.1946 - val_accuracy: 0.9190 - val_auc: 0.9072\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.92010\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 60s 50ms/step - loss: 0.2003 - accuracy: 0.9179 - auc: 0.8985 - val_loss: 0.1942 - val_accuracy: 0.9197 - val_auc: 0.9065\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.92010\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 62s 52ms/step - loss: 0.2006 - accuracy: 0.9177 - auc: 0.8988 - val_loss: 0.1930 - val_accuracy: 0.9198 - val_auc: 0.9081\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.92010\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 61s 51ms/step - loss: 0.2007 - accuracy: 0.9177 - auc: 0.8984 - val_loss: 0.1934 - val_accuracy: 0.9198 - val_auc: 0.9078\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.92010\n",
      "Epoch 00020: early stopping\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 15, 128)      0           max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 17, 128)      0           max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 1920)         0           dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)            (None, 2176)         0           dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_20 (Attention)        (None, 143)          33281       dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 1920)         0           flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_21 (Attention)        (None, 145)          33281       dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 2176)         0           flatten_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_20 (attention (None, 128)          0           attention_20[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 1)            1921        dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_21 (attention (None, 128)          0           attention_21[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 1)            2177        dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 129)          0           attention_flatten_20[0][0]       \n",
      "                                                                 dense_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 129)          0           attention_flatten_21[0][0]       \n",
      "                                                                 dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 1)            130         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 1)            130         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 2)            0           dense_51[0][0]                   \n",
      "                                                                 dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 1)            3           concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1)            0           dense_54[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 74s 62ms/step - loss: 0.2848 - accuracy: 0.9043 - auc: 0.7271 - val_loss: 0.2177 - val_accuracy: 0.9132 - val_auc: 0.8742\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91324, saving model to model/Ensemble/CV_1/model_0.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 72s 61ms/step - loss: 0.2206 - accuracy: 0.9124 - auc: 0.8710 - val_loss: 0.2097 - val_accuracy: 0.9143 - val_auc: 0.8871\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91324 to 0.91432, saving model to model/Ensemble/CV_1/model_0.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 72s 61ms/step - loss: 0.2113 - accuracy: 0.9148 - auc: 0.8817 - val_loss: 0.2061 - val_accuracy: 0.9161 - val_auc: 0.8914\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91432 to 0.91606, saving model to model/Ensemble/CV_1/model_0.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 68s 57ms/step - loss: 0.2102 - accuracy: 0.9147 - auc: 0.8851 - val_loss: 0.2045 - val_accuracy: 0.9161 - val_auc: 0.8940\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91606 to 0.91611, saving model to model/Ensemble/CV_1/model_0.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 75s 63ms/step - loss: 0.2087 - accuracy: 0.9153 - auc: 0.8867 - val_loss: 0.2033 - val_accuracy: 0.9171 - val_auc: 0.8946\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91611 to 0.91714, saving model to model/Ensemble/CV_1/model_0.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 71s 60ms/step - loss: 0.2063 - accuracy: 0.9163 - auc: 0.8892 - val_loss: 0.2020 - val_accuracy: 0.9172 - val_auc: 0.8965\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.91714 to 0.91719, saving model to model/Ensemble/CV_1/model_0.h5\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 75s 63ms/step - loss: 0.2066 - accuracy: 0.9159 - auc: 0.8903 - val_loss: 0.2018 - val_accuracy: 0.9169 - val_auc: 0.8977\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91719\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 70s 59ms/step - loss: 0.2060 - accuracy: 0.9162 - auc: 0.8912 - val_loss: 0.2002 - val_accuracy: 0.9179 - val_auc: 0.8987\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91719 to 0.91789, saving model to model/Ensemble/CV_1/model_0.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 71s 60ms/step - loss: 0.2053 - accuracy: 0.9158 - auc: 0.8927 - val_loss: 0.1999 - val_accuracy: 0.9180 - val_auc: 0.8993\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91789 to 0.91800, saving model to model/Ensemble/CV_1/model_0.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 74s 63ms/step - loss: 0.2038 - accuracy: 0.9171 - auc: 0.8932 - val_loss: 0.2008 - val_accuracy: 0.9173 - val_auc: 0.8988\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91800\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 74s 63ms/step - loss: 0.2025 - accuracy: 0.9172 - auc: 0.8945 - val_loss: 0.1988 - val_accuracy: 0.9185 - val_auc: 0.9005\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91800 to 0.91851, saving model to model/Ensemble/CV_1/model_0.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 72s 61ms/step - loss: 0.2034 - accuracy: 0.9170 - auc: 0.8940 - val_loss: 0.2002 - val_accuracy: 0.9172 - val_auc: 0.9002\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91851\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 71s 60ms/step - loss: 0.2033 - accuracy: 0.9171 - auc: 0.8943 - val_loss: 0.1989 - val_accuracy: 0.9180 - val_auc: 0.9010\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91851\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 73s 61ms/step - loss: 0.2030 - accuracy: 0.9169 - auc: 0.8942 - val_loss: 0.1986 - val_accuracy: 0.9179 - val_auc: 0.9011\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91851\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 72s 61ms/step - loss: 0.2029 - accuracy: 0.9174 - auc: 0.8947 - val_loss: 0.1986 - val_accuracy: 0.9182 - val_auc: 0.9006\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.91851\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 74s 63ms/step - loss: 0.2022 - accuracy: 0.9173 - auc: 0.8961 - val_loss: 0.1978 - val_accuracy: 0.9182 - val_auc: 0.9018\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.91851\n",
      "Epoch 00016: early stopping\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 15, 128)      0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 17, 128)      0           max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)            (None, 1920)         0           dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)            (None, 2176)         0           dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_24 (Attention)        (None, 143)          33281       dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 1920)         0           flatten_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_25 (Attention)        (None, 145)          33281       dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 2176)         0           flatten_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_24 (attention (None, 128)          0           attention_24[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 1)            1921        dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_25 (attention (None, 128)          0           attention_25[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 1)            2177        dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 129)          0           attention_flatten_24[0][0]       \n",
      "                                                                 dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 129)          0           attention_flatten_25[0][0]       \n",
      "                                                                 dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 1)            130         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 1)            130         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 2)            0           dense_61[0][0]                   \n",
      "                                                                 dense_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 1)            3           concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1)            0           dense_64[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 63s 52ms/step - loss: 0.2654 - accuracy: 0.9084 - auc: 0.7698 - val_loss: 0.2118 - val_accuracy: 0.9145 - val_auc: 0.8842\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91453, saving model to model/Ensemble/CV_1/model_1.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.2156 - accuracy: 0.9137 - auc: 0.8764 - val_loss: 0.2055 - val_accuracy: 0.9160 - val_auc: 0.8933\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91453 to 0.91597, saving model to model/Ensemble/CV_1/model_1.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.2106 - accuracy: 0.9145 - auc: 0.8841 - val_loss: 0.2027 - val_accuracy: 0.9166 - val_auc: 0.8964\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91597 to 0.91657, saving model to model/Ensemble/CV_1/model_1.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.2085 - accuracy: 0.9157 - auc: 0.8863 - val_loss: 0.2024 - val_accuracy: 0.9178 - val_auc: 0.8997\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91657 to 0.91781, saving model to model/Ensemble/CV_1/model_1.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 63s 53ms/step - loss: 0.2073 - accuracy: 0.9153 - auc: 0.8899 - val_loss: 0.2003 - val_accuracy: 0.9171 - val_auc: 0.9000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.91781\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 66s 55ms/step - loss: 0.2073 - accuracy: 0.9155 - auc: 0.8900 - val_loss: 0.1994 - val_accuracy: 0.9170 - val_auc: 0.9009\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91781\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.2064 - accuracy: 0.9160 - auc: 0.8905 - val_loss: 0.1982 - val_accuracy: 0.9186 - val_auc: 0.9013\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91781 to 0.91856, saving model to model/Ensemble/CV_1/model_1.h5\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.2046 - accuracy: 0.9164 - auc: 0.8926 - val_loss: 0.1973 - val_accuracy: 0.9187 - val_auc: 0.9024\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91856 to 0.91871, saving model to model/Ensemble/CV_1/model_1.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.2043 - accuracy: 0.9165 - auc: 0.8935 - val_loss: 0.1964 - val_accuracy: 0.9194 - val_auc: 0.9034\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91871 to 0.91944, saving model to model/Ensemble/CV_1/model_1.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2039 - accuracy: 0.9169 - auc: 0.8934 - val_loss: 0.1973 - val_accuracy: 0.9179 - val_auc: 0.9036\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91944\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 62s 52ms/step - loss: 0.2028 - accuracy: 0.9175 - auc: 0.8941 - val_loss: 0.1975 - val_accuracy: 0.9180 - val_auc: 0.9028\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91944\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 61s 52ms/step - loss: 0.2034 - accuracy: 0.9172 - auc: 0.8945 - val_loss: 0.1969 - val_accuracy: 0.9182 - val_auc: 0.9036\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91944\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.2014 - accuracy: 0.9182 - auc: 0.8958 - val_loss: 0.1989 - val_accuracy: 0.9173 - val_auc: 0.9038\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91944\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2031 - accuracy: 0.9170 - auc: 0.8949 - val_loss: 0.1956 - val_accuracy: 0.9192 - val_auc: 0.9051\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91944\n",
      "Epoch 00014: early stopping\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 15, 128)      0           max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 17, 128)      0           max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_28 (Flatten)            (None, 1920)         0           dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_29 (Flatten)            (None, 2176)         0           dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_28 (Attention)        (None, 143)          33281       dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 1920)         0           flatten_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_29 (Attention)        (None, 145)          33281       dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 2176)         0           flatten_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_28 (attention (None, 128)          0           attention_28[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 1)            1921        dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_29 (attention (None, 128)          0           attention_29[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 1)            2177        dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 129)          0           attention_flatten_28[0][0]       \n",
      "                                                                 dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 129)          0           attention_flatten_29[0][0]       \n",
      "                                                                 dense_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 1)            130         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 1)            130         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 2)            0           dense_71[0][0]                   \n",
      "                                                                 dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 1)            3           concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1)            0           dense_74[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 65s 54ms/step - loss: 0.2726 - accuracy: 0.9089 - auc: 0.7487 - val_loss: 0.2125 - val_accuracy: 0.9145 - val_auc: 0.8827\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91445, saving model to model/Ensemble/CV_1/model_2.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.2178 - accuracy: 0.9131 - auc: 0.8735 - val_loss: 0.2054 - val_accuracy: 0.9156 - val_auc: 0.8935\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91445 to 0.91556, saving model to model/Ensemble/CV_1/model_2.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 63s 53ms/step - loss: 0.2126 - accuracy: 0.9138 - auc: 0.8821 - val_loss: 0.2027 - val_accuracy: 0.9160 - val_auc: 0.8975\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91556 to 0.91601, saving model to model/Ensemble/CV_1/model_2.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2107 - accuracy: 0.9148 - auc: 0.8849 - val_loss: 0.2013 - val_accuracy: 0.9169 - val_auc: 0.8989\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91601 to 0.91687, saving model to model/Ensemble/CV_1/model_2.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 63s 54ms/step - loss: 0.2064 - accuracy: 0.9164 - auc: 0.8886 - val_loss: 0.1994 - val_accuracy: 0.9178 - val_auc: 0.9008\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91687 to 0.91781, saving model to model/Ensemble/CV_1/model_2.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 62s 52ms/step - loss: 0.2064 - accuracy: 0.9162 - auc: 0.8900 - val_loss: 0.1987 - val_accuracy: 0.9180 - val_auc: 0.9015\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.91781 to 0.91798, saving model to model/Ensemble/CV_1/model_2.h5\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 65s 55ms/step - loss: 0.2049 - accuracy: 0.9168 - auc: 0.8908 - val_loss: 0.1983 - val_accuracy: 0.9176 - val_auc: 0.9022\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91798\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 65s 55ms/step - loss: 0.2052 - accuracy: 0.9164 - auc: 0.8918 - val_loss: 0.1970 - val_accuracy: 0.9189 - val_auc: 0.9028\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91798 to 0.91890, saving model to model/Ensemble/CV_1/model_2.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 65s 55ms/step - loss: 0.2046 - accuracy: 0.9169 - auc: 0.8927 - val_loss: 0.1970 - val_accuracy: 0.9193 - val_auc: 0.9031\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91890 to 0.91926, saving model to model/Ensemble/CV_1/model_2.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 62s 53ms/step - loss: 0.2046 - accuracy: 0.9164 - auc: 0.8928 - val_loss: 0.1979 - val_accuracy: 0.9182 - val_auc: 0.9033\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91926\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 61s 52ms/step - loss: 0.2040 - accuracy: 0.9169 - auc: 0.8938 - val_loss: 0.1971 - val_accuracy: 0.9183 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91926\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.2017 - accuracy: 0.9178 - auc: 0.8951 - val_loss: 0.1963 - val_accuracy: 0.9183 - val_auc: 0.9048\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91926\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 60s 50ms/step - loss: 0.2040 - accuracy: 0.9169 - auc: 0.8938 - val_loss: 0.1975 - val_accuracy: 0.9180 - val_auc: 0.9045\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91926\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 63s 53ms/step - loss: 0.2026 - accuracy: 0.9173 - auc: 0.8947 - val_loss: 0.1956 - val_accuracy: 0.9196 - val_auc: 0.9045\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.91926 to 0.91957, saving model to model/Ensemble/CV_1/model_2.h5\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 65s 55ms/step - loss: 0.2027 - accuracy: 0.9167 - auc: 0.8962 - val_loss: 0.1952 - val_accuracy: 0.9195 - val_auc: 0.9053\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.91957\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 61s 52ms/step - loss: 0.2011 - accuracy: 0.9174 - auc: 0.8972 - val_loss: 0.1953 - val_accuracy: 0.9188 - val_auc: 0.9061\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.91957\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 60s 50ms/step - loss: 0.2032 - accuracy: 0.9166 - auc: 0.8947 - val_loss: 0.1950 - val_accuracy: 0.9190 - val_auc: 0.9064\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91957\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 63s 53ms/step - loss: 0.2012 - accuracy: 0.9178 - auc: 0.8975 - val_loss: 0.1944 - val_accuracy: 0.9193 - val_auc: 0.9064\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.91957\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2009 - accuracy: 0.9182 - auc: 0.8976 - val_loss: 0.1942 - val_accuracy: 0.9192 - val_auc: 0.9069\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.91957\n",
      "Epoch 00019: early stopping\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 15, 128)      0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 17, 128)      0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_32 (Flatten)            (None, 1920)         0           dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_33 (Flatten)            (None, 2176)         0           dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_32 (Attention)        (None, 143)          33281       dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 1920)         0           flatten_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_33 (Attention)        (None, 145)          33281       dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 2176)         0           flatten_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_32 (attention (None, 128)          0           attention_32[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 1)            1921        dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_33 (attention (None, 128)          0           attention_33[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 1)            2177        dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 129)          0           attention_flatten_32[0][0]       \n",
      "                                                                 dense_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 129)          0           attention_flatten_33[0][0]       \n",
      "                                                                 dense_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 1)            130         concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 1)            130         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 2)            0           dense_81[0][0]                   \n",
      "                                                                 dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 1)            3           concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 1)            0           dense_84[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 66s 55ms/step - loss: 0.2733 - accuracy: 0.9054 - auc: 0.7558 - val_loss: 0.2132 - val_accuracy: 0.9137 - val_auc: 0.8837\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91375, saving model to model/Ensemble/CV_1/model_3.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 66s 55ms/step - loss: 0.2165 - accuracy: 0.9132 - auc: 0.8759 - val_loss: 0.2043 - val_accuracy: 0.9165 - val_auc: 0.8948\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91375 to 0.91646, saving model to model/Ensemble/CV_1/model_3.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 65s 55ms/step - loss: 0.2122 - accuracy: 0.9144 - auc: 0.8827 - val_loss: 0.2030 - val_accuracy: 0.9152 - val_auc: 0.8980\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.91646\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 68s 58ms/step - loss: 0.2101 - accuracy: 0.9148 - auc: 0.8854 - val_loss: 0.2002 - val_accuracy: 0.9172 - val_auc: 0.8998\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91646 to 0.91721, saving model to model/Ensemble/CV_1/model_3.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 71s 60ms/step - loss: 0.2077 - accuracy: 0.9157 - auc: 0.8876 - val_loss: 0.1988 - val_accuracy: 0.9177 - val_auc: 0.9016\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91721 to 0.91770, saving model to model/Ensemble/CV_1/model_3.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 67s 57ms/step - loss: 0.2075 - accuracy: 0.9156 - auc: 0.8891 - val_loss: 0.1977 - val_accuracy: 0.9180 - val_auc: 0.9027\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.91770 to 0.91797, saving model to model/Ensemble/CV_1/model_3.h5\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 68s 58ms/step - loss: 0.2062 - accuracy: 0.9164 - auc: 0.8898 - val_loss: 0.1981 - val_accuracy: 0.9172 - val_auc: 0.9032\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91797\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 66s 56ms/step - loss: 0.2046 - accuracy: 0.9166 - auc: 0.8925 - val_loss: 0.1960 - val_accuracy: 0.9189 - val_auc: 0.9044\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91797 to 0.91892, saving model to model/Ensemble/CV_1/model_3.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.2047 - accuracy: 0.9167 - auc: 0.8918 - val_loss: 0.1964 - val_accuracy: 0.9191 - val_auc: 0.9043\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91892 to 0.91914, saving model to model/Ensemble/CV_1/model_3.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 66s 56ms/step - loss: 0.2057 - accuracy: 0.9164 - auc: 0.8914 - val_loss: 0.1955 - val_accuracy: 0.9195 - val_auc: 0.9047\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.91914 to 0.91953, saving model to model/Ensemble/CV_1/model_3.h5\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 65s 55ms/step - loss: 0.2037 - accuracy: 0.9171 - auc: 0.8936 - val_loss: 0.1954 - val_accuracy: 0.9198 - val_auc: 0.9047\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91953 to 0.91980, saving model to model/Ensemble/CV_1/model_3.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 63s 54ms/step - loss: 0.2032 - accuracy: 0.9172 - auc: 0.8947 - val_loss: 0.1964 - val_accuracy: 0.9179 - val_auc: 0.9053\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91980\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 65s 55ms/step - loss: 0.2041 - accuracy: 0.9170 - auc: 0.8932 - val_loss: 0.1954 - val_accuracy: 0.9184 - val_auc: 0.9060\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91980\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.2027 - accuracy: 0.9175 - auc: 0.8945 - val_loss: 0.1948 - val_accuracy: 0.9187 - val_auc: 0.9064\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91980\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 66s 55ms/step - loss: 0.2032 - accuracy: 0.9171 - auc: 0.8948 - val_loss: 0.1938 - val_accuracy: 0.9208 - val_auc: 0.9066\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.91980 to 0.92081, saving model to model/Ensemble/CV_1/model_3.h5\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 68s 57ms/step - loss: 0.2019 - accuracy: 0.9177 - auc: 0.8960 - val_loss: 0.1942 - val_accuracy: 0.9192 - val_auc: 0.9073\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.92081\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 69s 58ms/step - loss: 0.2010 - accuracy: 0.9181 - auc: 0.8960 - val_loss: 0.1934 - val_accuracy: 0.9203 - val_auc: 0.9075\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.92081\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 69s 58ms/step - loss: 0.2022 - accuracy: 0.9175 - auc: 0.8951 - val_loss: 0.1949 - val_accuracy: 0.9182 - val_auc: 0.9072\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.92081\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 67s 57ms/step - loss: 0.2019 - accuracy: 0.9176 - auc: 0.8963 - val_loss: 0.1935 - val_accuracy: 0.9193 - val_auc: 0.9081\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.92081\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 70s 59ms/step - loss: 0.2018 - accuracy: 0.9174 - auc: 0.8963 - val_loss: 0.1936 - val_accuracy: 0.9199 - val_auc: 0.9079\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.92081\n",
      "Epoch 00020: early stopping\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 15, 128)      0           max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 17, 128)      0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_36 (Flatten)            (None, 1920)         0           dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_37 (Flatten)            (None, 2176)         0           dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_36 (Attention)        (None, 143)          33281       dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 1920)         0           flatten_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_37 (Attention)        (None, 145)          33281       dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 2176)         0           flatten_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_36 (attention (None, 128)          0           attention_36[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 1)            1921        dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_37 (attention (None, 128)          0           attention_37[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 1)            2177        dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 129)          0           attention_flatten_36[0][0]       \n",
      "                                                                 dense_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 129)          0           attention_flatten_37[0][0]       \n",
      "                                                                 dense_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 1)            130         concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 1)            130         concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 2)            0           dense_91[0][0]                   \n",
      "                                                                 dense_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 1)            3           concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 1)            0           dense_94[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 59s 48ms/step - loss: 0.2760 - accuracy: 0.9062 - auc: 0.7517 - val_loss: 0.2137 - val_accuracy: 0.9143 - val_auc: 0.8816\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91431, saving model to model/Ensemble/CV_1/model_4.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 56s 47ms/step - loss: 0.2182 - accuracy: 0.9132 - auc: 0.8727 - val_loss: 0.2048 - val_accuracy: 0.9160 - val_auc: 0.8936\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91431 to 0.91605, saving model to model/Ensemble/CV_1/model_4.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 57s 48ms/step - loss: 0.2122 - accuracy: 0.9143 - auc: 0.8820 - val_loss: 0.2019 - val_accuracy: 0.9171 - val_auc: 0.8978\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91605 to 0.91707, saving model to model/Ensemble/CV_1/model_4.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 57s 48ms/step - loss: 0.2097 - accuracy: 0.9153 - auc: 0.8855 - val_loss: 0.1997 - val_accuracy: 0.9177 - val_auc: 0.9002\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91707 to 0.91774, saving model to model/Ensemble/CV_1/model_4.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 56s 48ms/step - loss: 0.2070 - accuracy: 0.9164 - auc: 0.8878 - val_loss: 0.1993 - val_accuracy: 0.9179 - val_auc: 0.9002\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91774 to 0.91791, saving model to model/Ensemble/CV_1/model_4.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 55s 47ms/step - loss: 0.2071 - accuracy: 0.9161 - auc: 0.8900 - val_loss: 0.1986 - val_accuracy: 0.9173 - val_auc: 0.9019\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91791\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 57s 48ms/step - loss: 0.2052 - accuracy: 0.9167 - auc: 0.8910 - val_loss: 0.1974 - val_accuracy: 0.9185 - val_auc: 0.9028\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91791 to 0.91848, saving model to model/Ensemble/CV_1/model_4.h5\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 56s 48ms/step - loss: 0.2047 - accuracy: 0.9165 - auc: 0.8923 - val_loss: 0.1982 - val_accuracy: 0.9175 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.91848\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 58s 49ms/step - loss: 0.2047 - accuracy: 0.9163 - auc: 0.8928 - val_loss: 0.1968 - val_accuracy: 0.9192 - val_auc: 0.9036\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91848 to 0.91919, saving model to model/Ensemble/CV_1/model_4.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 55s 47ms/step - loss: 0.2052 - accuracy: 0.9164 - auc: 0.8923 - val_loss: 0.1968 - val_accuracy: 0.9178 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91919\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 58s 49ms/step - loss: 0.2029 - accuracy: 0.9173 - auc: 0.8948 - val_loss: 0.1960 - val_accuracy: 0.9190 - val_auc: 0.9054\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91919\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 57s 48ms/step - loss: 0.2021 - accuracy: 0.9175 - auc: 0.8947 - val_loss: 0.1957 - val_accuracy: 0.9193 - val_auc: 0.9050\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.91919 to 0.91929, saving model to model/Ensemble/CV_1/model_4.h5\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 58s 49ms/step - loss: 0.2029 - accuracy: 0.9175 - auc: 0.8943 - val_loss: 0.1960 - val_accuracy: 0.9182 - val_auc: 0.9055\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91929\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 57s 48ms/step - loss: 0.2017 - accuracy: 0.9178 - auc: 0.8956 - val_loss: 0.1960 - val_accuracy: 0.9181 - val_auc: 0.9056\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91929\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 57s 48ms/step - loss: 0.2018 - accuracy: 0.9179 - auc: 0.8957 - val_loss: 0.1950 - val_accuracy: 0.9195 - val_auc: 0.9053\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.91929 to 0.91948, saving model to model/Ensemble/CV_1/model_4.h5\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 55s 47ms/step - loss: 0.2027 - accuracy: 0.9173 - auc: 0.8959 - val_loss: 0.1948 - val_accuracy: 0.9196 - val_auc: 0.9062\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.91948 to 0.91957, saving model to model/Ensemble/CV_1/model_4.h5\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 55s 46ms/step - loss: 0.2012 - accuracy: 0.9181 - auc: 0.8974 - val_loss: 0.1956 - val_accuracy: 0.9187 - val_auc: 0.9061\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91957\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 56s 48ms/step - loss: 0.2014 - accuracy: 0.9181 - auc: 0.8968 - val_loss: 0.1957 - val_accuracy: 0.9191 - val_auc: 0.9053\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.91957\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 54s 46ms/step - loss: 0.2010 - accuracy: 0.9175 - auc: 0.8984 - val_loss: 0.1938 - val_accuracy: 0.9195 - val_auc: 0.9079\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.91957\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 55s 46ms/step - loss: 0.2013 - accuracy: 0.9179 - auc: 0.8976 - val_loss: 0.1949 - val_accuracy: 0.9188 - val_auc: 0.9068\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.91957\n",
      "Epoch 21/100\n",
      "1182/1182 [==============================] - 56s 47ms/step - loss: 0.2003 - accuracy: 0.9182 - auc: 0.8985 - val_loss: 0.1933 - val_accuracy: 0.9204 - val_auc: 0.9082\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.91957 to 0.92043, saving model to model/Ensemble/CV_1/model_4.h5\n",
      "Epoch 22/100\n",
      "1182/1182 [==============================] - 55s 46ms/step - loss: 0.2001 - accuracy: 0.9183 - auc: 0.8986 - val_loss: 0.1940 - val_accuracy: 0.9196 - val_auc: 0.9072\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.92043\n",
      "Epoch 23/100\n",
      "1182/1182 [==============================] - 53s 45ms/step - loss: 0.2002 - accuracy: 0.9183 - auc: 0.8984 - val_loss: 0.1943 - val_accuracy: 0.9195 - val_auc: 0.9077\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.92043\n",
      "Epoch 24/100\n",
      "1182/1182 [==============================] - 56s 47ms/step - loss: 0.1995 - accuracy: 0.9182 - auc: 0.8993 - val_loss: 0.1927 - val_accuracy: 0.9208 - val_auc: 0.9076\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.92043 to 0.92081, saving model to model/Ensemble/CV_1/model_4.h5\n",
      "Epoch 25/100\n",
      "1182/1182 [==============================] - 54s 46ms/step - loss: 0.1993 - accuracy: 0.9188 - auc: 0.8994 - val_loss: 0.1929 - val_accuracy: 0.9206 - val_auc: 0.9080\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.92081\n",
      "Epoch 26/100\n",
      "1182/1182 [==============================] - 56s 47ms/step - loss: 0.1986 - accuracy: 0.9188 - auc: 0.8992 - val_loss: 0.1923 - val_accuracy: 0.9204 - val_auc: 0.9088\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.92081\n",
      "Epoch 27/100\n",
      "1182/1182 [==============================] - 54s 46ms/step - loss: 0.1986 - accuracy: 0.9191 - auc: 0.9008 - val_loss: 0.1929 - val_accuracy: 0.9210 - val_auc: 0.9086\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.92081 to 0.92104, saving model to model/Ensemble/CV_1/model_4.h5\n",
      "Epoch 28/100\n",
      "1182/1182 [==============================] - 56s 47ms/step - loss: 0.1991 - accuracy: 0.9185 - auc: 0.8998 - val_loss: 0.1925 - val_accuracy: 0.9203 - val_auc: 0.9090\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.92104\n",
      "Epoch 29/100\n",
      "1182/1182 [==============================] - 56s 47ms/step - loss: 0.1993 - accuracy: 0.9184 - auc: 0.9001 - val_loss: 0.1920 - val_accuracy: 0.9207 - val_auc: 0.9093\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.92104\n",
      "Epoch 30/100\n",
      "1182/1182 [==============================] - 55s 47ms/step - loss: 0.1990 - accuracy: 0.9184 - auc: 0.9000 - val_loss: 0.1931 - val_accuracy: 0.9195 - val_auc: 0.9088\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.92104\n",
      "Epoch 31/100\n",
      "1182/1182 [==============================] - 55s 47ms/step - loss: 0.1980 - accuracy: 0.9186 - auc: 0.9004 - val_loss: 0.1925 - val_accuracy: 0.9198 - val_auc: 0.9092\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.92104\n",
      "Epoch 32/100\n",
      "1182/1182 [==============================] - 56s 47ms/step - loss: 0.1977 - accuracy: 0.9195 - auc: 0.9008 - val_loss: 0.1913 - val_accuracy: 0.9208 - val_auc: 0.9098\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.92104\n",
      "Epoch 00032: early stopping\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 15, 128)      0           max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 17, 128)      0           max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_40 (Flatten)            (None, 1920)         0           dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_41 (Flatten)            (None, 2176)         0           dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_40 (Attention)        (None, 143)          33281       dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 1920)         0           flatten_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_41 (Attention)        (None, 145)          33281       dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 2176)         0           flatten_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_40 (attention (None, 128)          0           attention_40[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_100 (Dense)               (None, 1)            1921        dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_41 (attention (None, 128)          0           attention_41[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_102 (Dense)               (None, 1)            2177        dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 129)          0           attention_flatten_40[0][0]       \n",
      "                                                                 dense_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 129)          0           attention_flatten_41[0][0]       \n",
      "                                                                 dense_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_101 (Dense)               (None, 1)            130         concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_103 (Dense)               (None, 1)            130         concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 2)            0           dense_101[0][0]                  \n",
      "                                                                 dense_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_104 (Dense)               (None, 1)            3           concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1)            0           dense_104[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 58s 48ms/step - loss: 0.2680 - accuracy: 0.9069 - auc: 0.7661 - val_loss: 0.2149 - val_accuracy: 0.9138 - val_auc: 0.8799\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91384, saving model to model/Ensemble/CV_2/model_0.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2185 - accuracy: 0.9127 - auc: 0.8744 - val_loss: 0.2075 - val_accuracy: 0.9156 - val_auc: 0.8896\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91384 to 0.91562, saving model to model/Ensemble/CV_2/model_0.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 57s 48ms/step - loss: 0.2097 - accuracy: 0.9155 - auc: 0.8837 - val_loss: 0.2043 - val_accuracy: 0.9167 - val_auc: 0.8932\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91562 to 0.91667, saving model to model/Ensemble/CV_2/model_0.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 56s 48ms/step - loss: 0.2091 - accuracy: 0.9152 - auc: 0.8869 - val_loss: 0.2035 - val_accuracy: 0.9164 - val_auc: 0.8961\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.91667\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 55s 46ms/step - loss: 0.2071 - accuracy: 0.9159 - auc: 0.8889 - val_loss: 0.2012 - val_accuracy: 0.9180 - val_auc: 0.8973\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91667 to 0.91798, saving model to model/Ensemble/CV_2/model_0.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 56s 48ms/step - loss: 0.2056 - accuracy: 0.9165 - auc: 0.8903 - val_loss: 0.2009 - val_accuracy: 0.9174 - val_auc: 0.8985\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91798\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 53s 45ms/step - loss: 0.2052 - accuracy: 0.9167 - auc: 0.8923 - val_loss: 0.2007 - val_accuracy: 0.9177 - val_auc: 0.8987\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91798\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2045 - accuracy: 0.9166 - auc: 0.8932 - val_loss: 0.1990 - val_accuracy: 0.9184 - val_auc: 0.9001\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91798 to 0.91843, saving model to model/Ensemble/CV_2/model_0.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 55s 46ms/step - loss: 0.2038 - accuracy: 0.9168 - auc: 0.8943 - val_loss: 0.1992 - val_accuracy: 0.9186 - val_auc: 0.8999\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91843 to 0.91856, saving model to model/Ensemble/CV_2/model_0.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 55s 47ms/step - loss: 0.2016 - accuracy: 0.9181 - auc: 0.8961 - val_loss: 0.1988 - val_accuracy: 0.9182 - val_auc: 0.9007\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91856\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 54s 45ms/step - loss: 0.2007 - accuracy: 0.9182 - auc: 0.8967 - val_loss: 0.1980 - val_accuracy: 0.9191 - val_auc: 0.9016\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91856 to 0.91906, saving model to model/Ensemble/CV_2/model_0.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 56s 47ms/step - loss: 0.2019 - accuracy: 0.9176 - auc: 0.8961 - val_loss: 0.1990 - val_accuracy: 0.9176 - val_auc: 0.9014\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91906\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 55s 46ms/step - loss: 0.2014 - accuracy: 0.9177 - auc: 0.8967 - val_loss: 0.1980 - val_accuracy: 0.9186 - val_auc: 0.9018\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91906\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 55s 47ms/step - loss: 0.2010 - accuracy: 0.9182 - auc: 0.8965 - val_loss: 0.1971 - val_accuracy: 0.9191 - val_auc: 0.9024\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.91906 to 0.91912, saving model to model/Ensemble/CV_2/model_0.h5\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 54s 45ms/step - loss: 0.2007 - accuracy: 0.9180 - auc: 0.8976 - val_loss: 0.1973 - val_accuracy: 0.9187 - val_auc: 0.9021\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.91912\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 55s 47ms/step - loss: 0.1999 - accuracy: 0.9180 - auc: 0.8992 - val_loss: 0.1967 - val_accuracy: 0.9188 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.91912\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 53s 45ms/step - loss: 0.2013 - accuracy: 0.9180 - auc: 0.8980 - val_loss: 0.1963 - val_accuracy: 0.9194 - val_auc: 0.9033\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.91912 to 0.91936, saving model to model/Ensemble/CV_2/model_0.h5\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 54s 46ms/step - loss: 0.2001 - accuracy: 0.9181 - auc: 0.8985 - val_loss: 0.1969 - val_accuracy: 0.9189 - val_auc: 0.9029\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.91936\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 53s 45ms/step - loss: 0.1989 - accuracy: 0.9186 - auc: 0.8998 - val_loss: 0.1961 - val_accuracy: 0.9191 - val_auc: 0.9031\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.91936\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 54s 45ms/step - loss: 0.1984 - accuracy: 0.9187 - auc: 0.9001 - val_loss: 0.1958 - val_accuracy: 0.9199 - val_auc: 0.9034\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.91936 to 0.91986, saving model to model/Ensemble/CV_2/model_0.h5\n",
      "Epoch 21/100\n",
      "1182/1182 [==============================] - 52s 44ms/step - loss: 0.1987 - accuracy: 0.9186 - auc: 0.9002 - val_loss: 0.1961 - val_accuracy: 0.9191 - val_auc: 0.9036\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.91986\n",
      "Epoch 22/100\n",
      "1182/1182 [==============================] - 53s 45ms/step - loss: 0.1988 - accuracy: 0.9187 - auc: 0.9002 - val_loss: 0.1957 - val_accuracy: 0.9190 - val_auc: 0.9044\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.91986\n",
      "Epoch 23/100\n",
      "1182/1182 [==============================] - 52s 44ms/step - loss: 0.1975 - accuracy: 0.9196 - auc: 0.9005 - val_loss: 0.1954 - val_accuracy: 0.9194 - val_auc: 0.9045\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.91986\n",
      "Epoch 24/100\n",
      "1182/1182 [==============================] - 53s 45ms/step - loss: 0.1980 - accuracy: 0.9188 - auc: 0.9006 - val_loss: 0.1950 - val_accuracy: 0.9202 - val_auc: 0.9044\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.91986 to 0.92016, saving model to model/Ensemble/CV_2/model_0.h5\n",
      "Epoch 25/100\n",
      "1182/1182 [==============================] - 54s 45ms/step - loss: 0.1975 - accuracy: 0.9188 - auc: 0.9017 - val_loss: 0.1956 - val_accuracy: 0.9195 - val_auc: 0.9045\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.92016\n",
      "Epoch 26/100\n",
      "1182/1182 [==============================] - 56s 48ms/step - loss: 0.1967 - accuracy: 0.9190 - auc: 0.9029 - val_loss: 0.1946 - val_accuracy: 0.9199 - val_auc: 0.9049\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.92016\n",
      "Epoch 27/100\n",
      "1182/1182 [==============================] - 56s 48ms/step - loss: 0.1977 - accuracy: 0.9190 - auc: 0.9018 - val_loss: 0.1956 - val_accuracy: 0.9195 - val_auc: 0.9047\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.92016\n",
      "Epoch 28/100\n",
      "1182/1182 [==============================] - 56s 48ms/step - loss: 0.1978 - accuracy: 0.9188 - auc: 0.9011 - val_loss: 0.1950 - val_accuracy: 0.9194 - val_auc: 0.9049\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.92016\n",
      "Epoch 29/100\n",
      "1182/1182 [==============================] - 56s 47ms/step - loss: 0.1976 - accuracy: 0.9189 - auc: 0.9014 - val_loss: 0.1950 - val_accuracy: 0.9195 - val_auc: 0.9054\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.92016\n",
      "Epoch 00029: early stopping\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 15, 128)      0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 17, 128)      0           max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_44 (Flatten)            (None, 1920)         0           dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_45 (Flatten)            (None, 2176)         0           dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_44 (Attention)        (None, 143)          33281       dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 1920)         0           flatten_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_45 (Attention)        (None, 145)          33281       dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 2176)         0           flatten_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_44 (attention (None, 128)          0           attention_44[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_110 (Dense)               (None, 1)            1921        dropout_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_45 (attention (None, 128)          0           attention_45[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_112 (Dense)               (None, 1)            2177        dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 129)          0           attention_flatten_44[0][0]       \n",
      "                                                                 dense_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 129)          0           attention_flatten_45[0][0]       \n",
      "                                                                 dense_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_111 (Dense)               (None, 1)            130         concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_113 (Dense)               (None, 1)            130         concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 2)            0           dense_111[0][0]                  \n",
      "                                                                 dense_113[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_114 (Dense)               (None, 1)            3           concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 1)            0           dense_114[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 64s 53ms/step - loss: 0.2667 - accuracy: 0.9082 - auc: 0.7676 - val_loss: 0.2113 - val_accuracy: 0.9148 - val_auc: 0.8845\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91478, saving model to model/Ensemble/CV_2/model_1.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 61s 52ms/step - loss: 0.2152 - accuracy: 0.9138 - auc: 0.8770 - val_loss: 0.2051 - val_accuracy: 0.9154 - val_auc: 0.8944\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91478 to 0.91537, saving model to model/Ensemble/CV_2/model_1.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 62s 52ms/step - loss: 0.2108 - accuracy: 0.9148 - auc: 0.8841 - val_loss: 0.2021 - val_accuracy: 0.9164 - val_auc: 0.8976\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91537 to 0.91643, saving model to model/Ensemble/CV_2/model_1.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 63s 53ms/step - loss: 0.2083 - accuracy: 0.9158 - auc: 0.8865 - val_loss: 0.2017 - val_accuracy: 0.9179 - val_auc: 0.9004\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91643 to 0.91787, saving model to model/Ensemble/CV_2/model_1.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.2076 - accuracy: 0.9158 - auc: 0.8894 - val_loss: 0.1997 - val_accuracy: 0.9174 - val_auc: 0.9002\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.91787\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 58s 49ms/step - loss: 0.2074 - accuracy: 0.9158 - auc: 0.8897 - val_loss: 0.1993 - val_accuracy: 0.9169 - val_auc: 0.9012\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91787\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2067 - accuracy: 0.9158 - auc: 0.8900 - val_loss: 0.1976 - val_accuracy: 0.9188 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91787 to 0.91878, saving model to model/Ensemble/CV_2/model_1.h5\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2041 - accuracy: 0.9169 - auc: 0.8931 - val_loss: 0.1975 - val_accuracy: 0.9179 - val_auc: 0.9027\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.91878\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 62s 52ms/step - loss: 0.2046 - accuracy: 0.9166 - auc: 0.8928 - val_loss: 0.1962 - val_accuracy: 0.9188 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91878 to 0.91878, saving model to model/Ensemble/CV_2/model_1.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 66s 56ms/step - loss: 0.2042 - accuracy: 0.9170 - auc: 0.8931 - val_loss: 0.1964 - val_accuracy: 0.9183 - val_auc: 0.9046\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91878\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 62s 53ms/step - loss: 0.2026 - accuracy: 0.9175 - auc: 0.8947 - val_loss: 0.1971 - val_accuracy: 0.9180 - val_auc: 0.9037\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91878\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 58s 49ms/step - loss: 0.2028 - accuracy: 0.9171 - auc: 0.8956 - val_loss: 0.1967 - val_accuracy: 0.9181 - val_auc: 0.9044\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91878\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 61s 51ms/step - loss: 0.2012 - accuracy: 0.9179 - auc: 0.8962 - val_loss: 0.1974 - val_accuracy: 0.9184 - val_auc: 0.9048\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91878\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 61s 51ms/step - loss: 0.2024 - accuracy: 0.9178 - auc: 0.8956 - val_loss: 0.1951 - val_accuracy: 0.9192 - val_auc: 0.9057\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.91878 to 0.91916, saving model to model/Ensemble/CV_2/model_1.h5\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 59s 50ms/step - loss: 0.2022 - accuracy: 0.9174 - auc: 0.8967 - val_loss: 0.1954 - val_accuracy: 0.9186 - val_auc: 0.9057\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.91916\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 65s 55ms/step - loss: 0.2011 - accuracy: 0.9178 - auc: 0.8973 - val_loss: 0.1961 - val_accuracy: 0.9187 - val_auc: 0.9053\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.91916\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 66s 56ms/step - loss: 0.2014 - accuracy: 0.9174 - auc: 0.8981 - val_loss: 0.1958 - val_accuracy: 0.9188 - val_auc: 0.9056\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91916\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 65s 55ms/step - loss: 0.2014 - accuracy: 0.9174 - auc: 0.8976 - val_loss: 0.1942 - val_accuracy: 0.9198 - val_auc: 0.9071\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.91916 to 0.91977, saving model to model/Ensemble/CV_2/model_1.h5\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 61s 52ms/step - loss: 0.1998 - accuracy: 0.9188 - auc: 0.8979 - val_loss: 0.1952 - val_accuracy: 0.9186 - val_auc: 0.9067\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.91977\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 63s 53ms/step - loss: 0.1999 - accuracy: 0.9186 - auc: 0.8978 - val_loss: 0.1935 - val_accuracy: 0.9200 - val_auc: 0.9067\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.91977 to 0.91997, saving model to model/Ensemble/CV_2/model_1.h5\n",
      "Epoch 21/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.2004 - accuracy: 0.9185 - auc: 0.8984 - val_loss: 0.1932 - val_accuracy: 0.9204 - val_auc: 0.9073\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.91997 to 0.92042, saving model to model/Ensemble/CV_2/model_1.h5\n",
      "Epoch 22/100\n",
      "1182/1182 [==============================] - 63s 53ms/step - loss: 0.2004 - accuracy: 0.9182 - auc: 0.8985 - val_loss: 0.1936 - val_accuracy: 0.9199 - val_auc: 0.9071\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.92042\n",
      "Epoch 23/100\n",
      "1182/1182 [==============================] - 63s 53ms/step - loss: 0.1988 - accuracy: 0.9189 - auc: 0.8996 - val_loss: 0.1943 - val_accuracy: 0.9193 - val_auc: 0.9074\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.92042\n",
      "Epoch 24/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.1998 - accuracy: 0.9181 - auc: 0.8998 - val_loss: 0.1931 - val_accuracy: 0.9203 - val_auc: 0.9075\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.92042\n",
      "Epoch 25/100\n",
      "1182/1182 [==============================] - 61s 51ms/step - loss: 0.1989 - accuracy: 0.9183 - auc: 0.9000 - val_loss: 0.1927 - val_accuracy: 0.9198 - val_auc: 0.9083\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.92042\n",
      "Epoch 26/100\n",
      "1182/1182 [==============================] - 66s 55ms/step - loss: 0.1987 - accuracy: 0.9192 - auc: 0.8998 - val_loss: 0.1929 - val_accuracy: 0.9205 - val_auc: 0.9078\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.92042 to 0.92048, saving model to model/Ensemble/CV_2/model_1.h5\n",
      "Epoch 27/100\n",
      "1182/1182 [==============================] - 62s 52ms/step - loss: 0.1990 - accuracy: 0.9184 - auc: 0.9006 - val_loss: 0.1918 - val_accuracy: 0.9211 - val_auc: 0.9084\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.92048 to 0.92110, saving model to model/Ensemble/CV_2/model_1.h5\n",
      "Epoch 28/100\n",
      "1182/1182 [==============================] - 58s 49ms/step - loss: 0.1984 - accuracy: 0.9193 - auc: 0.9001 - val_loss: 0.1926 - val_accuracy: 0.9204 - val_auc: 0.9084\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.92110\n",
      "Epoch 29/100\n",
      "1182/1182 [==============================] - 58s 49ms/step - loss: 0.1985 - accuracy: 0.9191 - auc: 0.9004 - val_loss: 0.1929 - val_accuracy: 0.9198 - val_auc: 0.9086\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.92110\n",
      "Epoch 30/100\n",
      "1182/1182 [==============================] - 60s 51ms/step - loss: 0.1979 - accuracy: 0.9192 - auc: 0.9008 - val_loss: 0.1929 - val_accuracy: 0.9201 - val_auc: 0.9084\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.92110\n",
      "Epoch 31/100\n",
      "1182/1182 [==============================] - 66s 56ms/step - loss: 0.1978 - accuracy: 0.9193 - auc: 0.9012 - val_loss: 0.1921 - val_accuracy: 0.9204 - val_auc: 0.9087\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.92110\n",
      "Epoch 32/100\n",
      "1182/1182 [==============================] - 70s 59ms/step - loss: 0.1973 - accuracy: 0.9195 - auc: 0.9016 - val_loss: 0.1915 - val_accuracy: 0.9213 - val_auc: 0.9089\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.92110 to 0.92132, saving model to model/Ensemble/CV_2/model_1.h5\n",
      "Epoch 33/100\n",
      "1182/1182 [==============================] - 67s 57ms/step - loss: 0.1983 - accuracy: 0.9191 - auc: 0.9012 - val_loss: 0.1918 - val_accuracy: 0.9213 - val_auc: 0.9086\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.92132\n",
      "Epoch 34/100\n",
      "1182/1182 [==============================] - 66s 55ms/step - loss: 0.1975 - accuracy: 0.9190 - auc: 0.9017 - val_loss: 0.1917 - val_accuracy: 0.9208 - val_auc: 0.9087\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.92132\n",
      "Epoch 35/100\n",
      "1182/1182 [==============================] - 63s 53ms/step - loss: 0.1968 - accuracy: 0.9198 - auc: 0.9021 - val_loss: 0.1920 - val_accuracy: 0.9208 - val_auc: 0.9085\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.92132\n",
      "Epoch 36/100\n",
      "1182/1182 [==============================] - 67s 57ms/step - loss: 0.1975 - accuracy: 0.9191 - auc: 0.9014 - val_loss: 0.1913 - val_accuracy: 0.9214 - val_auc: 0.9094\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.92132 to 0.92139, saving model to model/Ensemble/CV_2/model_1.h5\n",
      "Epoch 37/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.1974 - accuracy: 0.9189 - auc: 0.9021 - val_loss: 0.1916 - val_accuracy: 0.9207 - val_auc: 0.9092\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.92139\n",
      "Epoch 38/100\n",
      "1182/1182 [==============================] - 66s 56ms/step - loss: 0.1969 - accuracy: 0.9194 - auc: 0.9022 - val_loss: 0.1918 - val_accuracy: 0.9205 - val_auc: 0.9092\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.92139\n",
      "Epoch 39/100\n",
      "1182/1182 [==============================] - 69s 58ms/step - loss: 0.1975 - accuracy: 0.9191 - auc: 0.9021 - val_loss: 0.1916 - val_accuracy: 0.9203 - val_auc: 0.9096\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.92139\n",
      "Epoch 40/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.1964 - accuracy: 0.9199 - auc: 0.9022 - val_loss: 0.1917 - val_accuracy: 0.9202 - val_auc: 0.9096\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.92139\n",
      "Epoch 41/100\n",
      "1182/1182 [==============================] - 64s 54ms/step - loss: 0.1978 - accuracy: 0.9189 - auc: 0.9022 - val_loss: 0.1910 - val_accuracy: 0.9213 - val_auc: 0.9095\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.92139\n",
      "Epoch 00041: early stopping\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 15, 128)      0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 17, 128)      0           max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_48 (Flatten)            (None, 1920)         0           dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_49 (Flatten)            (None, 2176)         0           dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_48 (Attention)        (None, 143)          33281       dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 1920)         0           flatten_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_49 (Attention)        (None, 145)          33281       dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 2176)         0           flatten_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_48 (attention (None, 128)          0           attention_48[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 1)            1921        dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_49 (attention (None, 128)          0           attention_49[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 1)            2177        dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 129)          0           attention_flatten_48[0][0]       \n",
      "                                                                 dense_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 129)          0           attention_flatten_49[0][0]       \n",
      "                                                                 dense_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 1)            130         concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 1)            130         concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 2)            0           dense_121[0][0]                  \n",
      "                                                                 dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_124 (Dense)               (None, 1)            3           concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 1)            0           dense_124[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 55s 44ms/step - loss: 0.2592 - accuracy: 0.9096 - auc: 0.7834 - val_loss: 0.2087 - val_accuracy: 0.9153 - val_auc: 0.8882\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91527, saving model to model/Ensemble/CV_2/model_2.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 52s 44ms/step - loss: 0.2158 - accuracy: 0.9138 - auc: 0.8766 - val_loss: 0.2034 - val_accuracy: 0.9162 - val_auc: 0.8966\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91527 to 0.91623, saving model to model/Ensemble/CV_2/model_2.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2115 - accuracy: 0.9144 - auc: 0.8835 - val_loss: 0.2014 - val_accuracy: 0.9169 - val_auc: 0.8995\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91623 to 0.91691, saving model to model/Ensemble/CV_2/model_2.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2100 - accuracy: 0.9153 - auc: 0.8858 - val_loss: 0.2000 - val_accuracy: 0.9177 - val_auc: 0.9003\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91691 to 0.91767, saving model to model/Ensemble/CV_2/model_2.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2054 - accuracy: 0.9167 - auc: 0.8900 - val_loss: 0.1985 - val_accuracy: 0.9185 - val_auc: 0.9022\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91767 to 0.91847, saving model to model/Ensemble/CV_2/model_2.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2058 - accuracy: 0.9166 - auc: 0.8907 - val_loss: 0.1977 - val_accuracy: 0.9184 - val_auc: 0.9029\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91847\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2042 - accuracy: 0.9169 - auc: 0.8919 - val_loss: 0.1982 - val_accuracy: 0.9181 - val_auc: 0.9029\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91847\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2042 - accuracy: 0.9169 - auc: 0.8932 - val_loss: 0.1962 - val_accuracy: 0.9197 - val_auc: 0.9041\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91847 to 0.91971, saving model to model/Ensemble/CV_2/model_2.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2038 - accuracy: 0.9171 - auc: 0.8936 - val_loss: 0.1963 - val_accuracy: 0.9197 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91971 to 0.91975, saving model to model/Ensemble/CV_2/model_2.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2031 - accuracy: 0.9170 - auc: 0.8950 - val_loss: 0.1960 - val_accuracy: 0.9195 - val_auc: 0.9045\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91975\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2031 - accuracy: 0.9173 - auc: 0.8950 - val_loss: 0.1958 - val_accuracy: 0.9193 - val_auc: 0.9052\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91975\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2006 - accuracy: 0.9184 - auc: 0.8965 - val_loss: 0.1953 - val_accuracy: 0.9194 - val_auc: 0.9055\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91975\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2032 - accuracy: 0.9171 - auc: 0.8950 - val_loss: 0.1963 - val_accuracy: 0.9187 - val_auc: 0.9057\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91975\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2012 - accuracy: 0.9178 - auc: 0.8968 - val_loss: 0.1949 - val_accuracy: 0.9197 - val_auc: 0.9055\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91975\n",
      "Epoch 00014: early stopping\n",
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 15, 128)      0           max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 17, 128)      0           max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_52 (Flatten)            (None, 1920)         0           dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_53 (Flatten)            (None, 2176)         0           dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_52 (Attention)        (None, 143)          33281       dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 1920)         0           flatten_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_53 (Attention)        (None, 145)          33281       dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 2176)         0           flatten_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_52 (attention (None, 128)          0           attention_52[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_130 (Dense)               (None, 1)            1921        dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_53 (attention (None, 128)          0           attention_53[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_132 (Dense)               (None, 1)            2177        dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 129)          0           attention_flatten_52[0][0]       \n",
      "                                                                 dense_130[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 129)          0           attention_flatten_53[0][0]       \n",
      "                                                                 dense_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_131 (Dense)               (None, 1)            130         concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_133 (Dense)               (None, 1)            130         concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 2)            0           dense_131[0][0]                  \n",
      "                                                                 dense_133[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_134 (Dense)               (None, 1)            3           concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 1)            0           dense_134[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 54s 45ms/step - loss: 0.2721 - accuracy: 0.9059 - auc: 0.7610 - val_loss: 0.2126 - val_accuracy: 0.9143 - val_auc: 0.8836\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91432, saving model to model/Ensemble/CV_2/model_3.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2165 - accuracy: 0.9133 - auc: 0.8758 - val_loss: 0.2036 - val_accuracy: 0.9169 - val_auc: 0.8954\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91432 to 0.91691, saving model to model/Ensemble/CV_2/model_3.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2115 - accuracy: 0.9145 - auc: 0.8838 - val_loss: 0.2024 - val_accuracy: 0.9155 - val_auc: 0.8986\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.91691\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 51s 44ms/step - loss: 0.2091 - accuracy: 0.9153 - auc: 0.8864 - val_loss: 0.1999 - val_accuracy: 0.9170 - val_auc: 0.9002\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91691 to 0.91696, saving model to model/Ensemble/CV_2/model_3.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 54s 45ms/step - loss: 0.2069 - accuracy: 0.9167 - auc: 0.8887 - val_loss: 0.1986 - val_accuracy: 0.9174 - val_auc: 0.9019\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91696 to 0.91736, saving model to model/Ensemble/CV_2/model_3.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 52s 44ms/step - loss: 0.2069 - accuracy: 0.9157 - auc: 0.8898 - val_loss: 0.1979 - val_accuracy: 0.9176 - val_auc: 0.9024\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.91736 to 0.91763, saving model to model/Ensemble/CV_2/model_3.h5\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2053 - accuracy: 0.9167 - auc: 0.8910 - val_loss: 0.1983 - val_accuracy: 0.9172 - val_auc: 0.9032\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91763\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2042 - accuracy: 0.9165 - auc: 0.8931 - val_loss: 0.1962 - val_accuracy: 0.9190 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91763 to 0.91904, saving model to model/Ensemble/CV_2/model_3.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2038 - accuracy: 0.9168 - auc: 0.8931 - val_loss: 0.1957 - val_accuracy: 0.9195 - val_auc: 0.9051\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91904 to 0.91950, saving model to model/Ensemble/CV_2/model_3.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2043 - accuracy: 0.9166 - auc: 0.8935 - val_loss: 0.1948 - val_accuracy: 0.9200 - val_auc: 0.9058\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.91950 to 0.91996, saving model to model/Ensemble/CV_2/model_3.h5\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2023 - accuracy: 0.9183 - auc: 0.8956 - val_loss: 0.1948 - val_accuracy: 0.9199 - val_auc: 0.9056\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91996\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2026 - accuracy: 0.9173 - auc: 0.8955 - val_loss: 0.1960 - val_accuracy: 0.9188 - val_auc: 0.9050\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91996\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2028 - accuracy: 0.9177 - auc: 0.8950 - val_loss: 0.1945 - val_accuracy: 0.9190 - val_auc: 0.9069\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91996\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 52s 44ms/step - loss: 0.2012 - accuracy: 0.9176 - auc: 0.8967 - val_loss: 0.1945 - val_accuracy: 0.9193 - val_auc: 0.9074\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91996\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2016 - accuracy: 0.9178 - auc: 0.8972 - val_loss: 0.1942 - val_accuracy: 0.9205 - val_auc: 0.9066\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.91996 to 0.92045, saving model to model/Ensemble/CV_2/model_3.h5\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2009 - accuracy: 0.9180 - auc: 0.8973 - val_loss: 0.1936 - val_accuracy: 0.9200 - val_auc: 0.9072\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.92045\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 52s 44ms/step - loss: 0.1985 - accuracy: 0.9192 - auc: 0.8990 - val_loss: 0.1933 - val_accuracy: 0.9202 - val_auc: 0.9083\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.92045\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 54s 46ms/step - loss: 0.1999 - accuracy: 0.9187 - auc: 0.8981 - val_loss: 0.1947 - val_accuracy: 0.9185 - val_auc: 0.9074\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.92045\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 53s 45ms/step - loss: 0.2002 - accuracy: 0.9180 - auc: 0.8989 - val_loss: 0.1928 - val_accuracy: 0.9199 - val_auc: 0.9084\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.92045\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 54s 46ms/step - loss: 0.1998 - accuracy: 0.9182 - auc: 0.8989 - val_loss: 0.1927 - val_accuracy: 0.9210 - val_auc: 0.9088\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.92045 to 0.92096, saving model to model/Ensemble/CV_2/model_3.h5\n",
      "Epoch 21/100\n",
      "1182/1182 [==============================] - 54s 45ms/step - loss: 0.1999 - accuracy: 0.9184 - auc: 0.8989 - val_loss: 0.1939 - val_accuracy: 0.9192 - val_auc: 0.9081\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.92096\n",
      "Epoch 22/100\n",
      "1182/1182 [==============================] - 53s 44ms/step - loss: 0.1985 - accuracy: 0.9192 - auc: 0.8999 - val_loss: 0.1923 - val_accuracy: 0.9205 - val_auc: 0.9085\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.92096\n",
      "Epoch 23/100\n",
      "1182/1182 [==============================] - 53s 45ms/step - loss: 0.1989 - accuracy: 0.9184 - auc: 0.9008 - val_loss: 0.1938 - val_accuracy: 0.9197 - val_auc: 0.9082\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.92096\n",
      "Epoch 24/100\n",
      "1182/1182 [==============================] - 53s 45ms/step - loss: 0.2002 - accuracy: 0.9182 - auc: 0.8990 - val_loss: 0.1918 - val_accuracy: 0.9207 - val_auc: 0.9092\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.92096\n",
      "Epoch 25/100\n",
      "1182/1182 [==============================] - 54s 46ms/step - loss: 0.1995 - accuracy: 0.9181 - auc: 0.8995 - val_loss: 0.1919 - val_accuracy: 0.9212 - val_auc: 0.9091\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.92096 to 0.92120, saving model to model/Ensemble/CV_2/model_3.h5\n",
      "Epoch 26/100\n",
      "1182/1182 [==============================] - 57s 48ms/step - loss: 0.1981 - accuracy: 0.9191 - auc: 0.9001 - val_loss: 0.1914 - val_accuracy: 0.9215 - val_auc: 0.9090\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.92120 to 0.92153, saving model to model/Ensemble/CV_2/model_3.h5\n",
      "Epoch 27/100\n",
      "1182/1182 [==============================] - 56s 47ms/step - loss: 0.1999 - accuracy: 0.9179 - auc: 0.9000 - val_loss: 0.1915 - val_accuracy: 0.9212 - val_auc: 0.9095\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.92153\n",
      "Epoch 28/100\n",
      "1182/1182 [==============================] - 55s 46ms/step - loss: 0.1982 - accuracy: 0.9189 - auc: 0.9008 - val_loss: 0.1914 - val_accuracy: 0.9213 - val_auc: 0.9095\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.92153\n",
      "Epoch 29/100\n",
      "1182/1182 [==============================] - 52s 44ms/step - loss: 0.1985 - accuracy: 0.9186 - auc: 0.9012 - val_loss: 0.1923 - val_accuracy: 0.9204 - val_auc: 0.9087\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.92153\n",
      "Epoch 30/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.1977 - accuracy: 0.9192 - auc: 0.9012 - val_loss: 0.1912 - val_accuracy: 0.9209 - val_auc: 0.9101\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.92153\n",
      "Epoch 31/100\n",
      "1182/1182 [==============================] - 53s 44ms/step - loss: 0.1976 - accuracy: 0.9189 - auc: 0.9016 - val_loss: 0.1913 - val_accuracy: 0.9212 - val_auc: 0.9095\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.92153\n",
      "Epoch 00031: early stopping\n",
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 15, 128)      0           max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 17, 128)      0           max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_56 (Flatten)            (None, 1920)         0           dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_57 (Flatten)            (None, 2176)         0           dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_56 (Attention)        (None, 143)          33281       dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 1920)         0           flatten_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_57 (Attention)        (None, 145)          33281       dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 2176)         0           flatten_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_56 (attention (None, 128)          0           attention_56[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_140 (Dense)               (None, 1)            1921        dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_57 (attention (None, 128)          0           attention_57[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_142 (Dense)               (None, 1)            2177        dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 129)          0           attention_flatten_56[0][0]       \n",
      "                                                                 dense_140[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 129)          0           attention_flatten_57[0][0]       \n",
      "                                                                 dense_142[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_141 (Dense)               (None, 1)            130         concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_143 (Dense)               (None, 1)            130         concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 2)            0           dense_141[0][0]                  \n",
      "                                                                 dense_143[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_144 (Dense)               (None, 1)            3           concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 1)            0           dense_144[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 55s 46ms/step - loss: 0.2710 - accuracy: 0.9055 - auc: 0.7599 - val_loss: 0.2121 - val_accuracy: 0.9144 - val_auc: 0.8843\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91441, saving model to model/Ensemble/CV_2/model_4.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 54s 45ms/step - loss: 0.2164 - accuracy: 0.9131 - auc: 0.8760 - val_loss: 0.2052 - val_accuracy: 0.9158 - val_auc: 0.8935\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91441 to 0.91582, saving model to model/Ensemble/CV_2/model_4.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2121 - accuracy: 0.9144 - auc: 0.8822 - val_loss: 0.2020 - val_accuracy: 0.9166 - val_auc: 0.8975\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91582 to 0.91664, saving model to model/Ensemble/CV_2/model_4.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 52s 44ms/step - loss: 0.2099 - accuracy: 0.9150 - auc: 0.8852 - val_loss: 0.2007 - val_accuracy: 0.9168 - val_auc: 0.8996\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91664 to 0.91679, saving model to model/Ensemble/CV_2/model_4.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 52s 44ms/step - loss: 0.2068 - accuracy: 0.9163 - auc: 0.8881 - val_loss: 0.1992 - val_accuracy: 0.9176 - val_auc: 0.9003\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91679 to 0.91759, saving model to model/Ensemble/CV_2/model_4.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 52s 44ms/step - loss: 0.2074 - accuracy: 0.9154 - auc: 0.8896 - val_loss: 0.1986 - val_accuracy: 0.9174 - val_auc: 0.9023\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91759\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 53s 45ms/step - loss: 0.2053 - accuracy: 0.9162 - auc: 0.8909 - val_loss: 0.1979 - val_accuracy: 0.9181 - val_auc: 0.9024\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91759 to 0.91805, saving model to model/Ensemble/CV_2/model_4.h5\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 53s 45ms/step - loss: 0.2048 - accuracy: 0.9167 - auc: 0.8921 - val_loss: 0.1987 - val_accuracy: 0.9172 - val_auc: 0.9029\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.91805\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2052 - accuracy: 0.9161 - auc: 0.8924 - val_loss: 0.1965 - val_accuracy: 0.9190 - val_auc: 0.9036\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91805 to 0.91896, saving model to model/Ensemble/CV_2/model_4.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 52s 44ms/step - loss: 0.2058 - accuracy: 0.9162 - auc: 0.8915 - val_loss: 0.1968 - val_accuracy: 0.9181 - val_auc: 0.9043\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91896\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 53s 45ms/step - loss: 0.2035 - accuracy: 0.9170 - auc: 0.8940 - val_loss: 0.1965 - val_accuracy: 0.9188 - val_auc: 0.9048\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91896\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 53s 45ms/step - loss: 0.2028 - accuracy: 0.9169 - auc: 0.8936 - val_loss: 0.1964 - val_accuracy: 0.9181 - val_auc: 0.9045\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91896\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 52s 44ms/step - loss: 0.2039 - accuracy: 0.9169 - auc: 0.8932 - val_loss: 0.1965 - val_accuracy: 0.9177 - val_auc: 0.9052\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91896\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 56s 47ms/step - loss: 0.2026 - accuracy: 0.9176 - auc: 0.8944 - val_loss: 0.1965 - val_accuracy: 0.9177 - val_auc: 0.9051\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91896\n",
      "Epoch 00014: early stopping\n",
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 15, 128)      0           max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)           (None, 17, 128)      0           max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_60 (Flatten)            (None, 1920)         0           dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_61 (Flatten)            (None, 2176)         0           dropout_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_60 (Attention)        (None, 143)          33281       dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 1920)         0           flatten_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_61 (Attention)        (None, 145)          33281       dropout_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)           (None, 2176)         0           flatten_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_60 (attention (None, 128)          0           attention_60[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_150 (Dense)               (None, 1)            1921        dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_61 (attention (None, 128)          0           attention_61[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_152 (Dense)               (None, 1)            2177        dropout_123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 129)          0           attention_flatten_60[0][0]       \n",
      "                                                                 dense_150[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 129)          0           attention_flatten_61[0][0]       \n",
      "                                                                 dense_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_151 (Dense)               (None, 1)            130         concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_153 (Dense)               (None, 1)            130         concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 2)            0           dense_151[0][0]                  \n",
      "                                                                 dense_153[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_154 (Dense)               (None, 1)            3           concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 1)            0           dense_154[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 53s 42ms/step - loss: 0.2696 - accuracy: 0.9008 - auc: 0.7671 - val_loss: 0.2127 - val_accuracy: 0.9147 - val_auc: 0.8825\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91467, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2175 - accuracy: 0.9128 - auc: 0.8762 - val_loss: 0.2070 - val_accuracy: 0.9156 - val_auc: 0.8906\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91467 to 0.91563, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2095 - accuracy: 0.9154 - auc: 0.8845 - val_loss: 0.2038 - val_accuracy: 0.9167 - val_auc: 0.8941\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91563 to 0.91670, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2088 - accuracy: 0.9154 - auc: 0.8874 - val_loss: 0.2038 - val_accuracy: 0.9161 - val_auc: 0.8959\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.91670\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 47s 39ms/step - loss: 0.2065 - accuracy: 0.9163 - auc: 0.8897 - val_loss: 0.2013 - val_accuracy: 0.9176 - val_auc: 0.8969\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91670 to 0.91765, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2052 - accuracy: 0.9168 - auc: 0.8908 - val_loss: 0.2009 - val_accuracy: 0.9177 - val_auc: 0.8979\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.91765 to 0.91770, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2054 - accuracy: 0.9166 - auc: 0.8918 - val_loss: 0.2013 - val_accuracy: 0.9175 - val_auc: 0.8981\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91770\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2048 - accuracy: 0.9167 - auc: 0.8928 - val_loss: 0.1995 - val_accuracy: 0.9180 - val_auc: 0.8996\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91770 to 0.91795, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 47s 39ms/step - loss: 0.2041 - accuracy: 0.9167 - auc: 0.8938 - val_loss: 0.1992 - val_accuracy: 0.9181 - val_auc: 0.9000\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91795 to 0.91807, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2022 - accuracy: 0.9174 - auc: 0.8954 - val_loss: 0.1989 - val_accuracy: 0.9181 - val_auc: 0.9007\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.91807 to 0.91813, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2005 - accuracy: 0.9184 - auc: 0.8972 - val_loss: 0.1980 - val_accuracy: 0.9190 - val_auc: 0.9017\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91813 to 0.91902, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2014 - accuracy: 0.9179 - auc: 0.8966 - val_loss: 0.1991 - val_accuracy: 0.9179 - val_auc: 0.9013\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91902\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2011 - accuracy: 0.9181 - auc: 0.8970 - val_loss: 0.1980 - val_accuracy: 0.9188 - val_auc: 0.9021\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91902\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2013 - accuracy: 0.9178 - auc: 0.8963 - val_loss: 0.1973 - val_accuracy: 0.9190 - val_auc: 0.9022\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91902\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2008 - accuracy: 0.9180 - auc: 0.8975 - val_loss: 0.1971 - val_accuracy: 0.9196 - val_auc: 0.9020\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.91902 to 0.91958, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2003 - accuracy: 0.9180 - auc: 0.8986 - val_loss: 0.1965 - val_accuracy: 0.9192 - val_auc: 0.9027\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.91958\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2014 - accuracy: 0.9179 - auc: 0.8979 - val_loss: 0.1964 - val_accuracy: 0.9195 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91958\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2001 - accuracy: 0.9184 - auc: 0.8986 - val_loss: 0.1967 - val_accuracy: 0.9190 - val_auc: 0.9028\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.91958\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 47s 39ms/step - loss: 0.1990 - accuracy: 0.9183 - auc: 0.8999 - val_loss: 0.1962 - val_accuracy: 0.9199 - val_auc: 0.9028\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.91958 to 0.91991, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1986 - accuracy: 0.9189 - auc: 0.8998 - val_loss: 0.1960 - val_accuracy: 0.9198 - val_auc: 0.9032\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.91991\n",
      "Epoch 21/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1990 - accuracy: 0.9186 - auc: 0.8998 - val_loss: 0.1957 - val_accuracy: 0.9196 - val_auc: 0.9035\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.91991\n",
      "Epoch 22/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1988 - accuracy: 0.9185 - auc: 0.9002 - val_loss: 0.1954 - val_accuracy: 0.9201 - val_auc: 0.9043\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.91991 to 0.92005, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 23/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1975 - accuracy: 0.9194 - auc: 0.9006 - val_loss: 0.1954 - val_accuracy: 0.9196 - val_auc: 0.9040\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.92005\n",
      "Epoch 24/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.1981 - accuracy: 0.9188 - auc: 0.9005 - val_loss: 0.1950 - val_accuracy: 0.9201 - val_auc: 0.9045\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.92005 to 0.92009, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 25/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1977 - accuracy: 0.9191 - auc: 0.9013 - val_loss: 0.1954 - val_accuracy: 0.9195 - val_auc: 0.9046\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.92009\n",
      "Epoch 26/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1969 - accuracy: 0.9193 - auc: 0.9022 - val_loss: 0.1947 - val_accuracy: 0.9202 - val_auc: 0.9046\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.92009 to 0.92025, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 27/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.1977 - accuracy: 0.9190 - auc: 0.9020 - val_loss: 0.1965 - val_accuracy: 0.9192 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.92025\n",
      "Epoch 28/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.1975 - accuracy: 0.9190 - auc: 0.9015 - val_loss: 0.1952 - val_accuracy: 0.9194 - val_auc: 0.9044\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.92025\n",
      "Epoch 29/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.1976 - accuracy: 0.9192 - auc: 0.9012 - val_loss: 0.1947 - val_accuracy: 0.9199 - val_auc: 0.9051\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.92025\n",
      "Epoch 30/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.1967 - accuracy: 0.9194 - auc: 0.9019 - val_loss: 0.1945 - val_accuracy: 0.9207 - val_auc: 0.9050\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.92025 to 0.92067, saving model to model/Ensemble/CV_3/model_0.h5\n",
      "Epoch 31/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.1971 - accuracy: 0.9191 - auc: 0.9025 - val_loss: 0.1956 - val_accuracy: 0.9200 - val_auc: 0.9059\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.92067\n",
      "Epoch 32/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.1955 - accuracy: 0.9201 - auc: 0.9029 - val_loss: 0.1950 - val_accuracy: 0.9199 - val_auc: 0.9053\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.92067\n",
      "Epoch 33/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.1965 - accuracy: 0.9194 - auc: 0.9032 - val_loss: 0.1939 - val_accuracy: 0.9205 - val_auc: 0.9058\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.92067\n",
      "Epoch 34/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1956 - accuracy: 0.9200 - auc: 0.9031 - val_loss: 0.1936 - val_accuracy: 0.9205 - val_auc: 0.9059\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.92067\n",
      "Epoch 35/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1964 - accuracy: 0.9195 - auc: 0.9038 - val_loss: 0.1942 - val_accuracy: 0.9205 - val_auc: 0.9054\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.92067\n",
      "Epoch 00035: early stopping\n",
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_128 (Dropout)           (None, 15, 128)      0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_130 (Dropout)           (None, 17, 128)      0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_64 (Flatten)            (None, 1920)         0           dropout_128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_65 (Flatten)            (None, 2176)         0           dropout_130[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_64 (Attention)        (None, 143)          33281       dropout_128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)           (None, 1920)         0           flatten_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_65 (Attention)        (None, 145)          33281       dropout_130[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)           (None, 2176)         0           flatten_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_64 (attention (None, 128)          0           attention_64[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_160 (Dense)               (None, 1)            1921        dropout_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_65 (attention (None, 128)          0           attention_65[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_162 (Dense)               (None, 1)            2177        dropout_131[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 129)          0           attention_flatten_64[0][0]       \n",
      "                                                                 dense_160[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 129)          0           attention_flatten_65[0][0]       \n",
      "                                                                 dense_162[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_161 (Dense)               (None, 1)            130         concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_163 (Dense)               (None, 1)            130         concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 2)            0           dense_161[0][0]                  \n",
      "                                                                 dense_163[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_164 (Dense)               (None, 1)            3           concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 1)            0           dense_164[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 50s 41ms/step - loss: 0.2806 - accuracy: 0.9090 - auc: 0.7383 - val_loss: 0.2160 - val_accuracy: 0.9141 - val_auc: 0.8789\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91414, saving model to model/Ensemble/CV_3/model_1.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2184 - accuracy: 0.9134 - auc: 0.8716 - val_loss: 0.2062 - val_accuracy: 0.9155 - val_auc: 0.8921\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91414 to 0.91552, saving model to model/Ensemble/CV_3/model_1.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 52s 44ms/step - loss: 0.2117 - accuracy: 0.9148 - auc: 0.8823 - val_loss: 0.2027 - val_accuracy: 0.9168 - val_auc: 0.8962\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91552 to 0.91680, saving model to model/Ensemble/CV_3/model_1.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 52s 44ms/step - loss: 0.2089 - accuracy: 0.9153 - auc: 0.8857 - val_loss: 0.2026 - val_accuracy: 0.9180 - val_auc: 0.8987\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91680 to 0.91803, saving model to model/Ensemble/CV_3/model_1.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2079 - accuracy: 0.9152 - auc: 0.8890 - val_loss: 0.1999 - val_accuracy: 0.9173 - val_auc: 0.8998\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.91803\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2079 - accuracy: 0.9154 - auc: 0.8891 - val_loss: 0.1996 - val_accuracy: 0.9172 - val_auc: 0.9001\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91803\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2066 - accuracy: 0.9163 - auc: 0.8898 - val_loss: 0.1983 - val_accuracy: 0.9188 - val_auc: 0.9016\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91803 to 0.91883, saving model to model/Ensemble/CV_3/model_1.h5\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2051 - accuracy: 0.9167 - auc: 0.8915 - val_loss: 0.1979 - val_accuracy: 0.9181 - val_auc: 0.9019\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.91883\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2043 - accuracy: 0.9169 - auc: 0.8931 - val_loss: 0.1967 - val_accuracy: 0.9190 - val_auc: 0.9035\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91883 to 0.91902, saving model to model/Ensemble/CV_3/model_1.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2046 - accuracy: 0.9168 - auc: 0.8922 - val_loss: 0.1971 - val_accuracy: 0.9178 - val_auc: 0.9037\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91902\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2033 - accuracy: 0.9171 - auc: 0.8936 - val_loss: 0.1973 - val_accuracy: 0.9182 - val_auc: 0.9027\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91902\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2036 - accuracy: 0.9168 - auc: 0.8944 - val_loss: 0.1967 - val_accuracy: 0.9183 - val_auc: 0.9035\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91902\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2017 - accuracy: 0.9175 - auc: 0.8954 - val_loss: 0.1977 - val_accuracy: 0.9177 - val_auc: 0.9040\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91902\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2035 - accuracy: 0.9172 - auc: 0.8941 - val_loss: 0.1959 - val_accuracy: 0.9193 - val_auc: 0.9043\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.91902 to 0.91933, saving model to model/Ensemble/CV_3/model_1.h5\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2032 - accuracy: 0.9172 - auc: 0.8951 - val_loss: 0.1959 - val_accuracy: 0.9180 - val_auc: 0.9051\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.91933\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2022 - accuracy: 0.9174 - auc: 0.8958 - val_loss: 0.1958 - val_accuracy: 0.9183 - val_auc: 0.9046\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.91933\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2027 - accuracy: 0.9171 - auc: 0.8959 - val_loss: 0.1957 - val_accuracy: 0.9188 - val_auc: 0.9051\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91933\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2022 - accuracy: 0.9170 - auc: 0.8968 - val_loss: 0.1942 - val_accuracy: 0.9197 - val_auc: 0.9069\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.91933 to 0.91972, saving model to model/Ensemble/CV_3/model_1.h5\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2009 - accuracy: 0.9185 - auc: 0.8960 - val_loss: 0.1954 - val_accuracy: 0.9184 - val_auc: 0.9058\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.91972\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2015 - accuracy: 0.9180 - auc: 0.8961 - val_loss: 0.1941 - val_accuracy: 0.9198 - val_auc: 0.9062\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.91972 to 0.91979, saving model to model/Ensemble/CV_3/model_1.h5\n",
      "Epoch 21/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2014 - accuracy: 0.9181 - auc: 0.8971 - val_loss: 0.1942 - val_accuracy: 0.9198 - val_auc: 0.9062\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.91979 to 0.91984, saving model to model/Ensemble/CV_3/model_1.h5\n",
      "Epoch 22/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2018 - accuracy: 0.9177 - auc: 0.8965 - val_loss: 0.1942 - val_accuracy: 0.9194 - val_auc: 0.9065\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.91984\n",
      "Epoch 23/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2003 - accuracy: 0.9184 - auc: 0.8977 - val_loss: 0.1949 - val_accuracy: 0.9187 - val_auc: 0.9064\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.91984\n",
      "Epoch 24/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2014 - accuracy: 0.9179 - auc: 0.8977 - val_loss: 0.1939 - val_accuracy: 0.9196 - val_auc: 0.9068\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.91984\n",
      "Epoch 25/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2008 - accuracy: 0.9179 - auc: 0.8976 - val_loss: 0.1937 - val_accuracy: 0.9198 - val_auc: 0.9072\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.91984\n",
      "Epoch 26/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.1999 - accuracy: 0.9185 - auc: 0.8980 - val_loss: 0.1934 - val_accuracy: 0.9192 - val_auc: 0.9075\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.91984\n",
      "Epoch 00026: early stopping\n",
      "Model: \"model_34\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)           (None, 15, 128)      0           max_pooling1d_68[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_138 (Dropout)           (None, 17, 128)      0           max_pooling1d_69[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_68 (Flatten)            (None, 1920)         0           dropout_136[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_69 (Flatten)            (None, 2176)         0           dropout_138[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_68 (Attention)        (None, 143)          33281       dropout_136[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_137 (Dropout)           (None, 1920)         0           flatten_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_69 (Attention)        (None, 145)          33281       dropout_138[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)           (None, 2176)         0           flatten_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_68 (attention (None, 128)          0           attention_68[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_170 (Dense)               (None, 1)            1921        dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_69 (attention (None, 128)          0           attention_69[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_172 (Dense)               (None, 1)            2177        dropout_139[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 129)          0           attention_flatten_68[0][0]       \n",
      "                                                                 dense_170[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 129)          0           attention_flatten_69[0][0]       \n",
      "                                                                 dense_172[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_171 (Dense)               (None, 1)            130         concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_173 (Dense)               (None, 1)            130         concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 2)            0           dense_171[0][0]                  \n",
      "                                                                 dense_173[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_174 (Dense)               (None, 1)            3           concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 1)            0           dense_174[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 52s 43ms/step - loss: 0.2690 - accuracy: 0.9074 - auc: 0.7667 - val_loss: 0.2104 - val_accuracy: 0.9153 - val_auc: 0.8854\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91529, saving model to model/Ensemble/CV_3/model_2.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2166 - accuracy: 0.9136 - auc: 0.8754 - val_loss: 0.2042 - val_accuracy: 0.9164 - val_auc: 0.8951\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91529 to 0.91643, saving model to model/Ensemble/CV_3/model_2.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2114 - accuracy: 0.9145 - auc: 0.8836 - val_loss: 0.2013 - val_accuracy: 0.9169 - val_auc: 0.8989\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91643 to 0.91689, saving model to model/Ensemble/CV_3/model_2.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2098 - accuracy: 0.9152 - auc: 0.8863 - val_loss: 0.2002 - val_accuracy: 0.9177 - val_auc: 0.9001\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91689 to 0.91768, saving model to model/Ensemble/CV_3/model_2.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2060 - accuracy: 0.9162 - auc: 0.8894 - val_loss: 0.1986 - val_accuracy: 0.9186 - val_auc: 0.9014\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91768 to 0.91861, saving model to model/Ensemble/CV_3/model_2.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2056 - accuracy: 0.9165 - auc: 0.8911 - val_loss: 0.1982 - val_accuracy: 0.9184 - val_auc: 0.9022\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91861\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2042 - accuracy: 0.9170 - auc: 0.8918 - val_loss: 0.1978 - val_accuracy: 0.9185 - val_auc: 0.9031\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91861\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2041 - accuracy: 0.9169 - auc: 0.8930 - val_loss: 0.1962 - val_accuracy: 0.9195 - val_auc: 0.9040\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91861 to 0.91951, saving model to model/Ensemble/CV_3/model_2.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2041 - accuracy: 0.9172 - auc: 0.8933 - val_loss: 0.1965 - val_accuracy: 0.9199 - val_auc: 0.9038\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91951 to 0.91988, saving model to model/Ensemble/CV_3/model_2.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2031 - accuracy: 0.9168 - auc: 0.8947 - val_loss: 0.1964 - val_accuracy: 0.9188 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91988\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2036 - accuracy: 0.9165 - auc: 0.8944 - val_loss: 0.1962 - val_accuracy: 0.9188 - val_auc: 0.9048\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91988\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2006 - accuracy: 0.9185 - auc: 0.8962 - val_loss: 0.1959 - val_accuracy: 0.9189 - val_auc: 0.9053\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91988\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2033 - accuracy: 0.9170 - auc: 0.8948 - val_loss: 0.1970 - val_accuracy: 0.9181 - val_auc: 0.9051\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91988\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2014 - accuracy: 0.9180 - auc: 0.8961 - val_loss: 0.1948 - val_accuracy: 0.9198 - val_auc: 0.9055\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91988\n",
      "Epoch 00014: early stopping\n",
      "Model: \"model_36\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)           (None, 15, 128)      0           max_pooling1d_72[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_146 (Dropout)           (None, 17, 128)      0           max_pooling1d_73[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_72 (Flatten)            (None, 1920)         0           dropout_144[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_73 (Flatten)            (None, 2176)         0           dropout_146[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_72 (Attention)        (None, 143)          33281       dropout_144[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_145 (Dropout)           (None, 1920)         0           flatten_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_73 (Attention)        (None, 145)          33281       dropout_146[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_147 (Dropout)           (None, 2176)         0           flatten_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_72 (attention (None, 128)          0           attention_72[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_180 (Dense)               (None, 1)            1921        dropout_145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_73 (attention (None, 128)          0           attention_73[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_182 (Dense)               (None, 1)            2177        dropout_147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 129)          0           attention_flatten_72[0][0]       \n",
      "                                                                 dense_180[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 129)          0           attention_flatten_73[0][0]       \n",
      "                                                                 dense_182[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_181 (Dense)               (None, 1)            130         concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_183 (Dense)               (None, 1)            130         concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 2)            0           dense_181[0][0]                  \n",
      "                                                                 dense_183[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_184 (Dense)               (None, 1)            3           concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 1)            0           dense_184[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 54s 43ms/step - loss: 0.2665 - accuracy: 0.9045 - auc: 0.7719 - val_loss: 0.2115 - val_accuracy: 0.9138 - val_auc: 0.8859\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91381, saving model to model/Ensemble/CV_3/model_3.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2157 - accuracy: 0.9134 - auc: 0.8771 - val_loss: 0.2037 - val_accuracy: 0.9171 - val_auc: 0.8955\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91381 to 0.91714, saving model to model/Ensemble/CV_3/model_3.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2116 - accuracy: 0.9143 - auc: 0.8838 - val_loss: 0.2022 - val_accuracy: 0.9157 - val_auc: 0.8987\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.91714\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2092 - accuracy: 0.9150 - auc: 0.8864 - val_loss: 0.1997 - val_accuracy: 0.9173 - val_auc: 0.9001\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91714 to 0.91728, saving model to model/Ensemble/CV_3/model_3.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2072 - accuracy: 0.9161 - auc: 0.8886 - val_loss: 0.1987 - val_accuracy: 0.9177 - val_auc: 0.9019\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91728 to 0.91773, saving model to model/Ensemble/CV_3/model_3.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2067 - accuracy: 0.9161 - auc: 0.8903 - val_loss: 0.1979 - val_accuracy: 0.9177 - val_auc: 0.9026\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.91773 to 0.91774, saving model to model/Ensemble/CV_3/model_3.h5\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2057 - accuracy: 0.9165 - auc: 0.8906 - val_loss: 0.1984 - val_accuracy: 0.9172 - val_auc: 0.9031\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91774\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2044 - accuracy: 0.9168 - auc: 0.8928 - val_loss: 0.1968 - val_accuracy: 0.9185 - val_auc: 0.9043\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91774 to 0.91847, saving model to model/Ensemble/CV_3/model_3.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2038 - accuracy: 0.9168 - auc: 0.8931 - val_loss: 0.1966 - val_accuracy: 0.9191 - val_auc: 0.9044\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91847 to 0.91914, saving model to model/Ensemble/CV_3/model_3.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2044 - accuracy: 0.9166 - auc: 0.8934 - val_loss: 0.1953 - val_accuracy: 0.9193 - val_auc: 0.9052\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.91914 to 0.91929, saving model to model/Ensemble/CV_3/model_3.h5\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2025 - accuracy: 0.9174 - auc: 0.8953 - val_loss: 0.1951 - val_accuracy: 0.9198 - val_auc: 0.9049\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91929 to 0.91979, saving model to model/Ensemble/CV_3/model_3.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2025 - accuracy: 0.9174 - auc: 0.8957 - val_loss: 0.1961 - val_accuracy: 0.9183 - val_auc: 0.9055\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91979\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2030 - accuracy: 0.9174 - auc: 0.8947 - val_loss: 0.1948 - val_accuracy: 0.9189 - val_auc: 0.9064\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91979\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2011 - accuracy: 0.9176 - auc: 0.8969 - val_loss: 0.1953 - val_accuracy: 0.9185 - val_auc: 0.9066\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91979\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2014 - accuracy: 0.9180 - auc: 0.8970 - val_loss: 0.1941 - val_accuracy: 0.9209 - val_auc: 0.9067\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.91979 to 0.92094, saving model to model/Ensemble/CV_3/model_3.h5\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2010 - accuracy: 0.9177 - auc: 0.8972 - val_loss: 0.1938 - val_accuracy: 0.9201 - val_auc: 0.9071\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.92094\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.1989 - accuracy: 0.9188 - auc: 0.8985 - val_loss: 0.1934 - val_accuracy: 0.9204 - val_auc: 0.9076\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.92094\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2004 - accuracy: 0.9184 - auc: 0.8974 - val_loss: 0.1952 - val_accuracy: 0.9186 - val_auc: 0.9069\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.92094\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2002 - accuracy: 0.9175 - auc: 0.8987 - val_loss: 0.1935 - val_accuracy: 0.9195 - val_auc: 0.9082\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.92094\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1999 - accuracy: 0.9182 - auc: 0.8986 - val_loss: 0.1926 - val_accuracy: 0.9208 - val_auc: 0.9091\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.92094\n",
      "Epoch 00020: early stopping\n",
      "Model: \"model_38\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)           (None, 15, 128)      0           max_pooling1d_76[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_154 (Dropout)           (None, 17, 128)      0           max_pooling1d_77[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_76 (Flatten)            (None, 1920)         0           dropout_152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_77 (Flatten)            (None, 2176)         0           dropout_154[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_76 (Attention)        (None, 143)          33281       dropout_152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_153 (Dropout)           (None, 1920)         0           flatten_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_77 (Attention)        (None, 145)          33281       dropout_154[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_155 (Dropout)           (None, 2176)         0           flatten_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_76 (attention (None, 128)          0           attention_76[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_190 (Dense)               (None, 1)            1921        dropout_153[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_77 (attention (None, 128)          0           attention_77[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_192 (Dense)               (None, 1)            2177        dropout_155[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 129)          0           attention_flatten_76[0][0]       \n",
      "                                                                 dense_190[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 129)          0           attention_flatten_77[0][0]       \n",
      "                                                                 dense_192[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_191 (Dense)               (None, 1)            130         concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_193 (Dense)               (None, 1)            130         concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 2)            0           dense_191[0][0]                  \n",
      "                                                                 dense_193[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_194 (Dense)               (None, 1)            3           concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1)            0           dense_194[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 52s 43ms/step - loss: 0.2667 - accuracy: 0.9081 - auc: 0.7666 - val_loss: 0.2117 - val_accuracy: 0.9141 - val_auc: 0.8856\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91406, saving model to model/Ensemble/CV_3/model_4.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2163 - accuracy: 0.9134 - auc: 0.8760 - val_loss: 0.2043 - val_accuracy: 0.9168 - val_auc: 0.8950\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91406 to 0.91676, saving model to model/Ensemble/CV_3/model_4.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2115 - accuracy: 0.9146 - auc: 0.8830 - val_loss: 0.2018 - val_accuracy: 0.9170 - val_auc: 0.8983\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91676 to 0.91698, saving model to model/Ensemble/CV_3/model_4.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2094 - accuracy: 0.9149 - auc: 0.8863 - val_loss: 0.1999 - val_accuracy: 0.9174 - val_auc: 0.9003\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91698 to 0.91739, saving model to model/Ensemble/CV_3/model_4.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2064 - accuracy: 0.9165 - auc: 0.8888 - val_loss: 0.1986 - val_accuracy: 0.9185 - val_auc: 0.9010\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91739 to 0.91847, saving model to model/Ensemble/CV_3/model_4.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2071 - accuracy: 0.9160 - auc: 0.8899 - val_loss: 0.1983 - val_accuracy: 0.9180 - val_auc: 0.9027\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91847\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2048 - accuracy: 0.9167 - auc: 0.8916 - val_loss: 0.1971 - val_accuracy: 0.9193 - val_auc: 0.9034\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91847 to 0.91927, saving model to model/Ensemble/CV_3/model_4.h5\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2049 - accuracy: 0.9171 - auc: 0.8922 - val_loss: 0.1975 - val_accuracy: 0.9183 - val_auc: 0.9035\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.91927\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2048 - accuracy: 0.9167 - auc: 0.8924 - val_loss: 0.1958 - val_accuracy: 0.9194 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91927 to 0.91945, saving model to model/Ensemble/CV_3/model_4.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2055 - accuracy: 0.9166 - auc: 0.8918 - val_loss: 0.1966 - val_accuracy: 0.9186 - val_auc: 0.9041\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91945\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2032 - accuracy: 0.9174 - auc: 0.8942 - val_loss: 0.1954 - val_accuracy: 0.9198 - val_auc: 0.9057\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91945 to 0.91980, saving model to model/Ensemble/CV_3/model_4.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2018 - accuracy: 0.9177 - auc: 0.8951 - val_loss: 0.1956 - val_accuracy: 0.9192 - val_auc: 0.9054\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91980\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2029 - accuracy: 0.9181 - auc: 0.8941 - val_loss: 0.1951 - val_accuracy: 0.9190 - val_auc: 0.9059\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91980\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2018 - accuracy: 0.9183 - auc: 0.8952 - val_loss: 0.1948 - val_accuracy: 0.9188 - val_auc: 0.9064\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91980\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2026 - accuracy: 0.9177 - auc: 0.8948 - val_loss: 0.1947 - val_accuracy: 0.9199 - val_auc: 0.9057\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.91980 to 0.91986, saving model to model/Ensemble/CV_3/model_4.h5\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2025 - accuracy: 0.9175 - auc: 0.8961 - val_loss: 0.1945 - val_accuracy: 0.9205 - val_auc: 0.9069\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.91986 to 0.92048, saving model to model/Ensemble/CV_3/model_4.h5\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2019 - accuracy: 0.9181 - auc: 0.8966 - val_loss: 0.1950 - val_accuracy: 0.9191 - val_auc: 0.9069\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.92048\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2016 - accuracy: 0.9177 - auc: 0.8969 - val_loss: 0.1957 - val_accuracy: 0.9189 - val_auc: 0.9060\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.92048\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2018 - accuracy: 0.9177 - auc: 0.8971 - val_loss: 0.1936 - val_accuracy: 0.9198 - val_auc: 0.9079\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.92048\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2015 - accuracy: 0.9180 - auc: 0.8972 - val_loss: 0.1942 - val_accuracy: 0.9195 - val_auc: 0.9074\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.92048\n",
      "Epoch 21/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2010 - accuracy: 0.9177 - auc: 0.8975 - val_loss: 0.1928 - val_accuracy: 0.9207 - val_auc: 0.9086\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.92048 to 0.92070, saving model to model/Ensemble/CV_3/model_4.h5\n",
      "Epoch 22/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2005 - accuracy: 0.9182 - auc: 0.8981 - val_loss: 0.1939 - val_accuracy: 0.9198 - val_auc: 0.9078\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.92070\n",
      "Epoch 23/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2006 - accuracy: 0.9181 - auc: 0.8976 - val_loss: 0.1938 - val_accuracy: 0.9197 - val_auc: 0.9083\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.92070\n",
      "Epoch 24/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.1991 - accuracy: 0.9184 - auc: 0.8999 - val_loss: 0.1926 - val_accuracy: 0.9206 - val_auc: 0.9078\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.92070\n",
      "Epoch 25/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.1993 - accuracy: 0.9188 - auc: 0.8995 - val_loss: 0.1925 - val_accuracy: 0.9205 - val_auc: 0.9089\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.92070\n",
      "Epoch 26/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.1983 - accuracy: 0.9186 - auc: 0.8997 - val_loss: 0.1922 - val_accuracy: 0.9204 - val_auc: 0.9089\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.92070\n",
      "Epoch 00026: early stopping\n",
      "Model: \"model_40\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)           (None, 15, 128)      0           max_pooling1d_80[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_162 (Dropout)           (None, 17, 128)      0           max_pooling1d_81[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_80 (Flatten)            (None, 1920)         0           dropout_160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_81 (Flatten)            (None, 2176)         0           dropout_162[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_80 (Attention)        (None, 143)          33281       dropout_160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_161 (Dropout)           (None, 1920)         0           flatten_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_81 (Attention)        (None, 145)          33281       dropout_162[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_163 (Dropout)           (None, 2176)         0           flatten_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_80 (attention (None, 128)          0           attention_80[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_200 (Dense)               (None, 1)            1921        dropout_161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_81 (attention (None, 128)          0           attention_81[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_202 (Dense)               (None, 1)            2177        dropout_163[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 129)          0           attention_flatten_80[0][0]       \n",
      "                                                                 dense_200[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 129)          0           attention_flatten_81[0][0]       \n",
      "                                                                 dense_202[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_201 (Dense)               (None, 1)            130         concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_203 (Dense)               (None, 1)            130         concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 2)            0           dense_201[0][0]                  \n",
      "                                                                 dense_203[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_204 (Dense)               (None, 1)            3           concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 1)            0           dense_204[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 49s 40ms/step - loss: 0.2694 - accuracy: 0.9010 - auc: 0.7678 - val_loss: 0.2147 - val_accuracy: 0.9140 - val_auc: 0.8789\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91398, saving model to model/Ensemble/CV_4/model_0.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2182 - accuracy: 0.9124 - auc: 0.8751 - val_loss: 0.2076 - val_accuracy: 0.9156 - val_auc: 0.8890\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91398 to 0.91558, saving model to model/Ensemble/CV_4/model_0.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2093 - accuracy: 0.9155 - auc: 0.8842 - val_loss: 0.2043 - val_accuracy: 0.9168 - val_auc: 0.8932\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91558 to 0.91683, saving model to model/Ensemble/CV_4/model_0.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2089 - accuracy: 0.9149 - auc: 0.8872 - val_loss: 0.2041 - val_accuracy: 0.9161 - val_auc: 0.8952\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.91683\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2071 - accuracy: 0.9157 - auc: 0.8889 - val_loss: 0.2018 - val_accuracy: 0.9177 - val_auc: 0.8962\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91683 to 0.91775, saving model to model/Ensemble/CV_4/model_0.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 47s 39ms/step - loss: 0.2056 - accuracy: 0.9162 - auc: 0.8900 - val_loss: 0.2015 - val_accuracy: 0.9172 - val_auc: 0.8979\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91775\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2055 - accuracy: 0.9162 - auc: 0.8919 - val_loss: 0.2017 - val_accuracy: 0.9168 - val_auc: 0.8982\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91775\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2046 - accuracy: 0.9166 - auc: 0.8932 - val_loss: 0.1994 - val_accuracy: 0.9182 - val_auc: 0.8995\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91775 to 0.91817, saving model to model/Ensemble/CV_4/model_0.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2043 - accuracy: 0.9164 - auc: 0.8937 - val_loss: 0.1998 - val_accuracy: 0.9175 - val_auc: 0.8997\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.91817\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2031 - accuracy: 0.9175 - auc: 0.8940 - val_loss: 0.1990 - val_accuracy: 0.9178 - val_auc: 0.9005\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91817\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2014 - accuracy: 0.9179 - auc: 0.8960 - val_loss: 0.1984 - val_accuracy: 0.9187 - val_auc: 0.9015\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91817 to 0.91874, saving model to model/Ensemble/CV_4/model_0.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2029 - accuracy: 0.9171 - auc: 0.8945 - val_loss: 0.1992 - val_accuracy: 0.9177 - val_auc: 0.9013\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91874\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2031 - accuracy: 0.9174 - auc: 0.8942 - val_loss: 0.1983 - val_accuracy: 0.9181 - val_auc: 0.9016\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91874\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2023 - accuracy: 0.9173 - auc: 0.8949 - val_loss: 0.1973 - val_accuracy: 0.9186 - val_auc: 0.9024\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91874\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2020 - accuracy: 0.9177 - auc: 0.8957 - val_loss: 0.1977 - val_accuracy: 0.9187 - val_auc: 0.9020\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.91874\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2016 - accuracy: 0.9177 - auc: 0.8971 - val_loss: 0.1970 - val_accuracy: 0.9192 - val_auc: 0.9027\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.91874 to 0.91918, saving model to model/Ensemble/CV_4/model_0.h5\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2030 - accuracy: 0.9174 - auc: 0.8957 - val_loss: 0.1969 - val_accuracy: 0.9190 - val_auc: 0.9026\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91918\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2020 - accuracy: 0.9175 - auc: 0.8960 - val_loss: 0.1970 - val_accuracy: 0.9186 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.91918\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2003 - accuracy: 0.9183 - auc: 0.8978 - val_loss: 0.1964 - val_accuracy: 0.9195 - val_auc: 0.9032\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.91918 to 0.91949, saving model to model/Ensemble/CV_4/model_0.h5\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2003 - accuracy: 0.9180 - auc: 0.8974 - val_loss: 0.1962 - val_accuracy: 0.9196 - val_auc: 0.9031\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.91949 to 0.91958, saving model to model/Ensemble/CV_4/model_0.h5\n",
      "Epoch 21/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2003 - accuracy: 0.9180 - auc: 0.8979 - val_loss: 0.1962 - val_accuracy: 0.9192 - val_auc: 0.9034\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.91958\n",
      "Epoch 22/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2006 - accuracy: 0.9181 - auc: 0.8978 - val_loss: 0.1963 - val_accuracy: 0.9193 - val_auc: 0.9038\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.91958\n",
      "Epoch 23/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1991 - accuracy: 0.9190 - auc: 0.8986 - val_loss: 0.1960 - val_accuracy: 0.9191 - val_auc: 0.9040\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.91958\n",
      "Epoch 24/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.1996 - accuracy: 0.9184 - auc: 0.8985 - val_loss: 0.1954 - val_accuracy: 0.9200 - val_auc: 0.9040\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.91958 to 0.92002, saving model to model/Ensemble/CV_4/model_0.h5\n",
      "Epoch 25/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.1994 - accuracy: 0.9181 - auc: 0.8992 - val_loss: 0.1962 - val_accuracy: 0.9189 - val_auc: 0.9043\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.92002\n",
      "Epoch 26/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1995 - accuracy: 0.9182 - auc: 0.8990 - val_loss: 0.1953 - val_accuracy: 0.9197 - val_auc: 0.9043\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.92002\n",
      "Epoch 27/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2001 - accuracy: 0.9183 - auc: 0.8988 - val_loss: 0.1958 - val_accuracy: 0.9191 - val_auc: 0.9038\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.92002\n",
      "Epoch 28/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.1995 - accuracy: 0.9185 - auc: 0.8986 - val_loss: 0.1955 - val_accuracy: 0.9193 - val_auc: 0.9046\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.92002\n",
      "Epoch 29/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.1994 - accuracy: 0.9185 - auc: 0.8988 - val_loss: 0.1957 - val_accuracy: 0.9190 - val_auc: 0.9045\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.92002\n",
      "Epoch 00029: early stopping\n",
      "Model: \"model_42\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_168 (Dropout)           (None, 15, 128)      0           max_pooling1d_84[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_170 (Dropout)           (None, 17, 128)      0           max_pooling1d_85[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_84 (Flatten)            (None, 1920)         0           dropout_168[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_85 (Flatten)            (None, 2176)         0           dropout_170[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_84 (Attention)        (None, 143)          33281       dropout_168[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_169 (Dropout)           (None, 1920)         0           flatten_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_85 (Attention)        (None, 145)          33281       dropout_170[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_171 (Dropout)           (None, 2176)         0           flatten_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_84 (attention (None, 128)          0           attention_84[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_210 (Dense)               (None, 1)            1921        dropout_169[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_85 (attention (None, 128)          0           attention_85[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_212 (Dense)               (None, 1)            2177        dropout_171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 129)          0           attention_flatten_84[0][0]       \n",
      "                                                                 dense_210[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 129)          0           attention_flatten_85[0][0]       \n",
      "                                                                 dense_212[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_211 (Dense)               (None, 1)            130         concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_213 (Dense)               (None, 1)            130         concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 2)            0           dense_211[0][0]                  \n",
      "                                                                 dense_213[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_214 (Dense)               (None, 1)            3           concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1)            0           dense_214[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 52s 41ms/step - loss: 0.2576 - accuracy: 0.9086 - auc: 0.7884 - val_loss: 0.2098 - val_accuracy: 0.9149 - val_auc: 0.8867\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91492, saving model to model/Ensemble/CV_4/model_1.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2148 - accuracy: 0.9140 - auc: 0.8776 - val_loss: 0.2043 - val_accuracy: 0.9162 - val_auc: 0.8948\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91492 to 0.91615, saving model to model/Ensemble/CV_4/model_1.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2097 - accuracy: 0.9153 - auc: 0.8852 - val_loss: 0.2025 - val_accuracy: 0.9160 - val_auc: 0.8977\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.91615\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2083 - accuracy: 0.9158 - auc: 0.8865 - val_loss: 0.2014 - val_accuracy: 0.9180 - val_auc: 0.9003\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91615 to 0.91795, saving model to model/Ensemble/CV_4/model_1.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2069 - accuracy: 0.9156 - auc: 0.8905 - val_loss: 0.1996 - val_accuracy: 0.9172 - val_auc: 0.9007\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.91795\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2073 - accuracy: 0.9153 - auc: 0.8899 - val_loss: 0.1993 - val_accuracy: 0.9170 - val_auc: 0.9014\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91795\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2056 - accuracy: 0.9161 - auc: 0.8912 - val_loss: 0.1975 - val_accuracy: 0.9185 - val_auc: 0.9024\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91795 to 0.91848, saving model to model/Ensemble/CV_4/model_1.h5\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2046 - accuracy: 0.9167 - auc: 0.8925 - val_loss: 0.1969 - val_accuracy: 0.9184 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.91848\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2045 - accuracy: 0.9164 - auc: 0.8931 - val_loss: 0.1966 - val_accuracy: 0.9188 - val_auc: 0.9036\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91848 to 0.91884, saving model to model/Ensemble/CV_4/model_1.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2040 - accuracy: 0.9170 - auc: 0.8932 - val_loss: 0.1968 - val_accuracy: 0.9185 - val_auc: 0.9037\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91884\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2025 - accuracy: 0.9176 - auc: 0.8946 - val_loss: 0.1973 - val_accuracy: 0.9180 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91884\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2030 - accuracy: 0.9169 - auc: 0.8949 - val_loss: 0.1967 - val_accuracy: 0.9183 - val_auc: 0.9039\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91884\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2017 - accuracy: 0.9171 - auc: 0.8955 - val_loss: 0.1984 - val_accuracy: 0.9176 - val_auc: 0.9038\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91884\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2030 - accuracy: 0.9174 - auc: 0.8948 - val_loss: 0.1958 - val_accuracy: 0.9187 - val_auc: 0.9051\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91884\n",
      "Epoch 00014: early stopping\n",
      "Model: \"model_44\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_176 (Dropout)           (None, 15, 128)      0           max_pooling1d_88[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_178 (Dropout)           (None, 17, 128)      0           max_pooling1d_89[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_88 (Flatten)            (None, 1920)         0           dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_89 (Flatten)            (None, 2176)         0           dropout_178[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_88 (Attention)        (None, 143)          33281       dropout_176[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_177 (Dropout)           (None, 1920)         0           flatten_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_89 (Attention)        (None, 145)          33281       dropout_178[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_179 (Dropout)           (None, 2176)         0           flatten_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_88 (attention (None, 128)          0           attention_88[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_220 (Dense)               (None, 1)            1921        dropout_177[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_89 (attention (None, 128)          0           attention_89[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_222 (Dense)               (None, 1)            2177        dropout_179[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 129)          0           attention_flatten_88[0][0]       \n",
      "                                                                 dense_220[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 129)          0           attention_flatten_89[0][0]       \n",
      "                                                                 dense_222[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_221 (Dense)               (None, 1)            130         concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_223 (Dense)               (None, 1)            130         concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 2)            0           dense_221[0][0]                  \n",
      "                                                                 dense_223[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_224 (Dense)               (None, 1)            3           concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 1)            0           dense_224[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2736 - accuracy: 0.9074 - auc: 0.7484 - val_loss: 0.2134 - val_accuracy: 0.9141 - val_auc: 0.8814\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91415, saving model to model/Ensemble/CV_4/model_2.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2182 - accuracy: 0.9134 - auc: 0.8728 - val_loss: 0.2049 - val_accuracy: 0.9161 - val_auc: 0.8942\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91415 to 0.91609, saving model to model/Ensemble/CV_4/model_2.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2125 - accuracy: 0.9139 - auc: 0.8823 - val_loss: 0.2026 - val_accuracy: 0.9161 - val_auc: 0.8982\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.91609\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2110 - accuracy: 0.9146 - auc: 0.8847 - val_loss: 0.2007 - val_accuracy: 0.9174 - val_auc: 0.8990\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91609 to 0.91744, saving model to model/Ensemble/CV_4/model_2.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2062 - accuracy: 0.9164 - auc: 0.8888 - val_loss: 0.1992 - val_accuracy: 0.9180 - val_auc: 0.9011\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91744 to 0.91800, saving model to model/Ensemble/CV_4/model_2.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2066 - accuracy: 0.9160 - auc: 0.8897 - val_loss: 0.1984 - val_accuracy: 0.9189 - val_auc: 0.9021\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.91800 to 0.91890, saving model to model/Ensemble/CV_4/model_2.h5\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2048 - accuracy: 0.9167 - auc: 0.8911 - val_loss: 0.1976 - val_accuracy: 0.9187 - val_auc: 0.9029\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91890\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2048 - accuracy: 0.9166 - auc: 0.8920 - val_loss: 0.1968 - val_accuracy: 0.9193 - val_auc: 0.9034\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91890 to 0.91930, saving model to model/Ensemble/CV_4/model_2.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2050 - accuracy: 0.9163 - auc: 0.8924 - val_loss: 0.1966 - val_accuracy: 0.9193 - val_auc: 0.9038\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.91930\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2041 - accuracy: 0.9165 - auc: 0.8932 - val_loss: 0.1973 - val_accuracy: 0.9183 - val_auc: 0.9034\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91930\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 47s 39ms/step - loss: 0.2047 - accuracy: 0.9165 - auc: 0.8929 - val_loss: 0.1972 - val_accuracy: 0.9181 - val_auc: 0.9047\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91930\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2022 - accuracy: 0.9178 - auc: 0.8943 - val_loss: 0.1963 - val_accuracy: 0.9185 - val_auc: 0.9047\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91930\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2046 - accuracy: 0.9168 - auc: 0.8931 - val_loss: 0.1973 - val_accuracy: 0.9177 - val_auc: 0.9051\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91930\n",
      "Epoch 00013: early stopping\n",
      "Model: \"model_46\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_184 (Dropout)           (None, 15, 128)      0           max_pooling1d_92[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_186 (Dropout)           (None, 17, 128)      0           max_pooling1d_93[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_92 (Flatten)            (None, 1920)         0           dropout_184[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_93 (Flatten)            (None, 2176)         0           dropout_186[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_92 (Attention)        (None, 143)          33281       dropout_184[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_185 (Dropout)           (None, 1920)         0           flatten_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_93 (Attention)        (None, 145)          33281       dropout_186[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_187 (Dropout)           (None, 2176)         0           flatten_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_92 (attention (None, 128)          0           attention_92[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_230 (Dense)               (None, 1)            1921        dropout_185[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_93 (attention (None, 128)          0           attention_93[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_232 (Dense)               (None, 1)            2177        dropout_187[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 129)          0           attention_flatten_92[0][0]       \n",
      "                                                                 dense_230[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 129)          0           attention_flatten_93[0][0]       \n",
      "                                                                 dense_232[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_231 (Dense)               (None, 1)            130         concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_233 (Dense)               (None, 1)            130         concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 2)            0           dense_231[0][0]                  \n",
      "                                                                 dense_233[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_234 (Dense)               (None, 1)            3           concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 1)            0           dense_234[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2902 - accuracy: 0.9063 - auc: 0.7253 - val_loss: 0.2165 - val_accuracy: 0.9133 - val_auc: 0.8779\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91331, saving model to model/Ensemble/CV_4/model_3.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2194 - accuracy: 0.9130 - auc: 0.8709 - val_loss: 0.2056 - val_accuracy: 0.9162 - val_auc: 0.8928\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91331 to 0.91619, saving model to model/Ensemble/CV_4/model_3.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2133 - accuracy: 0.9144 - auc: 0.8813 - val_loss: 0.2035 - val_accuracy: 0.9154 - val_auc: 0.8968\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.91619\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2105 - accuracy: 0.9147 - auc: 0.8848 - val_loss: 0.2012 - val_accuracy: 0.9172 - val_auc: 0.8982\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91619 to 0.91721, saving model to model/Ensemble/CV_4/model_3.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2087 - accuracy: 0.9157 - auc: 0.8865 - val_loss: 0.2002 - val_accuracy: 0.9169 - val_auc: 0.9002\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.91721\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2087 - accuracy: 0.9155 - auc: 0.8873 - val_loss: 0.1988 - val_accuracy: 0.9173 - val_auc: 0.9016\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.91721 to 0.91733, saving model to model/Ensemble/CV_4/model_3.h5\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2068 - accuracy: 0.9162 - auc: 0.8889 - val_loss: 0.1986 - val_accuracy: 0.9170 - val_auc: 0.9019\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91733\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2060 - accuracy: 0.9162 - auc: 0.8906 - val_loss: 0.1968 - val_accuracy: 0.9186 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91733 to 0.91859, saving model to model/Ensemble/CV_4/model_3.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2055 - accuracy: 0.9165 - auc: 0.8909 - val_loss: 0.1971 - val_accuracy: 0.9191 - val_auc: 0.9036\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91859 to 0.91906, saving model to model/Ensemble/CV_4/model_3.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2060 - accuracy: 0.9161 - auc: 0.8910 - val_loss: 0.1963 - val_accuracy: 0.9196 - val_auc: 0.9039\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.91906 to 0.91958, saving model to model/Ensemble/CV_4/model_3.h5\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2043 - accuracy: 0.9167 - auc: 0.8927 - val_loss: 0.1964 - val_accuracy: 0.9190 - val_auc: 0.9041\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91958\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2048 - accuracy: 0.9167 - auc: 0.8925 - val_loss: 0.1965 - val_accuracy: 0.9183 - val_auc: 0.9044\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91958\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2047 - accuracy: 0.9167 - auc: 0.8927 - val_loss: 0.1959 - val_accuracy: 0.9180 - val_auc: 0.9054\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91958\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2039 - accuracy: 0.9173 - auc: 0.8930 - val_loss: 0.1960 - val_accuracy: 0.9177 - val_auc: 0.9058\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91958\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2041 - accuracy: 0.9169 - auc: 0.8937 - val_loss: 0.1953 - val_accuracy: 0.9197 - val_auc: 0.9050\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.91958 to 0.91974, saving model to model/Ensemble/CV_4/model_3.h5\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2033 - accuracy: 0.9172 - auc: 0.8942 - val_loss: 0.1952 - val_accuracy: 0.9187 - val_auc: 0.9060\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.91974\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2018 - accuracy: 0.9181 - auc: 0.8948 - val_loss: 0.1947 - val_accuracy: 0.9197 - val_auc: 0.9064\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91974\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2029 - accuracy: 0.9175 - auc: 0.8942 - val_loss: 0.1970 - val_accuracy: 0.9171 - val_auc: 0.9050\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.91974\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2034 - accuracy: 0.9169 - auc: 0.8947 - val_loss: 0.1946 - val_accuracy: 0.9185 - val_auc: 0.9071\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.91974\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2025 - accuracy: 0.9172 - auc: 0.8953 - val_loss: 0.1947 - val_accuracy: 0.9194 - val_auc: 0.9065\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.91974\n",
      "Epoch 00020: early stopping\n",
      "Model: \"model_48\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling1D) (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling1D) (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_192 (Dropout)           (None, 15, 128)      0           max_pooling1d_96[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_194 (Dropout)           (None, 17, 128)      0           max_pooling1d_97[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_96 (Flatten)            (None, 1920)         0           dropout_192[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_97 (Flatten)            (None, 2176)         0           dropout_194[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_96 (Attention)        (None, 143)          33281       dropout_192[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_193 (Dropout)           (None, 1920)         0           flatten_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_97 (Attention)        (None, 145)          33281       dropout_194[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_195 (Dropout)           (None, 2176)         0           flatten_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_96 (attention (None, 128)          0           attention_96[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_240 (Dense)               (None, 1)            1921        dropout_193[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_97 (attention (None, 128)          0           attention_97[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_242 (Dense)               (None, 1)            2177        dropout_195[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 129)          0           attention_flatten_96[0][0]       \n",
      "                                                                 dense_240[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_145 (Concatenate)   (None, 129)          0           attention_flatten_97[0][0]       \n",
      "                                                                 dense_242[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_241 (Dense)               (None, 1)            130         concatenate_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_243 (Dense)               (None, 1)            130         concatenate_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_146 (Concatenate)   (None, 2)            0           dense_241[0][0]                  \n",
      "                                                                 dense_243[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_244 (Dense)               (None, 1)            3           concatenate_146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 1)            0           dense_244[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 51s 40ms/step - loss: 0.2828 - accuracy: 0.8952 - auc: 0.7346 - val_loss: 0.2144 - val_accuracy: 0.9138 - val_auc: 0.8810\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91385, saving model to model/Ensemble/CV_4/model_4.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 47s 39ms/step - loss: 0.2182 - accuracy: 0.9129 - auc: 0.8729 - val_loss: 0.2060 - val_accuracy: 0.9160 - val_auc: 0.8925\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91385 to 0.91601, saving model to model/Ensemble/CV_4/model_4.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2134 - accuracy: 0.9141 - auc: 0.8804 - val_loss: 0.2032 - val_accuracy: 0.9163 - val_auc: 0.8966\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91601 to 0.91631, saving model to model/Ensemble/CV_4/model_4.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2110 - accuracy: 0.9147 - auc: 0.8841 - val_loss: 0.2014 - val_accuracy: 0.9169 - val_auc: 0.8987\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91631 to 0.91685, saving model to model/Ensemble/CV_4/model_4.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2077 - accuracy: 0.9160 - auc: 0.8870 - val_loss: 0.1999 - val_accuracy: 0.9174 - val_auc: 0.9001\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91685 to 0.91736, saving model to model/Ensemble/CV_4/model_4.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2083 - accuracy: 0.9153 - auc: 0.8883 - val_loss: 0.1993 - val_accuracy: 0.9170 - val_auc: 0.9017\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91736\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2064 - accuracy: 0.9159 - auc: 0.8894 - val_loss: 0.1980 - val_accuracy: 0.9185 - val_auc: 0.9021\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91736 to 0.91855, saving model to model/Ensemble/CV_4/model_4.h5\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2060 - accuracy: 0.9163 - auc: 0.8908 - val_loss: 0.1988 - val_accuracy: 0.9168 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.91855\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2062 - accuracy: 0.9159 - auc: 0.8909 - val_loss: 0.1971 - val_accuracy: 0.9186 - val_auc: 0.9031\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91855 to 0.91855, saving model to model/Ensemble/CV_4/model_4.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2061 - accuracy: 0.9162 - auc: 0.8913 - val_loss: 0.1971 - val_accuracy: 0.9182 - val_auc: 0.9040\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91855\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2037 - accuracy: 0.9172 - auc: 0.8937 - val_loss: 0.1964 - val_accuracy: 0.9189 - val_auc: 0.9047\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91855 to 0.91894, saving model to model/Ensemble/CV_4/model_4.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2026 - accuracy: 0.9174 - auc: 0.8940 - val_loss: 0.1964 - val_accuracy: 0.9185 - val_auc: 0.9047\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91894\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2040 - accuracy: 0.9171 - auc: 0.8928 - val_loss: 0.1958 - val_accuracy: 0.9189 - val_auc: 0.9049\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91894\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2024 - accuracy: 0.9177 - auc: 0.8944 - val_loss: 0.1966 - val_accuracy: 0.9179 - val_auc: 0.9052\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91894\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2033 - accuracy: 0.9172 - auc: 0.8941 - val_loss: 0.1951 - val_accuracy: 0.9196 - val_auc: 0.9050\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.91894 to 0.91960, saving model to model/Ensemble/CV_4/model_4.h5\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2031 - accuracy: 0.9167 - auc: 0.8954 - val_loss: 0.1948 - val_accuracy: 0.9198 - val_auc: 0.9059\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.91960 to 0.91978, saving model to model/Ensemble/CV_4/model_4.h5\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 46s 39ms/step - loss: 0.2026 - accuracy: 0.9175 - auc: 0.8956 - val_loss: 0.1952 - val_accuracy: 0.9189 - val_auc: 0.9065\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91978\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 46s 39ms/step - loss: 0.2019 - accuracy: 0.9179 - auc: 0.8961 - val_loss: 0.1958 - val_accuracy: 0.9190 - val_auc: 0.9053\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.91978\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 46s 39ms/step - loss: 0.2020 - accuracy: 0.9176 - auc: 0.8969 - val_loss: 0.1941 - val_accuracy: 0.9196 - val_auc: 0.9074\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.91978\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2025 - accuracy: 0.9172 - auc: 0.8962 - val_loss: 0.1945 - val_accuracy: 0.9191 - val_auc: 0.9072\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.91978\n",
      "Epoch 21/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2013 - accuracy: 0.9178 - auc: 0.8973 - val_loss: 0.1934 - val_accuracy: 0.9202 - val_auc: 0.9080\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.91978 to 0.92016, saving model to model/Ensemble/CV_4/model_4.h5\n",
      "Epoch 22/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2010 - accuracy: 0.9178 - auc: 0.8975 - val_loss: 0.1941 - val_accuracy: 0.9196 - val_auc: 0.9071\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.92016\n",
      "Epoch 23/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2014 - accuracy: 0.9180 - auc: 0.8968 - val_loss: 0.1945 - val_accuracy: 0.9189 - val_auc: 0.9074\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.92016\n",
      "Epoch 24/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.1995 - accuracy: 0.9182 - auc: 0.8995 - val_loss: 0.1932 - val_accuracy: 0.9203 - val_auc: 0.9072\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.92016 to 0.92033, saving model to model/Ensemble/CV_4/model_4.h5\n",
      "Epoch 25/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.1997 - accuracy: 0.9183 - auc: 0.8990 - val_loss: 0.1925 - val_accuracy: 0.9204 - val_auc: 0.9087\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.92033 to 0.92042, saving model to model/Ensemble/CV_4/model_4.h5\n",
      "Epoch 26/100\n",
      "1182/1182 [==============================] - 46s 39ms/step - loss: 0.1988 - accuracy: 0.9187 - auc: 0.8990 - val_loss: 0.1927 - val_accuracy: 0.9201 - val_auc: 0.9083\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.92042\n",
      "Epoch 27/100\n",
      "1182/1182 [==============================] - 46s 39ms/step - loss: 0.1995 - accuracy: 0.9186 - auc: 0.8997 - val_loss: 0.1928 - val_accuracy: 0.9210 - val_auc: 0.9089\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.92042 to 0.92104, saving model to model/Ensemble/CV_4/model_4.h5\n",
      "Epoch 28/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.1993 - accuracy: 0.9186 - auc: 0.8994 - val_loss: 0.1927 - val_accuracy: 0.9202 - val_auc: 0.9087\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.92104\n",
      "Epoch 29/100\n",
      "1182/1182 [==============================] - 46s 39ms/step - loss: 0.1997 - accuracy: 0.9181 - auc: 0.8997 - val_loss: 0.1925 - val_accuracy: 0.9202 - val_auc: 0.9088\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.92104\n",
      "Epoch 30/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2000 - accuracy: 0.9182 - auc: 0.8990 - val_loss: 0.1930 - val_accuracy: 0.9194 - val_auc: 0.9090\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.92104\n",
      "Epoch 31/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1979 - accuracy: 0.9193 - auc: 0.9006 - val_loss: 0.1927 - val_accuracy: 0.9197 - val_auc: 0.9091\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.92104\n",
      "Epoch 32/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.1980 - accuracy: 0.9189 - auc: 0.9004 - val_loss: 0.1915 - val_accuracy: 0.9209 - val_auc: 0.9093\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.92104\n",
      "Epoch 00032: early stopping\n",
      "Model: \"model_50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_100 (MaxPooling1D (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_101 (MaxPooling1D (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_200 (Dropout)           (None, 15, 128)      0           max_pooling1d_100[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_202 (Dropout)           (None, 17, 128)      0           max_pooling1d_101[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_100 (Flatten)           (None, 1920)         0           dropout_200[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_101 (Flatten)           (None, 2176)         0           dropout_202[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_100 (Attention)       (None, 143)          33281       dropout_200[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_201 (Dropout)           (None, 1920)         0           flatten_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_101 (Attention)       (None, 145)          33281       dropout_202[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_203 (Dropout)           (None, 2176)         0           flatten_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_100 (attentio (None, 128)          0           attention_100[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_250 (Dense)               (None, 1)            1921        dropout_201[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_101 (attentio (None, 128)          0           attention_101[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_252 (Dense)               (None, 1)            2177        dropout_203[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_150 (Concatenate)   (None, 129)          0           attention_flatten_100[0][0]      \n",
      "                                                                 dense_250[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_151 (Concatenate)   (None, 129)          0           attention_flatten_101[0][0]      \n",
      "                                                                 dense_252[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_251 (Dense)               (None, 1)            130         concatenate_150[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_253 (Dense)               (None, 1)            130         concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_152 (Concatenate)   (None, 2)            0           dense_251[0][0]                  \n",
      "                                                                 dense_253[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_254 (Dense)               (None, 1)            3           concatenate_152[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 1)            0           dense_254[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 50s 41ms/step - loss: 0.2855 - accuracy: 0.8932 - auc: 0.7333 - val_loss: 0.2172 - val_accuracy: 0.9137 - val_auc: 0.8754\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91365, saving model to model/Ensemble/CV_5/model_0.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2203 - accuracy: 0.9124 - auc: 0.8716 - val_loss: 0.2090 - val_accuracy: 0.9146 - val_auc: 0.8876\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91365 to 0.91461, saving model to model/Ensemble/CV_5/model_0.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2104 - accuracy: 0.9153 - auc: 0.8826 - val_loss: 0.2054 - val_accuracy: 0.9160 - val_auc: 0.8921\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91461 to 0.91599, saving model to model/Ensemble/CV_5/model_0.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2095 - accuracy: 0.9148 - auc: 0.8864 - val_loss: 0.2039 - val_accuracy: 0.9160 - val_auc: 0.8945\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.91599\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2075 - accuracy: 0.9158 - auc: 0.8883 - val_loss: 0.2024 - val_accuracy: 0.9175 - val_auc: 0.8958\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91599 to 0.91755, saving model to model/Ensemble/CV_5/model_0.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2064 - accuracy: 0.9166 - auc: 0.8890 - val_loss: 0.2017 - val_accuracy: 0.9174 - val_auc: 0.8968\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91755\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2066 - accuracy: 0.9163 - auc: 0.8903 - val_loss: 0.2021 - val_accuracy: 0.9167 - val_auc: 0.8974\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91755\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2055 - accuracy: 0.9160 - auc: 0.8921 - val_loss: 0.2002 - val_accuracy: 0.9179 - val_auc: 0.8987\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91755 to 0.91787, saving model to model/Ensemble/CV_5/model_0.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2047 - accuracy: 0.9160 - auc: 0.8933 - val_loss: 0.2002 - val_accuracy: 0.9178 - val_auc: 0.8990\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.91787\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2034 - accuracy: 0.9172 - auc: 0.8937 - val_loss: 0.2001 - val_accuracy: 0.9172 - val_auc: 0.8995\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91787\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2021 - accuracy: 0.9172 - auc: 0.8953 - val_loss: 0.1985 - val_accuracy: 0.9187 - val_auc: 0.9009\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91787 to 0.91871, saving model to model/Ensemble/CV_5/model_0.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2031 - accuracy: 0.9170 - auc: 0.8941 - val_loss: 0.2000 - val_accuracy: 0.9171 - val_auc: 0.9004\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91871\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2025 - accuracy: 0.9173 - auc: 0.8952 - val_loss: 0.1984 - val_accuracy: 0.9183 - val_auc: 0.9012\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91871\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2022 - accuracy: 0.9177 - auc: 0.8951 - val_loss: 0.1979 - val_accuracy: 0.9184 - val_auc: 0.9017\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91871\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2019 - accuracy: 0.9177 - auc: 0.8961 - val_loss: 0.1979 - val_accuracy: 0.9187 - val_auc: 0.9013\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.91871\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2013 - accuracy: 0.9175 - auc: 0.8975 - val_loss: 0.1971 - val_accuracy: 0.9190 - val_auc: 0.9022\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.91871 to 0.91905, saving model to model/Ensemble/CV_5/model_0.h5\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2029 - accuracy: 0.9168 - auc: 0.8962 - val_loss: 0.1972 - val_accuracy: 0.9185 - val_auc: 0.9022\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.91905\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2017 - accuracy: 0.9175 - auc: 0.8967 - val_loss: 0.1974 - val_accuracy: 0.9182 - val_auc: 0.9024\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.91905\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2002 - accuracy: 0.9179 - auc: 0.8984 - val_loss: 0.1970 - val_accuracy: 0.9190 - val_auc: 0.9018\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.91905\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.1995 - accuracy: 0.9183 - auc: 0.8986 - val_loss: 0.1966 - val_accuracy: 0.9188 - val_auc: 0.9028\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.91905\n",
      "Epoch 21/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.1991 - accuracy: 0.9178 - auc: 0.8996 - val_loss: 0.1969 - val_accuracy: 0.9185 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.91905\n",
      "Epoch 00021: early stopping\n",
      "Model: \"model_52\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_104 (MaxPooling1D (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_105 (MaxPooling1D (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_208 (Dropout)           (None, 15, 128)      0           max_pooling1d_104[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_210 (Dropout)           (None, 17, 128)      0           max_pooling1d_105[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_104 (Flatten)           (None, 1920)         0           dropout_208[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_105 (Flatten)           (None, 2176)         0           dropout_210[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_104 (Attention)       (None, 143)          33281       dropout_208[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_209 (Dropout)           (None, 1920)         0           flatten_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_105 (Attention)       (None, 145)          33281       dropout_210[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_211 (Dropout)           (None, 2176)         0           flatten_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_104 (attentio (None, 128)          0           attention_104[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_260 (Dense)               (None, 1)            1921        dropout_209[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_105 (attentio (None, 128)          0           attention_105[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_262 (Dense)               (None, 1)            2177        dropout_211[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_156 (Concatenate)   (None, 129)          0           attention_flatten_104[0][0]      \n",
      "                                                                 dense_260[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_157 (Concatenate)   (None, 129)          0           attention_flatten_105[0][0]      \n",
      "                                                                 dense_262[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_261 (Dense)               (None, 1)            130         concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_263 (Dense)               (None, 1)            130         concatenate_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_158 (Concatenate)   (None, 2)            0           dense_261[0][0]                  \n",
      "                                                                 dense_263[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_264 (Dense)               (None, 1)            3           concatenate_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 1)            0           dense_264[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2740 - accuracy: 0.9014 - auc: 0.7561 - val_loss: 0.2132 - val_accuracy: 0.9146 - val_auc: 0.8821\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91456, saving model to model/Ensemble/CV_5/model_1.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2165 - accuracy: 0.9138 - auc: 0.8749 - val_loss: 0.2066 - val_accuracy: 0.9147 - val_auc: 0.8926\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91456 to 0.91473, saving model to model/Ensemble/CV_5/model_1.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2117 - accuracy: 0.9144 - auc: 0.8828 - val_loss: 0.2024 - val_accuracy: 0.9164 - val_auc: 0.8967\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91473 to 0.91644, saving model to model/Ensemble/CV_5/model_1.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2092 - accuracy: 0.9153 - auc: 0.8854 - val_loss: 0.2020 - val_accuracy: 0.9177 - val_auc: 0.8995\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91644 to 0.91769, saving model to model/Ensemble/CV_5/model_1.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2081 - accuracy: 0.9154 - auc: 0.8889 - val_loss: 0.2000 - val_accuracy: 0.9175 - val_auc: 0.8997\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.91769\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2075 - accuracy: 0.9158 - auc: 0.8897 - val_loss: 0.1992 - val_accuracy: 0.9171 - val_auc: 0.9008\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91769\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2064 - accuracy: 0.9161 - auc: 0.8902 - val_loss: 0.1979 - val_accuracy: 0.9179 - val_auc: 0.9019\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91769 to 0.91791, saving model to model/Ensemble/CV_5/model_1.h5\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2042 - accuracy: 0.9165 - auc: 0.8928 - val_loss: 0.1978 - val_accuracy: 0.9182 - val_auc: 0.9018\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91791 to 0.91823, saving model to model/Ensemble/CV_5/model_1.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2044 - accuracy: 0.9167 - auc: 0.8929 - val_loss: 0.1967 - val_accuracy: 0.9192 - val_auc: 0.9033\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91823 to 0.91925, saving model to model/Ensemble/CV_5/model_1.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2043 - accuracy: 0.9170 - auc: 0.8927 - val_loss: 0.1968 - val_accuracy: 0.9182 - val_auc: 0.9037\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91925\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2030 - accuracy: 0.9174 - auc: 0.8940 - val_loss: 0.1970 - val_accuracy: 0.9182 - val_auc: 0.9029\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91925\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2037 - accuracy: 0.9168 - auc: 0.8943 - val_loss: 0.1970 - val_accuracy: 0.9177 - val_auc: 0.9037\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91925\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2019 - accuracy: 0.9176 - auc: 0.8953 - val_loss: 0.1969 - val_accuracy: 0.9178 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91925\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2027 - accuracy: 0.9171 - auc: 0.8954 - val_loss: 0.1955 - val_accuracy: 0.9191 - val_auc: 0.9048\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91925\n",
      "Epoch 00014: early stopping\n",
      "Model: \"model_54\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_108 (MaxPooling1D (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_109 (MaxPooling1D (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_216 (Dropout)           (None, 15, 128)      0           max_pooling1d_108[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_218 (Dropout)           (None, 17, 128)      0           max_pooling1d_109[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_108 (Flatten)           (None, 1920)         0           dropout_216[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_109 (Flatten)           (None, 2176)         0           dropout_218[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_108 (Attention)       (None, 143)          33281       dropout_216[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_217 (Dropout)           (None, 1920)         0           flatten_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_109 (Attention)       (None, 145)          33281       dropout_218[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_219 (Dropout)           (None, 2176)         0           flatten_109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_108 (attentio (None, 128)          0           attention_108[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_270 (Dense)               (None, 1)            1921        dropout_217[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_109 (attentio (None, 128)          0           attention_109[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_272 (Dense)               (None, 1)            2177        dropout_219[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_162 (Concatenate)   (None, 129)          0           attention_flatten_108[0][0]      \n",
      "                                                                 dense_270[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_163 (Concatenate)   (None, 129)          0           attention_flatten_109[0][0]      \n",
      "                                                                 dense_272[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_271 (Dense)               (None, 1)            130         concatenate_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_273 (Dense)               (None, 1)            130         concatenate_163[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_164 (Concatenate)   (None, 2)            0           dense_271[0][0]                  \n",
      "                                                                 dense_273[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_274 (Dense)               (None, 1)            3           concatenate_164[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 1)            0           dense_274[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 51s 42ms/step - loss: 0.2694 - accuracy: 0.9059 - auc: 0.7600 - val_loss: 0.2118 - val_accuracy: 0.9147 - val_auc: 0.8837\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91471, saving model to model/Ensemble/CV_5/model_2.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2175 - accuracy: 0.9133 - auc: 0.8739 - val_loss: 0.2051 - val_accuracy: 0.9159 - val_auc: 0.8942\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91471 to 0.91592, saving model to model/Ensemble/CV_5/model_2.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2123 - accuracy: 0.9140 - auc: 0.8825 - val_loss: 0.2017 - val_accuracy: 0.9168 - val_auc: 0.8982\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91592 to 0.91681, saving model to model/Ensemble/CV_5/model_2.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 46s 39ms/step - loss: 0.2103 - accuracy: 0.9144 - auc: 0.8856 - val_loss: 0.2003 - val_accuracy: 0.9175 - val_auc: 0.8998\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91681 to 0.91748, saving model to model/Ensemble/CV_5/model_2.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2057 - accuracy: 0.9167 - auc: 0.8893 - val_loss: 0.1991 - val_accuracy: 0.9183 - val_auc: 0.9018\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91748 to 0.91832, saving model to model/Ensemble/CV_5/model_2.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2064 - accuracy: 0.9166 - auc: 0.8895 - val_loss: 0.1983 - val_accuracy: 0.9189 - val_auc: 0.9021\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.91832 to 0.91886, saving model to model/Ensemble/CV_5/model_2.h5\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 46s 39ms/step - loss: 0.2047 - accuracy: 0.9169 - auc: 0.8910 - val_loss: 0.1976 - val_accuracy: 0.9190 - val_auc: 0.9027\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91886 to 0.91902, saving model to model/Ensemble/CV_5/model_2.h5\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2046 - accuracy: 0.9166 - auc: 0.8924 - val_loss: 0.1967 - val_accuracy: 0.9191 - val_auc: 0.9035\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91902 to 0.91913, saving model to model/Ensemble/CV_5/model_2.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2043 - accuracy: 0.9167 - auc: 0.8931 - val_loss: 0.1969 - val_accuracy: 0.9189 - val_auc: 0.9037\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.91913\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2040 - accuracy: 0.9170 - auc: 0.8934 - val_loss: 0.1966 - val_accuracy: 0.9186 - val_auc: 0.9039\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91913\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2045 - accuracy: 0.9168 - auc: 0.8931 - val_loss: 0.1966 - val_accuracy: 0.9183 - val_auc: 0.9049\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91913\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2017 - accuracy: 0.9181 - auc: 0.8949 - val_loss: 0.1956 - val_accuracy: 0.9190 - val_auc: 0.9052\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91913\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2044 - accuracy: 0.9166 - auc: 0.8931 - val_loss: 0.1963 - val_accuracy: 0.9183 - val_auc: 0.9057\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91913\n",
      "Epoch 00013: early stopping\n",
      "Model: \"model_56\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_112 (MaxPooling1D (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_113 (MaxPooling1D (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_224 (Dropout)           (None, 15, 128)      0           max_pooling1d_112[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_226 (Dropout)           (None, 17, 128)      0           max_pooling1d_113[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_112 (Flatten)           (None, 1920)         0           dropout_224[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_113 (Flatten)           (None, 2176)         0           dropout_226[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_112 (Attention)       (None, 143)          33281       dropout_224[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_225 (Dropout)           (None, 1920)         0           flatten_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_113 (Attention)       (None, 145)          33281       dropout_226[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_227 (Dropout)           (None, 2176)         0           flatten_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_112 (attentio (None, 128)          0           attention_112[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_280 (Dense)               (None, 1)            1921        dropout_225[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_113 (attentio (None, 128)          0           attention_113[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_282 (Dense)               (None, 1)            2177        dropout_227[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_168 (Concatenate)   (None, 129)          0           attention_flatten_112[0][0]      \n",
      "                                                                 dense_280[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_169 (Concatenate)   (None, 129)          0           attention_flatten_113[0][0]      \n",
      "                                                                 dense_282[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_281 (Dense)               (None, 1)            130         concatenate_168[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_283 (Dense)               (None, 1)            130         concatenate_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_170 (Concatenate)   (None, 2)            0           dense_281[0][0]                  \n",
      "                                                                 dense_283[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_284 (Dense)               (None, 1)            3           concatenate_170[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 1)            0           dense_284[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2706 - accuracy: 0.9065 - auc: 0.7576 - val_loss: 0.2136 - val_accuracy: 0.9136 - val_auc: 0.8835\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91355, saving model to model/Ensemble/CV_5/model_3.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2168 - accuracy: 0.9131 - auc: 0.8756 - val_loss: 0.2047 - val_accuracy: 0.9165 - val_auc: 0.8942\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91355 to 0.91654, saving model to model/Ensemble/CV_5/model_3.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2124 - accuracy: 0.9141 - auc: 0.8826 - val_loss: 0.2034 - val_accuracy: 0.9152 - val_auc: 0.8982\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.91654\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2097 - accuracy: 0.9150 - auc: 0.8860 - val_loss: 0.2002 - val_accuracy: 0.9173 - val_auc: 0.8997\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91654 to 0.91734, saving model to model/Ensemble/CV_5/model_3.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2071 - accuracy: 0.9164 - auc: 0.8886 - val_loss: 0.1989 - val_accuracy: 0.9180 - val_auc: 0.9016\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91734 to 0.91796, saving model to model/Ensemble/CV_5/model_3.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2075 - accuracy: 0.9157 - auc: 0.8891 - val_loss: 0.1982 - val_accuracy: 0.9179 - val_auc: 0.9026\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91796\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2060 - accuracy: 0.9160 - auc: 0.8901 - val_loss: 0.1984 - val_accuracy: 0.9172 - val_auc: 0.9028\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91796\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2053 - accuracy: 0.9164 - auc: 0.8915 - val_loss: 0.1964 - val_accuracy: 0.9190 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91796 to 0.91897, saving model to model/Ensemble/CV_5/model_3.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2050 - accuracy: 0.9166 - auc: 0.8915 - val_loss: 0.1966 - val_accuracy: 0.9193 - val_auc: 0.9044\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91897 to 0.91927, saving model to model/Ensemble/CV_5/model_3.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2056 - accuracy: 0.9161 - auc: 0.8917 - val_loss: 0.1959 - val_accuracy: 0.9196 - val_auc: 0.9045\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.91927 to 0.91959, saving model to model/Ensemble/CV_5/model_3.h5\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2039 - accuracy: 0.9171 - auc: 0.8935 - val_loss: 0.1954 - val_accuracy: 0.9201 - val_auc: 0.9051\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91959 to 0.92013, saving model to model/Ensemble/CV_5/model_3.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2031 - accuracy: 0.9171 - auc: 0.8946 - val_loss: 0.1963 - val_accuracy: 0.9177 - val_auc: 0.9056\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.92013\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2041 - accuracy: 0.9170 - auc: 0.8936 - val_loss: 0.1953 - val_accuracy: 0.9190 - val_auc: 0.9060\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.92013\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2027 - accuracy: 0.9175 - auc: 0.8947 - val_loss: 0.1947 - val_accuracy: 0.9192 - val_auc: 0.9069\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.92013\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2032 - accuracy: 0.9170 - auc: 0.8949 - val_loss: 0.1940 - val_accuracy: 0.9207 - val_auc: 0.9067\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.92013 to 0.92072, saving model to model/Ensemble/CV_5/model_3.h5\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2025 - accuracy: 0.9173 - auc: 0.8953 - val_loss: 0.1945 - val_accuracy: 0.9194 - val_auc: 0.9071\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.92072\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2012 - accuracy: 0.9184 - auc: 0.8954 - val_loss: 0.1939 - val_accuracy: 0.9204 - val_auc: 0.9071\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.92072\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2024 - accuracy: 0.9177 - auc: 0.8949 - val_loss: 0.1954 - val_accuracy: 0.9179 - val_auc: 0.9071\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.92072\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2022 - accuracy: 0.9173 - auc: 0.8962 - val_loss: 0.1934 - val_accuracy: 0.9195 - val_auc: 0.9082\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.92072\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2018 - accuracy: 0.9176 - auc: 0.8965 - val_loss: 0.1937 - val_accuracy: 0.9200 - val_auc: 0.9079\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.92072\n",
      "Epoch 00020: early stopping\n",
      "Model: \"model_58\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_116 (MaxPooling1D (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_117 (MaxPooling1D (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_232 (Dropout)           (None, 15, 128)      0           max_pooling1d_116[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_234 (Dropout)           (None, 17, 128)      0           max_pooling1d_117[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_116 (Flatten)           (None, 1920)         0           dropout_232[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_117 (Flatten)           (None, 2176)         0           dropout_234[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_116 (Attention)       (None, 143)          33281       dropout_232[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_233 (Dropout)           (None, 1920)         0           flatten_116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_117 (Attention)       (None, 145)          33281       dropout_234[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_235 (Dropout)           (None, 2176)         0           flatten_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_116 (attentio (None, 128)          0           attention_116[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_290 (Dense)               (None, 1)            1921        dropout_233[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_117 (attentio (None, 128)          0           attention_117[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_292 (Dense)               (None, 1)            2177        dropout_235[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_174 (Concatenate)   (None, 129)          0           attention_flatten_116[0][0]      \n",
      "                                                                 dense_290[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_175 (Concatenate)   (None, 129)          0           attention_flatten_117[0][0]      \n",
      "                                                                 dense_292[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_291 (Dense)               (None, 1)            130         concatenate_174[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_293 (Dense)               (None, 1)            130         concatenate_175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_176 (Concatenate)   (None, 2)            0           dense_291[0][0]                  \n",
      "                                                                 dense_293[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_294 (Dense)               (None, 1)            3           concatenate_176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 1)            0           dense_294[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2644 - accuracy: 0.9061 - auc: 0.7745 - val_loss: 0.2104 - val_accuracy: 0.9148 - val_auc: 0.8871\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91475, saving model to model/Ensemble/CV_5/model_4.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2163 - accuracy: 0.9136 - auc: 0.8758 - val_loss: 0.2041 - val_accuracy: 0.9163 - val_auc: 0.8947\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91475 to 0.91634, saving model to model/Ensemble/CV_5/model_4.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2118 - accuracy: 0.9145 - auc: 0.8825 - val_loss: 0.2016 - val_accuracy: 0.9174 - val_auc: 0.8986\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91634 to 0.91740, saving model to model/Ensemble/CV_5/model_4.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2089 - accuracy: 0.9152 - auc: 0.8866 - val_loss: 0.2007 - val_accuracy: 0.9167 - val_auc: 0.9004\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.91740\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2069 - accuracy: 0.9167 - auc: 0.8880 - val_loss: 0.1990 - val_accuracy: 0.9181 - val_auc: 0.9008\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91740 to 0.91814, saving model to model/Ensemble/CV_5/model_4.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2066 - accuracy: 0.9160 - auc: 0.8906 - val_loss: 0.1983 - val_accuracy: 0.9179 - val_auc: 0.9025\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91814\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2050 - accuracy: 0.9168 - auc: 0.8913 - val_loss: 0.1968 - val_accuracy: 0.9191 - val_auc: 0.9035\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91814 to 0.91913, saving model to model/Ensemble/CV_5/model_4.h5\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2040 - accuracy: 0.9174 - auc: 0.8931 - val_loss: 0.1977 - val_accuracy: 0.9176 - val_auc: 0.9038\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.91913\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2043 - accuracy: 0.9164 - auc: 0.8936 - val_loss: 0.1963 - val_accuracy: 0.9193 - val_auc: 0.9042\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91913 to 0.91933, saving model to model/Ensemble/CV_5/model_4.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2041 - accuracy: 0.9169 - auc: 0.8937 - val_loss: 0.1964 - val_accuracy: 0.9186 - val_auc: 0.9043\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91933\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2022 - accuracy: 0.9176 - auc: 0.8958 - val_loss: 0.1954 - val_accuracy: 0.9196 - val_auc: 0.9056\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91933 to 0.91963, saving model to model/Ensemble/CV_5/model_4.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2009 - accuracy: 0.9181 - auc: 0.8964 - val_loss: 0.1954 - val_accuracy: 0.9194 - val_auc: 0.9053\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91963\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2018 - accuracy: 0.9183 - auc: 0.8957 - val_loss: 0.1954 - val_accuracy: 0.9194 - val_auc: 0.9058\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91963\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2007 - accuracy: 0.9181 - auc: 0.8968 - val_loss: 0.1958 - val_accuracy: 0.9192 - val_auc: 0.9055\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91963\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2014 - accuracy: 0.9178 - auc: 0.8964 - val_loss: 0.1951 - val_accuracy: 0.9196 - val_auc: 0.9052\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.91963\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2012 - accuracy: 0.9177 - auc: 0.8979 - val_loss: 0.1949 - val_accuracy: 0.9205 - val_auc: 0.9065\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.91963 to 0.92054, saving model to model/Ensemble/CV_5/model_4.h5\n",
      "Epoch 17/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2007 - accuracy: 0.9181 - auc: 0.8983 - val_loss: 0.1950 - val_accuracy: 0.9193 - val_auc: 0.9066\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.92054\n",
      "Epoch 18/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2003 - accuracy: 0.9186 - auc: 0.8982 - val_loss: 0.1947 - val_accuracy: 0.9195 - val_auc: 0.9065\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.92054\n",
      "Epoch 19/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2005 - accuracy: 0.9178 - auc: 0.8991 - val_loss: 0.1936 - val_accuracy: 0.9201 - val_auc: 0.9078\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.92054\n",
      "Epoch 20/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2005 - accuracy: 0.9178 - auc: 0.8986 - val_loss: 0.1947 - val_accuracy: 0.9195 - val_auc: 0.9071\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.92054\n",
      "Epoch 21/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1999 - accuracy: 0.9183 - auc: 0.8991 - val_loss: 0.1929 - val_accuracy: 0.9206 - val_auc: 0.9085\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.92054 to 0.92060, saving model to model/Ensemble/CV_5/model_4.h5\n",
      "Epoch 22/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1995 - accuracy: 0.9184 - auc: 0.8993 - val_loss: 0.1936 - val_accuracy: 0.9204 - val_auc: 0.9074\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.92060\n",
      "Epoch 23/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.1998 - accuracy: 0.9187 - auc: 0.8987 - val_loss: 0.1931 - val_accuracy: 0.9203 - val_auc: 0.9085\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.92060\n",
      "Epoch 24/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.1980 - accuracy: 0.9191 - auc: 0.9011 - val_loss: 0.1929 - val_accuracy: 0.9207 - val_auc: 0.9075\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.92060 to 0.92069, saving model to model/Ensemble/CV_5/model_4.h5\n",
      "Epoch 25/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1977 - accuracy: 0.9194 - auc: 0.9014 - val_loss: 0.1922 - val_accuracy: 0.9207 - val_auc: 0.9089\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.92069\n",
      "Epoch 26/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.1979 - accuracy: 0.9191 - auc: 0.9001 - val_loss: 0.1917 - val_accuracy: 0.9212 - val_auc: 0.9092\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.92069 to 0.92115, saving model to model/Ensemble/CV_5/model_4.h5\n",
      "Epoch 27/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1983 - accuracy: 0.9190 - auc: 0.9012 - val_loss: 0.1924 - val_accuracy: 0.9216 - val_auc: 0.9089\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.92115 to 0.92157, saving model to model/Ensemble/CV_5/model_4.h5\n",
      "Epoch 28/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1984 - accuracy: 0.9193 - auc: 0.9005 - val_loss: 0.1922 - val_accuracy: 0.9207 - val_auc: 0.9095\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.92157\n",
      "Epoch 29/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.1986 - accuracy: 0.9184 - auc: 0.9009 - val_loss: 0.1916 - val_accuracy: 0.9210 - val_auc: 0.9094\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.92157\n",
      "Epoch 30/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1985 - accuracy: 0.9188 - auc: 0.9006 - val_loss: 0.1920 - val_accuracy: 0.9206 - val_auc: 0.9095\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.92157\n",
      "Epoch 31/100\n",
      "1182/1182 [==============================] - 46s 39ms/step - loss: 0.1969 - accuracy: 0.9195 - auc: 0.9016 - val_loss: 0.1917 - val_accuracy: 0.9203 - val_auc: 0.9098\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.92157\n",
      "Epoch 32/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.1968 - accuracy: 0.9197 - auc: 0.9019 - val_loss: 0.1906 - val_accuracy: 0.9214 - val_auc: 0.9104\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.92157\n",
      "Epoch 00032: early stopping\n",
      "Model: \"model_60\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_120 (MaxPooling1D (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_121 (MaxPooling1D (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_240 (Dropout)           (None, 15, 128)      0           max_pooling1d_120[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_242 (Dropout)           (None, 17, 128)      0           max_pooling1d_121[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_120 (Flatten)           (None, 1920)         0           dropout_240[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_121 (Flatten)           (None, 2176)         0           dropout_242[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_120 (Attention)       (None, 143)          33281       dropout_240[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_241 (Dropout)           (None, 1920)         0           flatten_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_121 (Attention)       (None, 145)          33281       dropout_242[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_243 (Dropout)           (None, 2176)         0           flatten_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_120 (attentio (None, 128)          0           attention_120[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_300 (Dense)               (None, 1)            1921        dropout_241[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_121 (attentio (None, 128)          0           attention_121[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_302 (Dense)               (None, 1)            2177        dropout_243[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_180 (Concatenate)   (None, 129)          0           attention_flatten_120[0][0]      \n",
      "                                                                 dense_300[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_181 (Concatenate)   (None, 129)          0           attention_flatten_121[0][0]      \n",
      "                                                                 dense_302[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_301 (Dense)               (None, 1)            130         concatenate_180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_303 (Dense)               (None, 1)            130         concatenate_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_182 (Concatenate)   (None, 2)            0           dense_301[0][0]                  \n",
      "                                                                 dense_303[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_304 (Dense)               (None, 1)            3           concatenate_182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1)            0           dense_304[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 51s 42ms/step - loss: 0.2726 - accuracy: 0.9086 - auc: 0.7567 - val_loss: 0.2153 - val_accuracy: 0.9143 - val_auc: 0.8780\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91435, saving model to model/Ensemble/CV_6/model_0.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2187 - accuracy: 0.9126 - auc: 0.8741 - val_loss: 0.2074 - val_accuracy: 0.9155 - val_auc: 0.8897\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91435 to 0.91553, saving model to model/Ensemble/CV_6/model_0.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2098 - accuracy: 0.9153 - auc: 0.8838 - val_loss: 0.2043 - val_accuracy: 0.9168 - val_auc: 0.8931\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91553 to 0.91681, saving model to model/Ensemble/CV_6/model_0.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2091 - accuracy: 0.9152 - auc: 0.8869 - val_loss: 0.2036 - val_accuracy: 0.9163 - val_auc: 0.8958\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.91681\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 51s 43ms/step - loss: 0.2071 - accuracy: 0.9161 - auc: 0.8888 - val_loss: 0.2018 - val_accuracy: 0.9175 - val_auc: 0.8966\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91681 to 0.91746, saving model to model/Ensemble/CV_6/model_0.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2053 - accuracy: 0.9165 - auc: 0.8906 - val_loss: 0.2010 - val_accuracy: 0.9176 - val_auc: 0.8977\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.91746 to 0.91757, saving model to model/Ensemble/CV_6/model_0.h5\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2058 - accuracy: 0.9159 - auc: 0.8917 - val_loss: 0.2022 - val_accuracy: 0.9167 - val_auc: 0.8981\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91757\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2045 - accuracy: 0.9168 - auc: 0.8930 - val_loss: 0.1997 - val_accuracy: 0.9178 - val_auc: 0.8996\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91757 to 0.91775, saving model to model/Ensemble/CV_6/model_0.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2043 - accuracy: 0.9164 - auc: 0.8940 - val_loss: 0.1997 - val_accuracy: 0.9179 - val_auc: 0.8995\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91775 to 0.91787, saving model to model/Ensemble/CV_6/model_0.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2027 - accuracy: 0.9175 - auc: 0.8943 - val_loss: 0.1994 - val_accuracy: 0.9177 - val_auc: 0.9004\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91787\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2010 - accuracy: 0.9177 - auc: 0.8966 - val_loss: 0.1981 - val_accuracy: 0.9190 - val_auc: 0.9015\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.91787 to 0.91898, saving model to model/Ensemble/CV_6/model_0.h5\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2020 - accuracy: 0.9172 - auc: 0.8961 - val_loss: 0.1994 - val_accuracy: 0.9172 - val_auc: 0.9012\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91898\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2018 - accuracy: 0.9178 - auc: 0.8961 - val_loss: 0.1980 - val_accuracy: 0.9183 - val_auc: 0.9022\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91898\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2010 - accuracy: 0.9182 - auc: 0.8967 - val_loss: 0.1977 - val_accuracy: 0.9184 - val_auc: 0.9022\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91898\n",
      "Epoch 15/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2013 - accuracy: 0.9178 - auc: 0.8969 - val_loss: 0.1976 - val_accuracy: 0.9185 - val_auc: 0.9017\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.91898\n",
      "Epoch 16/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2005 - accuracy: 0.9178 - auc: 0.8985 - val_loss: 0.1972 - val_accuracy: 0.9183 - val_auc: 0.9026\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.91898\n",
      "Epoch 00016: early stopping\n",
      "Model: \"model_62\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_124 (MaxPooling1D (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_125 (MaxPooling1D (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_248 (Dropout)           (None, 15, 128)      0           max_pooling1d_124[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_250 (Dropout)           (None, 17, 128)      0           max_pooling1d_125[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_124 (Flatten)           (None, 1920)         0           dropout_248[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_125 (Flatten)           (None, 2176)         0           dropout_250[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_124 (Attention)       (None, 143)          33281       dropout_248[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_249 (Dropout)           (None, 1920)         0           flatten_124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_125 (Attention)       (None, 145)          33281       dropout_250[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_251 (Dropout)           (None, 2176)         0           flatten_125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_124 (attentio (None, 128)          0           attention_124[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_310 (Dense)               (None, 1)            1921        dropout_249[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_125 (attentio (None, 128)          0           attention_125[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_312 (Dense)               (None, 1)            2177        dropout_251[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_186 (Concatenate)   (None, 129)          0           attention_flatten_124[0][0]      \n",
      "                                                                 dense_310[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_187 (Concatenate)   (None, 129)          0           attention_flatten_125[0][0]      \n",
      "                                                                 dense_312[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_311 (Dense)               (None, 1)            130         concatenate_186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_313 (Dense)               (None, 1)            130         concatenate_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_188 (Concatenate)   (None, 2)            0           dense_311[0][0]                  \n",
      "                                                                 dense_313[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_314 (Dense)               (None, 1)            3           concatenate_188[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 1)            0           dense_314[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 51s 42ms/step - loss: 0.2691 - accuracy: 0.9050 - auc: 0.7637 - val_loss: 0.2122 - val_accuracy: 0.9143 - val_auc: 0.8836\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91430, saving model to model/Ensemble/CV_6/model_1.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2157 - accuracy: 0.9138 - auc: 0.8763 - val_loss: 0.2052 - val_accuracy: 0.9158 - val_auc: 0.8937\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91430 to 0.91582, saving model to model/Ensemble/CV_6/model_1.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2106 - accuracy: 0.9147 - auc: 0.8844 - val_loss: 0.2020 - val_accuracy: 0.9171 - val_auc: 0.8970\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91582 to 0.91707, saving model to model/Ensemble/CV_6/model_1.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2081 - accuracy: 0.9159 - auc: 0.8869 - val_loss: 0.2019 - val_accuracy: 0.9180 - val_auc: 0.8995\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91707 to 0.91801, saving model to model/Ensemble/CV_6/model_1.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2076 - accuracy: 0.9152 - auc: 0.8895 - val_loss: 0.1999 - val_accuracy: 0.9171 - val_auc: 0.8998\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.91801\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2071 - accuracy: 0.9157 - auc: 0.8902 - val_loss: 0.1992 - val_accuracy: 0.9171 - val_auc: 0.9009\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91801\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2063 - accuracy: 0.9158 - auc: 0.8903 - val_loss: 0.1980 - val_accuracy: 0.9183 - val_auc: 0.9016\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.91801 to 0.91834, saving model to model/Ensemble/CV_6/model_1.h5\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2043 - accuracy: 0.9168 - auc: 0.8930 - val_loss: 0.1972 - val_accuracy: 0.9185 - val_auc: 0.9026\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91834 to 0.91849, saving model to model/Ensemble/CV_6/model_1.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2045 - accuracy: 0.9168 - auc: 0.8928 - val_loss: 0.1967 - val_accuracy: 0.9190 - val_auc: 0.9031\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.91849 to 0.91902, saving model to model/Ensemble/CV_6/model_1.h5\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 50s 43ms/step - loss: 0.2043 - accuracy: 0.9169 - auc: 0.8926 - val_loss: 0.1975 - val_accuracy: 0.9177 - val_auc: 0.9030\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91902\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2029 - accuracy: 0.9172 - auc: 0.8940 - val_loss: 0.1979 - val_accuracy: 0.9179 - val_auc: 0.9024\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91902\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 49s 42ms/step - loss: 0.2035 - accuracy: 0.9171 - auc: 0.8943 - val_loss: 0.1971 - val_accuracy: 0.9182 - val_auc: 0.9033\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91902\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2019 - accuracy: 0.9177 - auc: 0.8952 - val_loss: 0.1977 - val_accuracy: 0.9180 - val_auc: 0.9036\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91902\n",
      "Epoch 14/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2028 - accuracy: 0.9173 - auc: 0.8951 - val_loss: 0.1960 - val_accuracy: 0.9190 - val_auc: 0.9044\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.91902\n",
      "Epoch 00014: early stopping\n",
      "Model: \"model_64\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_128 (MaxPooling1D (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_129 (MaxPooling1D (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_256 (Dropout)           (None, 15, 128)      0           max_pooling1d_128[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_258 (Dropout)           (None, 17, 128)      0           max_pooling1d_129[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_128 (Flatten)           (None, 1920)         0           dropout_256[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_129 (Flatten)           (None, 2176)         0           dropout_258[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_128 (Attention)       (None, 143)          33281       dropout_256[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_257 (Dropout)           (None, 1920)         0           flatten_128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_129 (Attention)       (None, 145)          33281       dropout_258[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_259 (Dropout)           (None, 2176)         0           flatten_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_128 (attentio (None, 128)          0           attention_128[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_320 (Dense)               (None, 1)            1921        dropout_257[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_129 (attentio (None, 128)          0           attention_129[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_322 (Dense)               (None, 1)            2177        dropout_259[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_192 (Concatenate)   (None, 129)          0           attention_flatten_128[0][0]      \n",
      "                                                                 dense_320[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_193 (Concatenate)   (None, 129)          0           attention_flatten_129[0][0]      \n",
      "                                                                 dense_322[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_321 (Dense)               (None, 1)            130         concatenate_192[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_323 (Dense)               (None, 1)            130         concatenate_193[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_194 (Concatenate)   (None, 2)            0           dense_321[0][0]                  \n",
      "                                                                 dense_323[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_324 (Dense)               (None, 1)            3           concatenate_194[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 1)            0           dense_324[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/100\n",
      "1182/1182 [==============================] - 52s 43ms/step - loss: 0.2809 - accuracy: 0.8981 - auc: 0.7389 - val_loss: 0.2132 - val_accuracy: 0.9143 - val_auc: 0.8811\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.91429, saving model to model/Ensemble/CV_6/model_2.h5\n",
      "Epoch 2/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2181 - accuracy: 0.9134 - auc: 0.8730 - val_loss: 0.2056 - val_accuracy: 0.9158 - val_auc: 0.8929\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.91429 to 0.91582, saving model to model/Ensemble/CV_6/model_2.h5\n",
      "Epoch 3/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2126 - accuracy: 0.9140 - auc: 0.8821 - val_loss: 0.2029 - val_accuracy: 0.9164 - val_auc: 0.8973\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.91582 to 0.91637, saving model to model/Ensemble/CV_6/model_2.h5\n",
      "Epoch 4/100\n",
      "1182/1182 [==============================] - 48s 40ms/step - loss: 0.2111 - accuracy: 0.9146 - auc: 0.8846 - val_loss: 0.2011 - val_accuracy: 0.9174 - val_auc: 0.8987\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.91637 to 0.91738, saving model to model/Ensemble/CV_6/model_2.h5\n",
      "Epoch 5/100\n",
      "1182/1182 [==============================] - 47s 40ms/step - loss: 0.2065 - accuracy: 0.9163 - auc: 0.8886 - val_loss: 0.1996 - val_accuracy: 0.9181 - val_auc: 0.9012\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.91738 to 0.91812, saving model to model/Ensemble/CV_6/model_2.h5\n",
      "Epoch 6/100\n",
      "1182/1182 [==============================] - 48s 41ms/step - loss: 0.2072 - accuracy: 0.9160 - auc: 0.8887 - val_loss: 0.1988 - val_accuracy: 0.9181 - val_auc: 0.9015\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.91812\n",
      "Epoch 7/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2055 - accuracy: 0.9166 - auc: 0.8898 - val_loss: 0.1984 - val_accuracy: 0.9180 - val_auc: 0.9022\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.91812\n",
      "Epoch 8/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2053 - accuracy: 0.9163 - auc: 0.8914 - val_loss: 0.1967 - val_accuracy: 0.9194 - val_auc: 0.9031\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.91812 to 0.91940, saving model to model/Ensemble/CV_6/model_2.h5\n",
      "Epoch 9/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2051 - accuracy: 0.9167 - auc: 0.8920 - val_loss: 0.1972 - val_accuracy: 0.9194 - val_auc: 0.9036\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.91940\n",
      "Epoch 10/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2048 - accuracy: 0.9163 - auc: 0.8925 - val_loss: 0.1972 - val_accuracy: 0.9184 - val_auc: 0.9038\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.91940\n",
      "Epoch 11/100\n",
      "1182/1182 [==============================] - 50s 42ms/step - loss: 0.2048 - accuracy: 0.9164 - auc: 0.8930 - val_loss: 0.1975 - val_accuracy: 0.9179 - val_auc: 0.9043\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.91940\n",
      "Epoch 12/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2026 - accuracy: 0.9177 - auc: 0.8937 - val_loss: 0.1958 - val_accuracy: 0.9188 - val_auc: 0.9050\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.91940\n",
      "Epoch 13/100\n",
      "1182/1182 [==============================] - 49s 41ms/step - loss: 0.2051 - accuracy: 0.9167 - auc: 0.8928 - val_loss: 0.1979 - val_accuracy: 0.9177 - val_auc: 0.9048\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.91940\n",
      "Epoch 00013: early stopping\n",
      "Model: \"model_66\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "peptide (InputLayer)            [(None, 30, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mhc (InputLayer)                [(None, 34, 20)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pep (Conv1D)              (None, 30, 128)      7808        peptide[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_mhc (Conv1D)              (None, 34, 128)      7808        mhc[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_132 (MaxPooling1D (None, 15, 128)      0           conv1_pep[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_133 (MaxPooling1D (None, 17, 128)      0           conv1_mhc[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_264 (Dropout)           (None, 15, 128)      0           max_pooling1d_132[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dropout_266 (Dropout)           (None, 17, 128)      0           max_pooling1d_133[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "flatten_132 (Flatten)           (None, 1920)         0           dropout_264[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_133 (Flatten)           (None, 2176)         0           dropout_266[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_132 (Attention)       (None, 143)          33281       dropout_264[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_265 (Dropout)           (None, 1920)         0           flatten_132[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_133 (Attention)       (None, 145)          33281       dropout_266[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_267 (Dropout)           (None, 2176)         0           flatten_133[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_132 (attentio (None, 128)          0           attention_132[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_330 (Dense)               (None, 1)            1921        dropout_265[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "attention_flatten_133 (attentio (None, 128)          0           attention_133[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_332 (Dense)               (None, 1)            2177        dropout_267[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_198 (Concatenate)   (None, 129)          0           attention_flatten_132[0][0]      \n",
      "                                                                 dense_330[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_199 (Concatenate)   (None, 129)          0           attention_flatten_133[0][0]      \n",
      "                                                                 dense_332[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_331 (Dense)               (None, 1)            130         concatenate_198[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_333 (Dense)               (None, 1)            130         concatenate_199[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_200 (Concatenate)   (None, 2)            0           dense_331[0][0]                  \n",
      "                                                                 dense_333[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_334 (Dense)               (None, 1)            3           concatenate_200[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 1)            0           dense_334[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 86,539\n",
      "Trainable params: 86,539\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for u in range(10):\n",
    "        pep_bal, mhc_bal, target_bal = balanced_sampling(train_pep, train_mhc, train_target)\n",
    "        folder = 'model/Ensemble/CV_'+str(u)+'/'\n",
    "        for i, (train, test) in enumerate(kfold.split(train_pep, train_target)):\n",
    "                training_pep = train_pep[train]\n",
    "                training_mhc = train_mhc[train]\n",
    "                training_target = train_target[train]\n",
    "                \n",
    "                validation_pep = train_pep[test]\n",
    "                validation_mhc = train_mhc[test]\n",
    "                validation_target = train_target[test]\n",
    "\n",
    "                mc = ModelCheckpoint(folder+'model_' +str(i)+'.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "                model = build_model(training_pep, training_mhc)\n",
    "                model.summary()\n",
    "\n",
    "                model.fit([training_pep,training_mhc], \n",
    "                        training_target,\n",
    "                        batch_size=512,\n",
    "                        epochs = 100,\n",
    "                        shuffle=True,\n",
    "                        callbacks=[es, mc],\n",
    "                        validation_data=([validation_pep,validation_mhc], validation_target),\n",
    "                        verbose=1)  \n",
    "                del model\n",
    "\n",
    "                saved_model = build_model(training_pep, training_mhc)\n",
    "                saved_model.load_weights(folder+'model_' +str(i)+'.h5')\n",
    "                probas_ = saved_model.predict([np.array(validation_pep),np.array(validation_mhc)])\n",
    "                allprobas_ = np.append(allprobas_, probas_)           \n",
    "                all_labels = np.append(all_labels, validation_target)\n",
    "                del saved_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_probas=np.array([]) \n",
    "temp_labels=np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method attention_flatten.call of <attention_layer.attention_flatten object at 0x7f71e56dc820>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method attention_flatten.call of <attention_layer.attention_flatten object at 0x7f71e56dc820>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Index'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-12 13:56:28.826505: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-10-12 13:56:28.827079: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-10-12 13:56:28.827095: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-10-12 13:56:28.827124: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sbcphaplp001.uthouston.edu): /proc/driver/nvidia/version does not exist\n",
      "2022-10-12 13:56:28.827398: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-12 13:56:28.828075: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-10-12 13:56:30.477501: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 363004800 exceeds 10% of free system memory.\n",
      "2022-10-12 13:56:31.017751: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 411405440 exceeds 10% of free system memory.\n",
      "2022-10-12 13:56:31.458403: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2022-10-12 13:56:31.460495: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200000000 Hz\n",
      "2022-10-12 13:56:45.575126: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 363004800 exceeds 10% of free system memory.\n",
      "2022-10-12 13:56:46.832988: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 411405440 exceeds 10% of free system memory.\n",
      "2022-10-12 13:57:04.624522: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 363004800 exceeds 10% of free system memory.\n",
      "findfont: Font family ['Times New Roman'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['Times New Roman'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 446.4x446.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 446.4x446.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "font1 = {'family' : 'Times New Roman',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "figsize=6.2, 6.2\n",
    "\n",
    "for u in range(10):\n",
    "    pep_bal, mhc_bal, target_bal = balanced_sampling(train_pep, train_mhc, train_target)\n",
    "    folder = 'model/Ensemble/CV_'+str(u)+'/'\n",
    "    for i, (train, test) in enumerate(kfold.split(train_pep, train_target)):\n",
    "        training_pep = train_pep[train]\n",
    "        training_mhc = train_mhc[train]\n",
    "        training_target = train_target[train]\n",
    "        \n",
    "        validation_pep = train_pep[test]\n",
    "        validation_mhc = train_mhc[test]\n",
    "        validation_target = train_target[test]\n",
    "\n",
    "        savedmodel = build_model(training_pep, training_mhc)\n",
    "        savedmodel.load_weights(folder+'model_'+str(i)+'.h5')\n",
    "        probas_ = savedmodel.predict([np.array(validation_pep),np.array(validation_mhc)])\n",
    "        del savedmodel\n",
    "        temp_probas = np.append(temp_probas, probas_)\n",
    "        temp_labels = np.append(temp_labels, validation_target)\n",
    "\n",
    "    if u == 0:\n",
    "        fpr, tpr, threshold = roc_curve(temp_labels, temp_probas)\n",
    "        auroc = auc(fpr, tpr)\n",
    "        pr, rc, _ = precision_recall_curve(temp_labels, temp_probas)\n",
    "        aupr = average_precision_score(temp_labels, temp_probas)\n",
    "\n",
    "        figure1, ax1 = plt.subplots(figsize=figsize)\n",
    "        ax1.tick_params(labelsize=18)\n",
    "        labels = ax1.get_xticklabels() + ax1.get_yticklabels()\n",
    "        [label.set_fontname('Times New Roman') for label in labels]  \n",
    "        ax1.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Luck', alpha=.8)\n",
    "\n",
    "        ax1.plot(fpr, tpr,\n",
    "                label=r'Ensemble Model '+str(u)+ '(AUC = %0.4f)' % (auroc),\n",
    "                    lw=2, alpha=.8)\n",
    "        ax1.set_xlim([-0.05, 1.05])\n",
    "        ax1.set_ylim([-0.05, 1.05])\n",
    "        ax1.set_xlabel('False Positive Rate', font1)\n",
    "        ax1.set_ylabel('True Positive Rate', font1)\n",
    "        title1 = 'Cross Validated ROC Curve'\n",
    "        ax1.set_title(title1, font1)\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "        \n",
    "        ########PR_figure\n",
    "        figure2, ax2 = plt.subplots(figsize=figsize)\n",
    "        ax2.tick_params(labelsize=18)\n",
    "        labels = ax2.get_xticklabels() + ax2.get_yticklabels()\n",
    "        [label.set_fontname('Times New Roman') for label in labels] \n",
    "\n",
    "        ax2.plot(rc, pr,\n",
    "                label=r'Ensemble Model '+str(u)+ '(AUC = %0.4f)' % aupr,\n",
    "                lw=2, alpha=.8)\n",
    "\n",
    "        ax2.set_xlim([-0.05, 1.05])\n",
    "        ax2.set_ylim([-0.05, 1.05])\n",
    "        ax2.set_xlabel('Recall', font1)\n",
    "        ax2.set_ylabel('Precision', font1)\n",
    "        title2 = 'Cross Validated PR Curve'\n",
    "        ax2.set_title(title2, font1)\n",
    "        ax2.legend(loc=\"lower left\")\n",
    "    else:\n",
    "        fpr, tpr, threshold = roc_curve(temp_labels, temp_probas)\n",
    "        auroc = auc(fpr, tpr)\n",
    "        pr, rc, _ = precision_recall_curve(temp_labels, temp_probas)\n",
    "        aupr = average_precision_score(temp_labels, temp_probas)\n",
    "\n",
    "        ax1.plot(fpr, tpr,\n",
    "        label=r'Ensemble Model '+str(u)+ '(AUC = %0.4f)' % (auroc),\n",
    "            lw=2, alpha=.8)\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "        ax2.plot(rc, pr,\n",
    "                label=r'Ensemble Model '+str(u)+ '(AUC = %0.4f)' % aupr,\n",
    "                lw=2, alpha=.8)\n",
    "        ax2.legend(loc='lower left')\n",
    "\n",
    "    allprobas_ = np.append(allprobas_, temp_probas)\n",
    "    all_labels = np.append(all_labels, temp_labels)\n",
    "\n",
    "    temp_probas = np.array([])\n",
    "    temp_labels = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure1.savefig('figures/balancedCV_5_fold_roc.jpg', dpi=300, bbox_inches = 'tight')\n",
    "figure2.savefig('figures/balancedCV_5_fold_prc.jpg', dpi=300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.904674343087452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f6fa02f1be0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 446.4x446.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 446.4x446.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "font1 = {'family' : 'Times New Roman',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "figsize=6.2, 6.2\n",
    "\n",
    "########ROC_figure\n",
    "figure1, ax1 = plt.subplots(figsize=figsize)\n",
    "ax1.tick_params(labelsize=18)\n",
    "labels = ax1.get_xticklabels() + ax1.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]  \n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, allprobas_)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n",
    "\n",
    "ax1.plot(fpr, tpr, color='b',\n",
    "    label=r'Mean ROC (AUC = %0.4f)' % (roc_auc),\n",
    "    lw=2, alpha=.8)\n",
    "ax1.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Luck', alpha=.8)\n",
    "ax1.set_xlim([-0.05, 1.05])\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.set_xlabel('False Positive Rate', font1)\n",
    "ax1.set_ylabel('True Positive Rate', font1)\n",
    "title1 = 'Cross Validated ROC Curve'\n",
    "ax1.set_title(title1, font1)\n",
    "ax1.legend(loc=\"lower right\")\n",
    "#figure1.savefig('figures/balancedCV_mean_5_fold_roc.jpg', dpi=300, bbox_inches = 'tight')\n",
    "\n",
    "########PR_figure\n",
    "figure2, ax2 = plt.subplots(figsize=figsize)\n",
    "ax2.tick_params(labelsize=18)\n",
    "labels = ax2.get_xticklabels() + ax2.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels] \n",
    "\n",
    "precision, recall, _ = precision_recall_curve(all_labels, allprobas_)\n",
    "ax2.plot(recall, precision, color='b',\n",
    "        label=r'Mean Precision-Recall (AUC = %0.4f)' % (average_precision_score(all_labels, allprobas_)),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "ax2.set_xlim([-0.05, 1.05])\n",
    "ax2.set_ylim([-0.05, 1.05])\n",
    "ax2.set_xlabel('Recall', font1)\n",
    "ax2.set_ylabel('Precision', font1)\n",
    "title2 = 'Cross Validated PR Curve'\n",
    "ax2.set_title(title2, font1)\n",
    "ax2.legend(loc=\"lower left\")\n",
    "#figure2.savefig('figures/balancedCV_mean_5_fold_pr.jpg', dpi=300, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "allprobas2_=np.array([]) \n",
    "all_labels2=np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9043729084154335\n",
      "0.8867285406173129\n",
      "0.9078333530003553\n",
      "0.8913014574605149\n",
      "0.9069692972279242\n",
      "0.8901869411617296\n",
      "0.9065570514645526\n",
      "0.8886435432412917\n",
      "0.907325825686799\n",
      "0.8897905578600386\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 446.4x446.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 446.4x446.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "font1 = {'family' : 'Times New Roman',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "figsize=6.2, 6.2\n",
    "\n",
    "for i in range(5):\n",
    "    if i == 0:\n",
    "        saved_model = build_model(training_pep, training_mhc)\n",
    "        saved_model.load_weights('model/balanced_CV/model_' +str(i)+'.h5')\n",
    "        probas_ = saved_model.predict([np.array(test_pep),np.array(test_mhc)])\n",
    "        allprobas2_ = np.append(allprobas2_, probas_)           \n",
    "        all_labels2 = np.append(all_labels2, test_target)\n",
    "        del saved_model\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(all_labels2, allprobas2_)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        precision, recall, _ = precision_recall_curve(all_labels2, allprobas2_)\n",
    "        aupr = average_precision_score(all_labels2, allprobas2_)\n",
    "        print(roc_auc)\n",
    "        print(aupr)\n",
    "\n",
    "        figure1, ax1 = plt.subplots(figsize=figsize)\n",
    "        ax1.tick_params(labelsize=18)\n",
    "        labels = ax1.get_xticklabels() + ax1.get_yticklabels()\n",
    "        [label.set_fontname('Times New Roman') for label in labels]  \n",
    "        ax1.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Luck', alpha=.8)\n",
    "\n",
    "        ax1.plot(fpr, tpr, color='b',\n",
    "                label=r'First CV ROC (AUC = %0.4f)' % (roc_auc),\n",
    "                    lw=2, alpha=.8)\n",
    "        ax1.set_xlim([-0.05, 1.05])\n",
    "        ax1.set_ylim([-0.05, 1.05])\n",
    "        ax1.set_xlabel('False Positive Rate', font1)\n",
    "        ax1.set_ylabel('True Positive Rate', font1)\n",
    "        title1 = 'Cross Validated ROC Curve'\n",
    "        ax1.set_title(title1, font1)\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "        \n",
    "        ########PR_figure\n",
    "        figure2, ax2 = plt.subplots(figsize=figsize)\n",
    "        ax2.tick_params(labelsize=18)\n",
    "        labels = ax2.get_xticklabels() + ax2.get_yticklabels()\n",
    "        [label.set_fontname('Times New Roman') for label in labels] \n",
    "\n",
    "        ax2.plot(recall, precision, color='b',\n",
    "                label=r'First CV Precision-Recall (AUC = %0.4f)' % aupr,\n",
    "                lw=2, alpha=.8)\n",
    "\n",
    "        ax2.set_xlim([-0.05, 1.05])\n",
    "        ax2.set_ylim([-0.05, 1.05])\n",
    "        ax2.set_xlabel('Recall', font1)\n",
    "        ax2.set_ylabel('Precision', font1)\n",
    "        title2 = 'Cross Validated PR Curve'\n",
    "        ax2.set_title(title2, font1)\n",
    "        ax2.legend(loc=\"lower left\")\n",
    "\n",
    "    else:\n",
    "        saved_model = build_model(training_pep, training_mhc)\n",
    "        saved_model.load_weights('model/balanced_CV/model_' +str(i)+'.h5')\n",
    "        probas_ = saved_model.predict([np.array(test_pep),np.array(test_mhc)])\n",
    "        allprobas2_ = np.append(allprobas2_, probas_)           \n",
    "        all_labels2 = np.append(all_labels2, test_target)\n",
    "        del saved_model\n",
    "        \n",
    "        fpr, tpr, thresholds = roc_curve(test_target, probas_)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        precision, recall, _ = precision_recall_curve(test_target, probas_)\n",
    "        aupr = average_precision_score(test_target, probas_)\n",
    "        print(roc_auc)\n",
    "        print(aupr)\n",
    "\n",
    "        ax1.plot(fpr, tpr,\n",
    "        label=str(i)+'th CV ROC (AUC = %0.4f)' % (roc_auc),\n",
    "            lw=2, alpha=.8)\n",
    "        ax1.legend(loc=\"lower right\")\n",
    "\n",
    "\n",
    "        ax2.plot(recall, precision, \n",
    "        label=str(i)+'th CV Precision-Recall (AUC = %0.4f)' % (aupr),\n",
    "        lw=2, alpha=.8)\n",
    "        ax2.legend(loc=\"lower left\")\n",
    "\n",
    "figure1.savefig('figures/balancedCV_test_5_fold_roc.jpg', dpi=300, bbox_inches = 'tight')\n",
    "figure2.savefig('figures/balancedCV_test_5_fold_prc.jpg', dpi=300, bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9065181307006668\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 446.4x446.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 446.4x446.4 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "font1 = {'family' : 'Times New Roman',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 16}\n",
    "figsize=6.2, 6.2\n",
    "\n",
    "########ROC_figure\n",
    "figure1, ax1 = plt.subplots(figsize=figsize)\n",
    "ax1.tick_params(labelsize=18)\n",
    "labels = ax1.get_xticklabels() + ax1.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels]  \n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(all_labels2, allprobas2_)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n",
    "\n",
    "ax1.plot(fpr, tpr, color='b',\n",
    "    label=r'Mean ROC (AUC = %0.4f)' % (roc_auc),\n",
    "    lw=2, alpha=.8)\n",
    "ax1.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "        label='Luck', alpha=.8)\n",
    "ax1.set_xlim([-0.05, 1.05])\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.set_xlabel('False Positive Rate', font1)\n",
    "ax1.set_ylabel('True Positive Rate', font1)\n",
    "title1 = 'Cross Validated ROC Curve'\n",
    "ax1.set_title(title1, font1)\n",
    "ax1.legend(loc=\"lower right\")\n",
    "figure1.savefig('figures/balancedCV_test_mean_5_fold_roc.jpg', dpi=300, bbox_inches = 'tight')\n",
    "\n",
    "########PR_figure\n",
    "figure2, ax2 = plt.subplots(figsize=figsize)\n",
    "ax2.tick_params(labelsize=18)\n",
    "labels = ax2.get_xticklabels() + ax2.get_yticklabels()\n",
    "[label.set_fontname('Times New Roman') for label in labels] \n",
    "\n",
    "precision, recall, _ = precision_recall_curve(all_labels2, allprobas2_)\n",
    "ax2.plot(recall, precision, color='b',\n",
    "        label=r'Mean Precision-Recall (AUC = %0.4f)' % (average_precision_score(all_labels2, allprobas2_)),\n",
    "        lw=2, alpha=.8)\n",
    "\n",
    "ax2.set_xlim([-0.05, 1.05])\n",
    "ax2.set_ylim([-0.05, 1.05])\n",
    "ax2.set_xlabel('Recall', font1)\n",
    "ax2.set_ylabel('Precision', font1)\n",
    "title2 = 'Cross Validated PR Curve'\n",
    "ax2.set_title(title2, font1)\n",
    "ax2.legend(loc=\"lower left\")\n",
    "figure2.savefig('figures/balancedCV_test_mean_5_fold_pr.jpg', dpi=300, bbox_inches = 'tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure1, ax1 = plt.subplots(figsize=figsize)\n",
    "figure2, ax2 = plt.subplots(figsize=figsize)\n",
    "for i in range(5):\n",
    "    saved_model = build_model(training_pep, training_mhc)\n",
    "    saved_model = load_model('model/CV/model_'+str(i)+'.h5')\n",
    "\n",
    "    ax1.plot(saved_model.history[\"loss\"])\n",
    "    ax1.plot(saved_model.history[\"val_loss\"])\n",
    "    ax1.legend(['train', 'test'], loc='best')\n",
    " \n",
    "    ax2.plot(saved_model.history[\"accuracy\"])\n",
    "    ax2.plot(saved_model.history[\"val_accuracy\"])\n",
    "    ax2.legend(['train', 'test'], loc='best')\n",
    "\n",
    "    del saved_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('viralepitope': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "89a569e57c3a868c837518f690d34e8ba538dcefa2ece26ecfaf82d5cd67ebe4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
